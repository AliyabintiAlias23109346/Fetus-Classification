{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVyu4TyZgYBa"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "JT12rNcrgbGW",
        "outputId": "25612fbe-51f7-47d2-a37b-efb8369bdaeb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a746e3c9-0492-451a-b2f4-c7a03ec4d6dc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a746e3c9-0492-451a-b2f4-c7a03ec4d6dc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Fetus_testingdata.csv to Fetus_testingdata (3).csv\n",
            "Saving Fetus_trainingdata.csv to Fetus_trainingdata (3).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files  # Import Colab file upload library\n",
        "\n",
        "# Upload files directly from your device\n",
        "uploaded = files.upload()  # This opens a file upload dialog\n",
        "\n",
        "# Load the uploaded CSV files\n",
        "train_data = pd.read_csv(\"Fetus_trainingdata.csv\")\n",
        "test_data = pd.read_csv(\"Fetus_testingdata.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEMevF6YgjNc"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "train_data = pd.read_csv(\"Fetus_trainingdata.csv\")\n",
        "test_data = pd.read_csv(\"Fetus_testingdata.csv\")\n",
        "\n",
        "# Separate features and labels\n",
        "X_train = train_data.iloc[:, 1:].values\n",
        "y_train = train_data.iloc[:, 0].values\n",
        "X_test = test_data.iloc[:, 1:].values\n",
        "y_test = test_data.iloc[:, 0].values\n",
        "\n",
        "# Normalize features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4hYDZGaiap4"
      },
      "outputs": [],
      "source": [
        "# Convert categorical labels to numeric codes\n",
        "train_data['label_encoded'] = pd.Categorical(train_data.iloc[:, 0]).codes\n",
        "test_data['label_encoded'] = pd.Categorical(test_data.iloc[:, 0],\n",
        "                                            categories=pd.Categorical(train_data.iloc[:, 0]).categories).codes\n",
        "\n",
        "# Separate features and encoded labels\n",
        "X_train = train_data.iloc[:, 1:-1].values  # Features\n",
        "y_train = train_data['label_encoded'].values  # Encoded labels\n",
        "X_test = test_data.iloc[:, 1:-1].values\n",
        "y_test = test_data['label_encoded'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_FdYaiPid0X"
      },
      "outputs": [],
      "source": [
        "class FetusDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# Create Dataset and DataLoader instances\n",
        "batch_size = 32\n",
        "train_dataset = FetusDataset(X_train, y_train)\n",
        "test_dataset = FetusDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyI9_eP5jS0Z"
      },
      "outputs": [],
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(16, 10)\n",
        "        self.fc2 = nn.Linear(10, 5)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(10)\n",
        "        #self.batchnorm2 = nn.BatchNorm1d(5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)  # No softmax here; CrossEntropyLoss will handle it\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = MLPModel()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kKQEI7trCBXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIxa_KA-jc_8"
      },
      "outputs": [],
      "source": [
        "#Set hyperparameters\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVlVfSzcjgfT",
        "outputId": "2be706ea-3162-4afa-83f6-4954c8e223a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 5001/10000, Train Loss: 0.6232, Train Acc: 63.01%, Test Loss: 0.5637, Test Acc: 70.69%\n",
            "Epoch 5002/10000, Train Loss: 0.6172, Train Acc: 65.32%, Test Loss: 0.5586, Test Acc: 72.41%\n",
            "Epoch 5003/10000, Train Loss: 0.6260, Train Acc: 66.18%, Test Loss: 0.5551, Test Acc: 74.14%\n",
            "Epoch 5004/10000, Train Loss: 0.6340, Train Acc: 60.69%, Test Loss: 0.5562, Test Acc: 75.86%\n",
            "Epoch 5005/10000, Train Loss: 0.6256, Train Acc: 61.27%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 5006/10000, Train Loss: 0.6178, Train Acc: 64.74%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 5007/10000, Train Loss: 0.6115, Train Acc: 63.87%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 5008/10000, Train Loss: 0.6229, Train Acc: 64.74%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 5009/10000, Train Loss: 0.6017, Train Acc: 65.32%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 5010/10000, Train Loss: 0.6194, Train Acc: 63.01%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 5011/10000, Train Loss: 0.6233, Train Acc: 65.03%, Test Loss: 0.5511, Test Acc: 68.97%\n",
            "Epoch 5012/10000, Train Loss: 0.6106, Train Acc: 64.16%, Test Loss: 0.5516, Test Acc: 74.14%\n",
            "Epoch 5013/10000, Train Loss: 0.6126, Train Acc: 66.76%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 5014/10000, Train Loss: 0.6412, Train Acc: 61.85%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 5015/10000, Train Loss: 0.6113, Train Acc: 63.87%, Test Loss: 0.5600, Test Acc: 70.69%\n",
            "Epoch 5016/10000, Train Loss: 0.6167, Train Acc: 64.74%, Test Loss: 0.5600, Test Acc: 70.69%\n",
            "Epoch 5017/10000, Train Loss: 0.6408, Train Acc: 61.56%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 5018/10000, Train Loss: 0.6390, Train Acc: 60.98%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5019/10000, Train Loss: 0.6056, Train Acc: 64.16%, Test Loss: 0.5626, Test Acc: 70.69%\n",
            "Epoch 5020/10000, Train Loss: 0.6237, Train Acc: 63.01%, Test Loss: 0.5647, Test Acc: 68.97%\n",
            "Epoch 5021/10000, Train Loss: 0.6125, Train Acc: 65.90%, Test Loss: 0.5664, Test Acc: 67.24%\n",
            "Epoch 5022/10000, Train Loss: 0.6321, Train Acc: 61.85%, Test Loss: 0.5656, Test Acc: 70.69%\n",
            "Epoch 5023/10000, Train Loss: 0.5937, Train Acc: 68.50%, Test Loss: 0.5673, Test Acc: 72.41%\n",
            "Epoch 5024/10000, Train Loss: 0.6249, Train Acc: 67.34%, Test Loss: 0.5656, Test Acc: 72.41%\n",
            "Epoch 5025/10000, Train Loss: 0.6074, Train Acc: 64.16%, Test Loss: 0.5623, Test Acc: 75.86%\n",
            "Epoch 5026/10000, Train Loss: 0.6386, Train Acc: 62.14%, Test Loss: 0.5567, Test Acc: 75.86%\n",
            "Epoch 5027/10000, Train Loss: 0.6220, Train Acc: 62.72%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 5028/10000, Train Loss: 0.6272, Train Acc: 63.29%, Test Loss: 0.5561, Test Acc: 74.14%\n",
            "Epoch 5029/10000, Train Loss: 0.6116, Train Acc: 64.16%, Test Loss: 0.5561, Test Acc: 74.14%\n",
            "Epoch 5030/10000, Train Loss: 0.6267, Train Acc: 61.27%, Test Loss: 0.5553, Test Acc: 75.86%\n",
            "Epoch 5031/10000, Train Loss: 0.6064, Train Acc: 65.90%, Test Loss: 0.5553, Test Acc: 75.86%\n",
            "Epoch 5032/10000, Train Loss: 0.6047, Train Acc: 64.45%, Test Loss: 0.5552, Test Acc: 75.86%\n",
            "Epoch 5033/10000, Train Loss: 0.6202, Train Acc: 67.34%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 5034/10000, Train Loss: 0.6062, Train Acc: 65.32%, Test Loss: 0.5618, Test Acc: 68.97%\n",
            "Epoch 5035/10000, Train Loss: 0.5945, Train Acc: 65.32%, Test Loss: 0.5671, Test Acc: 67.24%\n",
            "Epoch 5036/10000, Train Loss: 0.6195, Train Acc: 62.72%, Test Loss: 0.5686, Test Acc: 68.97%\n",
            "Epoch 5037/10000, Train Loss: 0.6067, Train Acc: 65.32%, Test Loss: 0.5627, Test Acc: 70.69%\n",
            "Epoch 5038/10000, Train Loss: 0.6052, Train Acc: 65.03%, Test Loss: 0.5568, Test Acc: 70.69%\n",
            "Epoch 5039/10000, Train Loss: 0.6297, Train Acc: 62.72%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 5040/10000, Train Loss: 0.6350, Train Acc: 62.43%, Test Loss: 0.5564, Test Acc: 74.14%\n",
            "Epoch 5041/10000, Train Loss: 0.6094, Train Acc: 62.43%, Test Loss: 0.5557, Test Acc: 75.86%\n",
            "Epoch 5042/10000, Train Loss: 0.6277, Train Acc: 62.14%, Test Loss: 0.5554, Test Acc: 75.86%\n",
            "Epoch 5043/10000, Train Loss: 0.6148, Train Acc: 70.52%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 5044/10000, Train Loss: 0.6130, Train Acc: 63.01%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 5045/10000, Train Loss: 0.6124, Train Acc: 64.16%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5046/10000, Train Loss: 0.5972, Train Acc: 67.34%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 5047/10000, Train Loss: 0.6187, Train Acc: 61.56%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 5048/10000, Train Loss: 0.6319, Train Acc: 63.58%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 5049/10000, Train Loss: 0.6050, Train Acc: 67.05%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 5050/10000, Train Loss: 0.6294, Train Acc: 63.29%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 5051/10000, Train Loss: 0.5990, Train Acc: 68.79%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 5052/10000, Train Loss: 0.6080, Train Acc: 62.14%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 5053/10000, Train Loss: 0.6188, Train Acc: 64.16%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 5054/10000, Train Loss: 0.6014, Train Acc: 66.76%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 5055/10000, Train Loss: 0.6154, Train Acc: 65.03%, Test Loss: 0.5519, Test Acc: 70.69%\n",
            "Epoch 5056/10000, Train Loss: 0.6088, Train Acc: 65.90%, Test Loss: 0.5520, Test Acc: 75.86%\n",
            "Epoch 5057/10000, Train Loss: 0.6214, Train Acc: 63.87%, Test Loss: 0.5517, Test Acc: 75.86%\n",
            "Epoch 5058/10000, Train Loss: 0.6021, Train Acc: 65.32%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 5059/10000, Train Loss: 0.6145, Train Acc: 62.72%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 5060/10000, Train Loss: 0.6026, Train Acc: 65.03%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 5061/10000, Train Loss: 0.6065, Train Acc: 64.16%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 5062/10000, Train Loss: 0.6287, Train Acc: 65.61%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 5063/10000, Train Loss: 0.5968, Train Acc: 63.87%, Test Loss: 0.5609, Test Acc: 70.69%\n",
            "Epoch 5064/10000, Train Loss: 0.6391, Train Acc: 62.43%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 5065/10000, Train Loss: 0.5835, Train Acc: 65.32%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 5066/10000, Train Loss: 0.5994, Train Acc: 61.85%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 5067/10000, Train Loss: 0.6149, Train Acc: 62.43%, Test Loss: 0.5511, Test Acc: 68.97%\n",
            "Epoch 5068/10000, Train Loss: 0.6140, Train Acc: 61.27%, Test Loss: 0.5482, Test Acc: 68.97%\n",
            "Epoch 5069/10000, Train Loss: 0.5985, Train Acc: 67.63%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 5070/10000, Train Loss: 0.6190, Train Acc: 61.85%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 5071/10000, Train Loss: 0.6062, Train Acc: 65.61%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 5072/10000, Train Loss: 0.6141, Train Acc: 66.47%, Test Loss: 0.5606, Test Acc: 68.97%\n",
            "Epoch 5073/10000, Train Loss: 0.6353, Train Acc: 65.90%, Test Loss: 0.5648, Test Acc: 68.97%\n",
            "Epoch 5074/10000, Train Loss: 0.6054, Train Acc: 64.16%, Test Loss: 0.5627, Test Acc: 67.24%\n",
            "Epoch 5075/10000, Train Loss: 0.6202, Train Acc: 64.74%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 5076/10000, Train Loss: 0.6223, Train Acc: 65.61%, Test Loss: 0.5574, Test Acc: 74.14%\n",
            "Epoch 5077/10000, Train Loss: 0.6038, Train Acc: 61.85%, Test Loss: 0.5549, Test Acc: 75.86%\n",
            "Epoch 5078/10000, Train Loss: 0.6132, Train Acc: 69.08%, Test Loss: 0.5541, Test Acc: 75.86%\n",
            "Epoch 5079/10000, Train Loss: 0.5930, Train Acc: 67.63%, Test Loss: 0.5527, Test Acc: 74.14%\n",
            "Epoch 5080/10000, Train Loss: 0.5908, Train Acc: 64.74%, Test Loss: 0.5532, Test Acc: 75.86%\n",
            "Epoch 5081/10000, Train Loss: 0.6196, Train Acc: 62.72%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 5082/10000, Train Loss: 0.6236, Train Acc: 64.16%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 5083/10000, Train Loss: 0.5963, Train Acc: 65.90%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 5084/10000, Train Loss: 0.6212, Train Acc: 64.74%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 5085/10000, Train Loss: 0.6147, Train Acc: 61.85%, Test Loss: 0.5640, Test Acc: 67.24%\n",
            "Epoch 5086/10000, Train Loss: 0.6222, Train Acc: 64.74%, Test Loss: 0.5663, Test Acc: 67.24%\n",
            "Epoch 5087/10000, Train Loss: 0.5980, Train Acc: 65.03%, Test Loss: 0.5683, Test Acc: 65.52%\n",
            "Epoch 5088/10000, Train Loss: 0.6054, Train Acc: 67.34%, Test Loss: 0.5626, Test Acc: 67.24%\n",
            "Epoch 5089/10000, Train Loss: 0.6101, Train Acc: 64.45%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 5090/10000, Train Loss: 0.6290, Train Acc: 63.58%, Test Loss: 0.5529, Test Acc: 75.86%\n",
            "Epoch 5091/10000, Train Loss: 0.6005, Train Acc: 64.45%, Test Loss: 0.5554, Test Acc: 75.86%\n",
            "Epoch 5092/10000, Train Loss: 0.6302, Train Acc: 66.18%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 5093/10000, Train Loss: 0.6218, Train Acc: 66.76%, Test Loss: 0.5607, Test Acc: 72.41%\n",
            "Epoch 5094/10000, Train Loss: 0.6298, Train Acc: 63.29%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 5095/10000, Train Loss: 0.6081, Train Acc: 65.32%, Test Loss: 0.5588, Test Acc: 70.69%\n",
            "Epoch 5096/10000, Train Loss: 0.6258, Train Acc: 63.87%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 5097/10000, Train Loss: 0.6327, Train Acc: 63.58%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 5098/10000, Train Loss: 0.6380, Train Acc: 66.76%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 5099/10000, Train Loss: 0.6241, Train Acc: 63.01%, Test Loss: 0.5592, Test Acc: 75.86%\n",
            "Epoch 5100/10000, Train Loss: 0.6168, Train Acc: 67.34%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 5101/10000, Train Loss: 0.6126, Train Acc: 65.03%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 5102/10000, Train Loss: 0.6306, Train Acc: 65.32%, Test Loss: 0.5509, Test Acc: 75.86%\n",
            "Epoch 5103/10000, Train Loss: 0.6361, Train Acc: 64.16%, Test Loss: 0.5512, Test Acc: 75.86%\n",
            "Epoch 5104/10000, Train Loss: 0.6195, Train Acc: 65.90%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 5105/10000, Train Loss: 0.6167, Train Acc: 65.90%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 5106/10000, Train Loss: 0.6414, Train Acc: 63.01%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 5107/10000, Train Loss: 0.6096, Train Acc: 62.72%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 5108/10000, Train Loss: 0.6121, Train Acc: 66.76%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 5109/10000, Train Loss: 0.6132, Train Acc: 64.74%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5110/10000, Train Loss: 0.6099, Train Acc: 65.32%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 5111/10000, Train Loss: 0.6218, Train Acc: 65.03%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 5112/10000, Train Loss: 0.6180, Train Acc: 66.47%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5113/10000, Train Loss: 0.6194, Train Acc: 64.74%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 5114/10000, Train Loss: 0.5960, Train Acc: 66.76%, Test Loss: 0.5617, Test Acc: 68.97%\n",
            "Epoch 5115/10000, Train Loss: 0.6228, Train Acc: 66.47%, Test Loss: 0.5645, Test Acc: 67.24%\n",
            "Epoch 5116/10000, Train Loss: 0.6300, Train Acc: 63.87%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 5117/10000, Train Loss: 0.6149, Train Acc: 63.01%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 5118/10000, Train Loss: 0.6044, Train Acc: 63.29%, Test Loss: 0.5571, Test Acc: 70.69%\n",
            "Epoch 5119/10000, Train Loss: 0.5899, Train Acc: 67.05%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 5120/10000, Train Loss: 0.6103, Train Acc: 63.58%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 5121/10000, Train Loss: 0.6278, Train Acc: 66.76%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 5122/10000, Train Loss: 0.6250, Train Acc: 66.18%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 5123/10000, Train Loss: 0.6098, Train Acc: 65.90%, Test Loss: 0.5574, Test Acc: 74.14%\n",
            "Epoch 5124/10000, Train Loss: 0.6301, Train Acc: 62.72%, Test Loss: 0.5570, Test Acc: 74.14%\n",
            "Epoch 5125/10000, Train Loss: 0.6242, Train Acc: 64.45%, Test Loss: 0.5574, Test Acc: 72.41%\n",
            "Epoch 5126/10000, Train Loss: 0.6153, Train Acc: 63.58%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 5127/10000, Train Loss: 0.6127, Train Acc: 62.14%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 5128/10000, Train Loss: 0.6117, Train Acc: 67.34%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 5129/10000, Train Loss: 0.6163, Train Acc: 67.92%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 5130/10000, Train Loss: 0.6163, Train Acc: 66.47%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 5131/10000, Train Loss: 0.6179, Train Acc: 68.21%, Test Loss: 0.5609, Test Acc: 70.69%\n",
            "Epoch 5132/10000, Train Loss: 0.6017, Train Acc: 66.76%, Test Loss: 0.5572, Test Acc: 72.41%\n",
            "Epoch 5133/10000, Train Loss: 0.6147, Train Acc: 65.32%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 5134/10000, Train Loss: 0.5981, Train Acc: 65.61%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 5135/10000, Train Loss: 0.6099, Train Acc: 63.01%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 5136/10000, Train Loss: 0.6050, Train Acc: 65.03%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 5137/10000, Train Loss: 0.6019, Train Acc: 66.18%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 5138/10000, Train Loss: 0.6101, Train Acc: 62.43%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 5139/10000, Train Loss: 0.6070, Train Acc: 65.32%, Test Loss: 0.5566, Test Acc: 74.14%\n",
            "Epoch 5140/10000, Train Loss: 0.6318, Train Acc: 59.54%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 5141/10000, Train Loss: 0.6150, Train Acc: 63.29%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 5142/10000, Train Loss: 0.6272, Train Acc: 63.87%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 5143/10000, Train Loss: 0.6057, Train Acc: 66.76%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 5144/10000, Train Loss: 0.6202, Train Acc: 62.14%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 5145/10000, Train Loss: 0.6111, Train Acc: 64.16%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 5146/10000, Train Loss: 0.6175, Train Acc: 64.45%, Test Loss: 0.5577, Test Acc: 70.69%\n",
            "Epoch 5147/10000, Train Loss: 0.6225, Train Acc: 65.61%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 5148/10000, Train Loss: 0.5999, Train Acc: 64.45%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 5149/10000, Train Loss: 0.6340, Train Acc: 62.14%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 5150/10000, Train Loss: 0.6271, Train Acc: 63.58%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 5151/10000, Train Loss: 0.6234, Train Acc: 63.87%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 5152/10000, Train Loss: 0.6158, Train Acc: 63.87%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 5153/10000, Train Loss: 0.6053, Train Acc: 66.47%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 5154/10000, Train Loss: 0.6020, Train Acc: 65.61%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 5155/10000, Train Loss: 0.6359, Train Acc: 64.74%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 5156/10000, Train Loss: 0.6490, Train Acc: 61.27%, Test Loss: 0.5521, Test Acc: 72.41%\n",
            "Epoch 5157/10000, Train Loss: 0.6130, Train Acc: 65.03%, Test Loss: 0.5515, Test Acc: 72.41%\n",
            "Epoch 5158/10000, Train Loss: 0.6185, Train Acc: 62.14%, Test Loss: 0.5501, Test Acc: 74.14%\n",
            "Epoch 5159/10000, Train Loss: 0.6223, Train Acc: 63.29%, Test Loss: 0.5477, Test Acc: 72.41%\n",
            "Epoch 5160/10000, Train Loss: 0.6216, Train Acc: 66.18%, Test Loss: 0.5520, Test Acc: 74.14%\n",
            "Epoch 5161/10000, Train Loss: 0.6137, Train Acc: 64.74%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 5162/10000, Train Loss: 0.6315, Train Acc: 63.58%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 5163/10000, Train Loss: 0.6189, Train Acc: 64.16%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 5164/10000, Train Loss: 0.6089, Train Acc: 67.05%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 5165/10000, Train Loss: 0.6547, Train Acc: 61.27%, Test Loss: 0.5472, Test Acc: 70.69%\n",
            "Epoch 5166/10000, Train Loss: 0.6071, Train Acc: 64.45%, Test Loss: 0.5481, Test Acc: 70.69%\n",
            "Epoch 5167/10000, Train Loss: 0.6307, Train Acc: 62.14%, Test Loss: 0.5479, Test Acc: 70.69%\n",
            "Epoch 5168/10000, Train Loss: 0.6301, Train Acc: 62.43%, Test Loss: 0.5498, Test Acc: 68.97%\n",
            "Epoch 5169/10000, Train Loss: 0.6538, Train Acc: 62.14%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 5170/10000, Train Loss: 0.5974, Train Acc: 63.01%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 5171/10000, Train Loss: 0.6254, Train Acc: 65.03%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 5172/10000, Train Loss: 0.6270, Train Acc: 66.47%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 5173/10000, Train Loss: 0.6275, Train Acc: 64.45%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 5174/10000, Train Loss: 0.6141, Train Acc: 65.90%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5175/10000, Train Loss: 0.6344, Train Acc: 63.58%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 5176/10000, Train Loss: 0.6138, Train Acc: 65.32%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 5177/10000, Train Loss: 0.5964, Train Acc: 67.05%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 5178/10000, Train Loss: 0.6188, Train Acc: 63.29%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 5179/10000, Train Loss: 0.5961, Train Acc: 64.16%, Test Loss: 0.5522, Test Acc: 75.86%\n",
            "Epoch 5180/10000, Train Loss: 0.6120, Train Acc: 64.74%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 5181/10000, Train Loss: 0.6033, Train Acc: 64.74%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 5182/10000, Train Loss: 0.6204, Train Acc: 67.63%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 5183/10000, Train Loss: 0.6294, Train Acc: 66.76%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 5184/10000, Train Loss: 0.6246, Train Acc: 64.45%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 5185/10000, Train Loss: 0.6019, Train Acc: 66.18%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 5186/10000, Train Loss: 0.6300, Train Acc: 63.01%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 5187/10000, Train Loss: 0.6260, Train Acc: 63.29%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 5188/10000, Train Loss: 0.6028, Train Acc: 62.43%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5189/10000, Train Loss: 0.6114, Train Acc: 65.61%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 5190/10000, Train Loss: 0.6599, Train Acc: 60.40%, Test Loss: 0.5502, Test Acc: 68.97%\n",
            "Epoch 5191/10000, Train Loss: 0.6199, Train Acc: 63.01%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 5192/10000, Train Loss: 0.6173, Train Acc: 63.87%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 5193/10000, Train Loss: 0.6146, Train Acc: 65.61%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 5194/10000, Train Loss: 0.6208, Train Acc: 64.74%, Test Loss: 0.5611, Test Acc: 68.97%\n",
            "Epoch 5195/10000, Train Loss: 0.6295, Train Acc: 65.61%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 5196/10000, Train Loss: 0.6221, Train Acc: 61.85%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 5197/10000, Train Loss: 0.5871, Train Acc: 65.90%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 5198/10000, Train Loss: 0.6157, Train Acc: 66.47%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 5199/10000, Train Loss: 0.6155, Train Acc: 65.90%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 5200/10000, Train Loss: 0.6123, Train Acc: 65.03%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 5201/10000, Train Loss: 0.6168, Train Acc: 65.32%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 5202/10000, Train Loss: 0.6302, Train Acc: 63.29%, Test Loss: 0.5531, Test Acc: 74.14%\n",
            "Epoch 5203/10000, Train Loss: 0.5984, Train Acc: 65.03%, Test Loss: 0.5575, Test Acc: 74.14%\n",
            "Epoch 5204/10000, Train Loss: 0.6185, Train Acc: 64.16%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 5205/10000, Train Loss: 0.6183, Train Acc: 65.32%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 5206/10000, Train Loss: 0.6219, Train Acc: 65.03%, Test Loss: 0.5500, Test Acc: 72.41%\n",
            "Epoch 5207/10000, Train Loss: 0.6184, Train Acc: 59.54%, Test Loss: 0.5493, Test Acc: 70.69%\n",
            "Epoch 5208/10000, Train Loss: 0.6267, Train Acc: 64.74%, Test Loss: 0.5500, Test Acc: 67.24%\n",
            "Epoch 5209/10000, Train Loss: 0.6405, Train Acc: 65.03%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 5210/10000, Train Loss: 0.6101, Train Acc: 65.03%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 5211/10000, Train Loss: 0.6326, Train Acc: 62.43%, Test Loss: 0.5506, Test Acc: 70.69%\n",
            "Epoch 5212/10000, Train Loss: 0.6196, Train Acc: 66.47%, Test Loss: 0.5482, Test Acc: 68.97%\n",
            "Epoch 5213/10000, Train Loss: 0.6260, Train Acc: 64.16%, Test Loss: 0.5488, Test Acc: 68.97%\n",
            "Epoch 5214/10000, Train Loss: 0.6370, Train Acc: 65.61%, Test Loss: 0.5514, Test Acc: 67.24%\n",
            "Epoch 5215/10000, Train Loss: 0.6126, Train Acc: 67.92%, Test Loss: 0.5510, Test Acc: 67.24%\n",
            "Epoch 5216/10000, Train Loss: 0.6185, Train Acc: 63.87%, Test Loss: 0.5523, Test Acc: 67.24%\n",
            "Epoch 5217/10000, Train Loss: 0.6129, Train Acc: 63.29%, Test Loss: 0.5495, Test Acc: 70.69%\n",
            "Epoch 5218/10000, Train Loss: 0.6139, Train Acc: 65.03%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 5219/10000, Train Loss: 0.6197, Train Acc: 65.32%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 5220/10000, Train Loss: 0.6130, Train Acc: 61.56%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 5221/10000, Train Loss: 0.6242, Train Acc: 65.32%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 5222/10000, Train Loss: 0.6146, Train Acc: 65.90%, Test Loss: 0.5618, Test Acc: 68.97%\n",
            "Epoch 5223/10000, Train Loss: 0.6017, Train Acc: 66.47%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 5224/10000, Train Loss: 0.6007, Train Acc: 65.32%, Test Loss: 0.5498, Test Acc: 75.86%\n",
            "Epoch 5225/10000, Train Loss: 0.6115, Train Acc: 66.18%, Test Loss: 0.5485, Test Acc: 70.69%\n",
            "Epoch 5226/10000, Train Loss: 0.6211, Train Acc: 61.56%, Test Loss: 0.5515, Test Acc: 74.14%\n",
            "Epoch 5227/10000, Train Loss: 0.6374, Train Acc: 64.16%, Test Loss: 0.5519, Test Acc: 70.69%\n",
            "Epoch 5228/10000, Train Loss: 0.6185, Train Acc: 65.61%, Test Loss: 0.5487, Test Acc: 72.41%\n",
            "Epoch 5229/10000, Train Loss: 0.6143, Train Acc: 64.16%, Test Loss: 0.5476, Test Acc: 70.69%\n",
            "Epoch 5230/10000, Train Loss: 0.6101, Train Acc: 65.32%, Test Loss: 0.5515, Test Acc: 72.41%\n",
            "Epoch 5231/10000, Train Loss: 0.6311, Train Acc: 63.58%, Test Loss: 0.5561, Test Acc: 67.24%\n",
            "Epoch 5232/10000, Train Loss: 0.6121, Train Acc: 60.98%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 5233/10000, Train Loss: 0.6270, Train Acc: 65.03%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 5234/10000, Train Loss: 0.6237, Train Acc: 67.92%, Test Loss: 0.5508, Test Acc: 68.97%\n",
            "Epoch 5235/10000, Train Loss: 0.6207, Train Acc: 64.74%, Test Loss: 0.5554, Test Acc: 72.41%\n",
            "Epoch 5236/10000, Train Loss: 0.6147, Train Acc: 63.58%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 5237/10000, Train Loss: 0.6365, Train Acc: 63.29%, Test Loss: 0.5594, Test Acc: 72.41%\n",
            "Epoch 5238/10000, Train Loss: 0.6026, Train Acc: 62.43%, Test Loss: 0.5602, Test Acc: 68.97%\n",
            "Epoch 5239/10000, Train Loss: 0.5955, Train Acc: 63.87%, Test Loss: 0.5602, Test Acc: 68.97%\n",
            "Epoch 5240/10000, Train Loss: 0.6200, Train Acc: 65.90%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 5241/10000, Train Loss: 0.5979, Train Acc: 63.58%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 5242/10000, Train Loss: 0.6032, Train Acc: 64.74%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 5243/10000, Train Loss: 0.6014, Train Acc: 64.74%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 5244/10000, Train Loss: 0.6398, Train Acc: 62.43%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 5245/10000, Train Loss: 0.6234, Train Acc: 61.27%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 5246/10000, Train Loss: 0.6202, Train Acc: 64.74%, Test Loss: 0.5526, Test Acc: 70.69%\n",
            "Epoch 5247/10000, Train Loss: 0.6119, Train Acc: 63.87%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 5248/10000, Train Loss: 0.6086, Train Acc: 63.87%, Test Loss: 0.5487, Test Acc: 74.14%\n",
            "Epoch 5249/10000, Train Loss: 0.6091, Train Acc: 64.16%, Test Loss: 0.5514, Test Acc: 70.69%\n",
            "Epoch 5250/10000, Train Loss: 0.6258, Train Acc: 63.58%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 5251/10000, Train Loss: 0.6611, Train Acc: 62.14%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 5252/10000, Train Loss: 0.6356, Train Acc: 63.87%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 5253/10000, Train Loss: 0.6213, Train Acc: 66.18%, Test Loss: 0.5527, Test Acc: 74.14%\n",
            "Epoch 5254/10000, Train Loss: 0.6089, Train Acc: 67.92%, Test Loss: 0.5523, Test Acc: 72.41%\n",
            "Epoch 5255/10000, Train Loss: 0.6248, Train Acc: 62.14%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 5256/10000, Train Loss: 0.6427, Train Acc: 63.01%, Test Loss: 0.5587, Test Acc: 72.41%\n",
            "Epoch 5257/10000, Train Loss: 0.6187, Train Acc: 63.29%, Test Loss: 0.5643, Test Acc: 70.69%\n",
            "Epoch 5258/10000, Train Loss: 0.6068, Train Acc: 63.01%, Test Loss: 0.5597, Test Acc: 70.69%\n",
            "Epoch 5259/10000, Train Loss: 0.6118, Train Acc: 62.72%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 5260/10000, Train Loss: 0.6286, Train Acc: 65.90%, Test Loss: 0.5530, Test Acc: 75.86%\n",
            "Epoch 5261/10000, Train Loss: 0.6145, Train Acc: 64.45%, Test Loss: 0.5526, Test Acc: 75.86%\n",
            "Epoch 5262/10000, Train Loss: 0.6176, Train Acc: 65.61%, Test Loss: 0.5533, Test Acc: 74.14%\n",
            "Epoch 5263/10000, Train Loss: 0.6111, Train Acc: 67.05%, Test Loss: 0.5570, Test Acc: 72.41%\n",
            "Epoch 5264/10000, Train Loss: 0.6105, Train Acc: 64.45%, Test Loss: 0.5553, Test Acc: 74.14%\n",
            "Epoch 5265/10000, Train Loss: 0.6200, Train Acc: 63.29%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 5266/10000, Train Loss: 0.6291, Train Acc: 61.56%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 5267/10000, Train Loss: 0.6302, Train Acc: 64.45%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 5268/10000, Train Loss: 0.6319, Train Acc: 61.27%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 5269/10000, Train Loss: 0.6112, Train Acc: 62.72%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 5270/10000, Train Loss: 0.6173, Train Acc: 65.03%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 5271/10000, Train Loss: 0.6297, Train Acc: 65.03%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 5272/10000, Train Loss: 0.6257, Train Acc: 63.01%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 5273/10000, Train Loss: 0.6113, Train Acc: 65.32%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5274/10000, Train Loss: 0.6379, Train Acc: 65.32%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 5275/10000, Train Loss: 0.6335, Train Acc: 62.14%, Test Loss: 0.5612, Test Acc: 72.41%\n",
            "Epoch 5276/10000, Train Loss: 0.6151, Train Acc: 67.34%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 5277/10000, Train Loss: 0.6245, Train Acc: 65.03%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 5278/10000, Train Loss: 0.6176, Train Acc: 66.76%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 5279/10000, Train Loss: 0.6116, Train Acc: 64.45%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 5280/10000, Train Loss: 0.6284, Train Acc: 63.01%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5281/10000, Train Loss: 0.6130, Train Acc: 63.01%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 5282/10000, Train Loss: 0.5994, Train Acc: 67.92%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 5283/10000, Train Loss: 0.5982, Train Acc: 64.74%, Test Loss: 0.5551, Test Acc: 74.14%\n",
            "Epoch 5284/10000, Train Loss: 0.6076, Train Acc: 66.76%, Test Loss: 0.5566, Test Acc: 72.41%\n",
            "Epoch 5285/10000, Train Loss: 0.6046, Train Acc: 66.76%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 5286/10000, Train Loss: 0.6340, Train Acc: 64.16%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 5287/10000, Train Loss: 0.5920, Train Acc: 66.76%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 5288/10000, Train Loss: 0.6109, Train Acc: 64.45%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 5289/10000, Train Loss: 0.6039, Train Acc: 63.87%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5290/10000, Train Loss: 0.6036, Train Acc: 68.50%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 5291/10000, Train Loss: 0.5925, Train Acc: 66.47%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 5292/10000, Train Loss: 0.6151, Train Acc: 65.61%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5293/10000, Train Loss: 0.6148, Train Acc: 61.85%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 5294/10000, Train Loss: 0.6204, Train Acc: 67.34%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 5295/10000, Train Loss: 0.6138, Train Acc: 64.74%, Test Loss: 0.5614, Test Acc: 68.97%\n",
            "Epoch 5296/10000, Train Loss: 0.6224, Train Acc: 65.03%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 5297/10000, Train Loss: 0.6393, Train Acc: 63.58%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 5298/10000, Train Loss: 0.6111, Train Acc: 62.14%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 5299/10000, Train Loss: 0.5961, Train Acc: 68.21%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 5300/10000, Train Loss: 0.6224, Train Acc: 63.01%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 5301/10000, Train Loss: 0.6013, Train Acc: 63.87%, Test Loss: 0.5522, Test Acc: 75.86%\n",
            "Epoch 5302/10000, Train Loss: 0.5983, Train Acc: 68.21%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 5303/10000, Train Loss: 0.6102, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 5304/10000, Train Loss: 0.6266, Train Acc: 62.43%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 5305/10000, Train Loss: 0.5978, Train Acc: 65.32%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 5306/10000, Train Loss: 0.6095, Train Acc: 65.61%, Test Loss: 0.5615, Test Acc: 70.69%\n",
            "Epoch 5307/10000, Train Loss: 0.6246, Train Acc: 65.61%, Test Loss: 0.5624, Test Acc: 68.97%\n",
            "Epoch 5308/10000, Train Loss: 0.6133, Train Acc: 65.61%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 5309/10000, Train Loss: 0.5942, Train Acc: 64.16%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 5310/10000, Train Loss: 0.6304, Train Acc: 62.72%, Test Loss: 0.5575, Test Acc: 70.69%\n",
            "Epoch 5311/10000, Train Loss: 0.6195, Train Acc: 66.76%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 5312/10000, Train Loss: 0.5988, Train Acc: 68.21%, Test Loss: 0.5579, Test Acc: 72.41%\n",
            "Epoch 5313/10000, Train Loss: 0.6100, Train Acc: 65.03%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 5314/10000, Train Loss: 0.6201, Train Acc: 64.16%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 5315/10000, Train Loss: 0.6201, Train Acc: 63.29%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 5316/10000, Train Loss: 0.6023, Train Acc: 64.74%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 5317/10000, Train Loss: 0.6241, Train Acc: 65.90%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 5318/10000, Train Loss: 0.6247, Train Acc: 65.03%, Test Loss: 0.5585, Test Acc: 72.41%\n",
            "Epoch 5319/10000, Train Loss: 0.6083, Train Acc: 65.90%, Test Loss: 0.5589, Test Acc: 70.69%\n",
            "Epoch 5320/10000, Train Loss: 0.6121, Train Acc: 65.61%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 5321/10000, Train Loss: 0.6229, Train Acc: 63.58%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 5322/10000, Train Loss: 0.6205, Train Acc: 62.72%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 5323/10000, Train Loss: 0.6397, Train Acc: 63.29%, Test Loss: 0.5585, Test Acc: 72.41%\n",
            "Epoch 5324/10000, Train Loss: 0.6346, Train Acc: 65.32%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 5325/10000, Train Loss: 0.6363, Train Acc: 64.45%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 5326/10000, Train Loss: 0.6157, Train Acc: 67.63%, Test Loss: 0.5556, Test Acc: 74.14%\n",
            "Epoch 5327/10000, Train Loss: 0.6093, Train Acc: 64.16%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 5328/10000, Train Loss: 0.6023, Train Acc: 65.32%, Test Loss: 0.5576, Test Acc: 74.14%\n",
            "Epoch 5329/10000, Train Loss: 0.6017, Train Acc: 69.36%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 5330/10000, Train Loss: 0.6290, Train Acc: 64.45%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 5331/10000, Train Loss: 0.6446, Train Acc: 61.27%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 5332/10000, Train Loss: 0.6015, Train Acc: 65.61%, Test Loss: 0.5610, Test Acc: 68.97%\n",
            "Epoch 5333/10000, Train Loss: 0.6180, Train Acc: 61.27%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 5334/10000, Train Loss: 0.6277, Train Acc: 62.72%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 5335/10000, Train Loss: 0.6180, Train Acc: 64.45%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 5336/10000, Train Loss: 0.5945, Train Acc: 62.43%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 5337/10000, Train Loss: 0.6220, Train Acc: 65.90%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5338/10000, Train Loss: 0.6096, Train Acc: 66.47%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 5339/10000, Train Loss: 0.6315, Train Acc: 62.72%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 5340/10000, Train Loss: 0.6373, Train Acc: 62.72%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 5341/10000, Train Loss: 0.5907, Train Acc: 67.63%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 5342/10000, Train Loss: 0.6062, Train Acc: 63.01%, Test Loss: 0.5527, Test Acc: 74.14%\n",
            "Epoch 5343/10000, Train Loss: 0.5984, Train Acc: 65.61%, Test Loss: 0.5544, Test Acc: 74.14%\n",
            "Epoch 5344/10000, Train Loss: 0.6401, Train Acc: 65.61%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 5345/10000, Train Loss: 0.6259, Train Acc: 60.12%, Test Loss: 0.5528, Test Acc: 74.14%\n",
            "Epoch 5346/10000, Train Loss: 0.6206, Train Acc: 65.61%, Test Loss: 0.5512, Test Acc: 74.14%\n",
            "Epoch 5347/10000, Train Loss: 0.6211, Train Acc: 63.87%, Test Loss: 0.5483, Test Acc: 72.41%\n",
            "Epoch 5348/10000, Train Loss: 0.6041, Train Acc: 64.74%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 5349/10000, Train Loss: 0.6238, Train Acc: 63.29%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 5350/10000, Train Loss: 0.6276, Train Acc: 61.56%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 5351/10000, Train Loss: 0.5959, Train Acc: 65.61%, Test Loss: 0.5591, Test Acc: 72.41%\n",
            "Epoch 5352/10000, Train Loss: 0.6147, Train Acc: 65.90%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 5353/10000, Train Loss: 0.6238, Train Acc: 66.18%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 5354/10000, Train Loss: 0.6152, Train Acc: 62.72%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 5355/10000, Train Loss: 0.6059, Train Acc: 65.90%, Test Loss: 0.5520, Test Acc: 74.14%\n",
            "Epoch 5356/10000, Train Loss: 0.6385, Train Acc: 63.58%, Test Loss: 0.5498, Test Acc: 68.97%\n",
            "Epoch 5357/10000, Train Loss: 0.6270, Train Acc: 60.98%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 5358/10000, Train Loss: 0.6389, Train Acc: 61.27%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 5359/10000, Train Loss: 0.6289, Train Acc: 63.58%, Test Loss: 0.5604, Test Acc: 70.69%\n",
            "Epoch 5360/10000, Train Loss: 0.6156, Train Acc: 65.61%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 5361/10000, Train Loss: 0.6262, Train Acc: 64.45%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 5362/10000, Train Loss: 0.6024, Train Acc: 64.45%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 5363/10000, Train Loss: 0.6215, Train Acc: 64.45%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 5364/10000, Train Loss: 0.6216, Train Acc: 64.16%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 5365/10000, Train Loss: 0.6043, Train Acc: 66.76%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 5366/10000, Train Loss: 0.6254, Train Acc: 63.29%, Test Loss: 0.5584, Test Acc: 72.41%\n",
            "Epoch 5367/10000, Train Loss: 0.6162, Train Acc: 63.58%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 5368/10000, Train Loss: 0.6108, Train Acc: 66.18%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5369/10000, Train Loss: 0.5846, Train Acc: 70.52%, Test Loss: 0.5561, Test Acc: 75.86%\n",
            "Epoch 5370/10000, Train Loss: 0.6205, Train Acc: 63.01%, Test Loss: 0.5565, Test Acc: 75.86%\n",
            "Epoch 5371/10000, Train Loss: 0.6079, Train Acc: 65.32%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 5372/10000, Train Loss: 0.6196, Train Acc: 65.32%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 5373/10000, Train Loss: 0.6111, Train Acc: 67.92%, Test Loss: 0.5506, Test Acc: 74.14%\n",
            "Epoch 5374/10000, Train Loss: 0.6244, Train Acc: 64.74%, Test Loss: 0.5498, Test Acc: 74.14%\n",
            "Epoch 5375/10000, Train Loss: 0.6158, Train Acc: 64.74%, Test Loss: 0.5481, Test Acc: 72.41%\n",
            "Epoch 5376/10000, Train Loss: 0.6051, Train Acc: 67.34%, Test Loss: 0.5499, Test Acc: 74.14%\n",
            "Epoch 5377/10000, Train Loss: 0.6152, Train Acc: 67.05%, Test Loss: 0.5516, Test Acc: 67.24%\n",
            "Epoch 5378/10000, Train Loss: 0.6066, Train Acc: 64.45%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 5379/10000, Train Loss: 0.6099, Train Acc: 69.08%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 5380/10000, Train Loss: 0.6201, Train Acc: 66.76%, Test Loss: 0.5527, Test Acc: 70.69%\n",
            "Epoch 5381/10000, Train Loss: 0.6141, Train Acc: 61.85%, Test Loss: 0.5551, Test Acc: 70.69%\n",
            "Epoch 5382/10000, Train Loss: 0.6027, Train Acc: 62.72%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 5383/10000, Train Loss: 0.5995, Train Acc: 63.58%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 5384/10000, Train Loss: 0.6313, Train Acc: 65.61%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 5385/10000, Train Loss: 0.6195, Train Acc: 65.03%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 5386/10000, Train Loss: 0.6236, Train Acc: 63.29%, Test Loss: 0.5521, Test Acc: 68.97%\n",
            "Epoch 5387/10000, Train Loss: 0.6387, Train Acc: 65.32%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 5388/10000, Train Loss: 0.6250, Train Acc: 64.74%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 5389/10000, Train Loss: 0.6045, Train Acc: 65.03%, Test Loss: 0.5592, Test Acc: 70.69%\n",
            "Epoch 5390/10000, Train Loss: 0.6136, Train Acc: 63.58%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 5391/10000, Train Loss: 0.5970, Train Acc: 69.94%, Test Loss: 0.5580, Test Acc: 70.69%\n",
            "Epoch 5392/10000, Train Loss: 0.6245, Train Acc: 64.74%, Test Loss: 0.5606, Test Acc: 68.97%\n",
            "Epoch 5393/10000, Train Loss: 0.6062, Train Acc: 66.18%, Test Loss: 0.5597, Test Acc: 70.69%\n",
            "Epoch 5394/10000, Train Loss: 0.6290, Train Acc: 65.61%, Test Loss: 0.5542, Test Acc: 75.86%\n",
            "Epoch 5395/10000, Train Loss: 0.5836, Train Acc: 68.21%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 5396/10000, Train Loss: 0.6140, Train Acc: 65.90%, Test Loss: 0.5524, Test Acc: 74.14%\n",
            "Epoch 5397/10000, Train Loss: 0.6530, Train Acc: 63.87%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 5398/10000, Train Loss: 0.6074, Train Acc: 64.74%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 5399/10000, Train Loss: 0.5975, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 74.14%\n",
            "Epoch 5400/10000, Train Loss: 0.6167, Train Acc: 64.45%, Test Loss: 0.5496, Test Acc: 74.14%\n",
            "Epoch 5401/10000, Train Loss: 0.5976, Train Acc: 66.18%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 5402/10000, Train Loss: 0.6019, Train Acc: 63.29%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 5403/10000, Train Loss: 0.6031, Train Acc: 66.47%, Test Loss: 0.5539, Test Acc: 67.24%\n",
            "Epoch 5404/10000, Train Loss: 0.6102, Train Acc: 63.01%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 5405/10000, Train Loss: 0.6170, Train Acc: 62.14%, Test Loss: 0.5495, Test Acc: 70.69%\n",
            "Epoch 5406/10000, Train Loss: 0.6175, Train Acc: 64.45%, Test Loss: 0.5513, Test Acc: 70.69%\n",
            "Epoch 5407/10000, Train Loss: 0.6024, Train Acc: 64.16%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 5408/10000, Train Loss: 0.6208, Train Acc: 63.87%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 5409/10000, Train Loss: 0.6128, Train Acc: 65.32%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 5410/10000, Train Loss: 0.6135, Train Acc: 65.61%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 5411/10000, Train Loss: 0.6106, Train Acc: 65.90%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 5412/10000, Train Loss: 0.6020, Train Acc: 62.14%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 5413/10000, Train Loss: 0.5870, Train Acc: 67.34%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 5414/10000, Train Loss: 0.6209, Train Acc: 62.43%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 5415/10000, Train Loss: 0.6289, Train Acc: 62.43%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 5416/10000, Train Loss: 0.6082, Train Acc: 65.32%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 5417/10000, Train Loss: 0.5977, Train Acc: 67.05%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 5418/10000, Train Loss: 0.5941, Train Acc: 68.50%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 5419/10000, Train Loss: 0.6352, Train Acc: 62.72%, Test Loss: 0.5494, Test Acc: 68.97%\n",
            "Epoch 5420/10000, Train Loss: 0.6132, Train Acc: 64.16%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 5421/10000, Train Loss: 0.6337, Train Acc: 64.45%, Test Loss: 0.5496, Test Acc: 68.97%\n",
            "Epoch 5422/10000, Train Loss: 0.6141, Train Acc: 65.90%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 5423/10000, Train Loss: 0.6243, Train Acc: 65.03%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 5424/10000, Train Loss: 0.6072, Train Acc: 65.61%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 5425/10000, Train Loss: 0.5952, Train Acc: 66.47%, Test Loss: 0.5513, Test Acc: 74.14%\n",
            "Epoch 5426/10000, Train Loss: 0.6103, Train Acc: 62.14%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 5427/10000, Train Loss: 0.6210, Train Acc: 67.05%, Test Loss: 0.5521, Test Acc: 72.41%\n",
            "Epoch 5428/10000, Train Loss: 0.6023, Train Acc: 64.16%, Test Loss: 0.5503, Test Acc: 74.14%\n",
            "Epoch 5429/10000, Train Loss: 0.6131, Train Acc: 66.76%, Test Loss: 0.5491, Test Acc: 72.41%\n",
            "Epoch 5430/10000, Train Loss: 0.6307, Train Acc: 65.90%, Test Loss: 0.5466, Test Acc: 68.97%\n",
            "Epoch 5431/10000, Train Loss: 0.6189, Train Acc: 66.76%, Test Loss: 0.5481, Test Acc: 68.97%\n",
            "Epoch 5432/10000, Train Loss: 0.6041, Train Acc: 64.74%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 5433/10000, Train Loss: 0.6126, Train Acc: 64.16%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 5434/10000, Train Loss: 0.6333, Train Acc: 60.12%, Test Loss: 0.5599, Test Acc: 68.97%\n",
            "Epoch 5435/10000, Train Loss: 0.6209, Train Acc: 63.87%, Test Loss: 0.5602, Test Acc: 68.97%\n",
            "Epoch 5436/10000, Train Loss: 0.6097, Train Acc: 63.87%, Test Loss: 0.5668, Test Acc: 70.69%\n",
            "Epoch 5437/10000, Train Loss: 0.6137, Train Acc: 63.58%, Test Loss: 0.5621, Test Acc: 68.97%\n",
            "Epoch 5438/10000, Train Loss: 0.6160, Train Acc: 63.87%, Test Loss: 0.5581, Test Acc: 70.69%\n",
            "Epoch 5439/10000, Train Loss: 0.6043, Train Acc: 65.32%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 5440/10000, Train Loss: 0.5993, Train Acc: 68.50%, Test Loss: 0.5517, Test Acc: 75.86%\n",
            "Epoch 5441/10000, Train Loss: 0.6300, Train Acc: 65.90%, Test Loss: 0.5532, Test Acc: 74.14%\n",
            "Epoch 5442/10000, Train Loss: 0.6131, Train Acc: 65.61%, Test Loss: 0.5555, Test Acc: 75.86%\n",
            "Epoch 5443/10000, Train Loss: 0.6481, Train Acc: 63.29%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 5444/10000, Train Loss: 0.6099, Train Acc: 66.18%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 5445/10000, Train Loss: 0.6118, Train Acc: 64.16%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 5446/10000, Train Loss: 0.6013, Train Acc: 68.21%, Test Loss: 0.5533, Test Acc: 74.14%\n",
            "Epoch 5447/10000, Train Loss: 0.6129, Train Acc: 66.18%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 5448/10000, Train Loss: 0.5910, Train Acc: 66.47%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 5449/10000, Train Loss: 0.6060, Train Acc: 67.05%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 5450/10000, Train Loss: 0.6207, Train Acc: 60.69%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 5451/10000, Train Loss: 0.6124, Train Acc: 65.90%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 5452/10000, Train Loss: 0.6431, Train Acc: 64.45%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 5453/10000, Train Loss: 0.6074, Train Acc: 62.43%, Test Loss: 0.5513, Test Acc: 72.41%\n",
            "Epoch 5454/10000, Train Loss: 0.5957, Train Acc: 67.34%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 5455/10000, Train Loss: 0.6231, Train Acc: 65.03%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5456/10000, Train Loss: 0.6094, Train Acc: 67.34%, Test Loss: 0.5553, Test Acc: 74.14%\n",
            "Epoch 5457/10000, Train Loss: 0.5972, Train Acc: 65.32%, Test Loss: 0.5534, Test Acc: 74.14%\n",
            "Epoch 5458/10000, Train Loss: 0.5916, Train Acc: 64.16%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 5459/10000, Train Loss: 0.6200, Train Acc: 65.32%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 5460/10000, Train Loss: 0.6311, Train Acc: 63.01%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 5461/10000, Train Loss: 0.6104, Train Acc: 65.61%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 5462/10000, Train Loss: 0.6054, Train Acc: 65.61%, Test Loss: 0.5551, Test Acc: 70.69%\n",
            "Epoch 5463/10000, Train Loss: 0.6041, Train Acc: 64.74%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 5464/10000, Train Loss: 0.6163, Train Acc: 61.85%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 5465/10000, Train Loss: 0.6354, Train Acc: 63.01%, Test Loss: 0.5522, Test Acc: 75.86%\n",
            "Epoch 5466/10000, Train Loss: 0.6146, Train Acc: 63.87%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 5467/10000, Train Loss: 0.6167, Train Acc: 63.29%, Test Loss: 0.5551, Test Acc: 70.69%\n",
            "Epoch 5468/10000, Train Loss: 0.6120, Train Acc: 63.58%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 5469/10000, Train Loss: 0.6126, Train Acc: 65.32%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5470/10000, Train Loss: 0.5960, Train Acc: 66.18%, Test Loss: 0.5578, Test Acc: 70.69%\n",
            "Epoch 5471/10000, Train Loss: 0.6113, Train Acc: 64.16%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5472/10000, Train Loss: 0.6309, Train Acc: 62.43%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 5473/10000, Train Loss: 0.6528, Train Acc: 65.61%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 5474/10000, Train Loss: 0.6268, Train Acc: 63.29%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 5475/10000, Train Loss: 0.6129, Train Acc: 65.90%, Test Loss: 0.5493, Test Acc: 75.86%\n",
            "Epoch 5476/10000, Train Loss: 0.6084, Train Acc: 68.50%, Test Loss: 0.5485, Test Acc: 68.97%\n",
            "Epoch 5477/10000, Train Loss: 0.6224, Train Acc: 69.65%, Test Loss: 0.5479, Test Acc: 75.86%\n",
            "Epoch 5478/10000, Train Loss: 0.6133, Train Acc: 66.47%, Test Loss: 0.5484, Test Acc: 70.69%\n",
            "Epoch 5479/10000, Train Loss: 0.6623, Train Acc: 63.58%, Test Loss: 0.5488, Test Acc: 68.97%\n",
            "Epoch 5480/10000, Train Loss: 0.6230, Train Acc: 63.87%, Test Loss: 0.5489, Test Acc: 68.97%\n",
            "Epoch 5481/10000, Train Loss: 0.6361, Train Acc: 63.87%, Test Loss: 0.5494, Test Acc: 68.97%\n",
            "Epoch 5482/10000, Train Loss: 0.6107, Train Acc: 64.45%, Test Loss: 0.5508, Test Acc: 68.97%\n",
            "Epoch 5483/10000, Train Loss: 0.6026, Train Acc: 67.05%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 5484/10000, Train Loss: 0.6452, Train Acc: 62.14%, Test Loss: 0.5525, Test Acc: 70.69%\n",
            "Epoch 5485/10000, Train Loss: 0.6161, Train Acc: 64.74%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 5486/10000, Train Loss: 0.6208, Train Acc: 65.32%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 5487/10000, Train Loss: 0.6081, Train Acc: 63.58%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5488/10000, Train Loss: 0.6122, Train Acc: 62.72%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 5489/10000, Train Loss: 0.6181, Train Acc: 63.58%, Test Loss: 0.5611, Test Acc: 72.41%\n",
            "Epoch 5490/10000, Train Loss: 0.6385, Train Acc: 65.32%, Test Loss: 0.5609, Test Acc: 70.69%\n",
            "Epoch 5491/10000, Train Loss: 0.6339, Train Acc: 64.74%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 5492/10000, Train Loss: 0.6144, Train Acc: 63.87%, Test Loss: 0.5555, Test Acc: 75.86%\n",
            "Epoch 5493/10000, Train Loss: 0.6373, Train Acc: 64.16%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 5494/10000, Train Loss: 0.6318, Train Acc: 66.47%, Test Loss: 0.5504, Test Acc: 72.41%\n",
            "Epoch 5495/10000, Train Loss: 0.6265, Train Acc: 60.98%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 5496/10000, Train Loss: 0.6200, Train Acc: 65.03%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 5497/10000, Train Loss: 0.6254, Train Acc: 64.74%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 5498/10000, Train Loss: 0.6024, Train Acc: 66.76%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 5499/10000, Train Loss: 0.5913, Train Acc: 67.34%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 5500/10000, Train Loss: 0.6077, Train Acc: 63.87%, Test Loss: 0.5479, Test Acc: 68.97%\n",
            "Epoch 5501/10000, Train Loss: 0.6134, Train Acc: 69.08%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 5502/10000, Train Loss: 0.6083, Train Acc: 62.43%, Test Loss: 0.5506, Test Acc: 68.97%\n",
            "Epoch 5503/10000, Train Loss: 0.6394, Train Acc: 63.87%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 5504/10000, Train Loss: 0.6324, Train Acc: 64.45%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 5505/10000, Train Loss: 0.6345, Train Acc: 63.29%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5506/10000, Train Loss: 0.5758, Train Acc: 65.03%, Test Loss: 0.5586, Test Acc: 70.69%\n",
            "Epoch 5507/10000, Train Loss: 0.6280, Train Acc: 62.14%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 5508/10000, Train Loss: 0.6166, Train Acc: 64.16%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 5509/10000, Train Loss: 0.5943, Train Acc: 67.34%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 5510/10000, Train Loss: 0.6079, Train Acc: 64.16%, Test Loss: 0.5545, Test Acc: 74.14%\n",
            "Epoch 5511/10000, Train Loss: 0.6081, Train Acc: 64.16%, Test Loss: 0.5524, Test Acc: 74.14%\n",
            "Epoch 5512/10000, Train Loss: 0.6349, Train Acc: 61.85%, Test Loss: 0.5511, Test Acc: 75.86%\n",
            "Epoch 5513/10000, Train Loss: 0.6175, Train Acc: 64.74%, Test Loss: 0.5519, Test Acc: 75.86%\n",
            "Epoch 5514/10000, Train Loss: 0.6469, Train Acc: 63.87%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 5515/10000, Train Loss: 0.6073, Train Acc: 66.18%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 5516/10000, Train Loss: 0.6083, Train Acc: 68.79%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 5517/10000, Train Loss: 0.6147, Train Acc: 68.50%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 5518/10000, Train Loss: 0.6147, Train Acc: 68.79%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 5519/10000, Train Loss: 0.6341, Train Acc: 65.03%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 5520/10000, Train Loss: 0.6029, Train Acc: 64.16%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 5521/10000, Train Loss: 0.6284, Train Acc: 62.72%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 5522/10000, Train Loss: 0.6169, Train Acc: 62.72%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 5523/10000, Train Loss: 0.6182, Train Acc: 64.45%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5524/10000, Train Loss: 0.6158, Train Acc: 65.03%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 5525/10000, Train Loss: 0.6335, Train Acc: 66.47%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 5526/10000, Train Loss: 0.5972, Train Acc: 65.90%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 5527/10000, Train Loss: 0.6390, Train Acc: 64.74%, Test Loss: 0.5527, Test Acc: 75.86%\n",
            "Epoch 5528/10000, Train Loss: 0.6369, Train Acc: 63.58%, Test Loss: 0.5556, Test Acc: 72.41%\n",
            "Epoch 5529/10000, Train Loss: 0.6074, Train Acc: 64.45%, Test Loss: 0.5546, Test Acc: 74.14%\n",
            "Epoch 5530/10000, Train Loss: 0.6169, Train Acc: 63.87%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 5531/10000, Train Loss: 0.6616, Train Acc: 60.69%, Test Loss: 0.5498, Test Acc: 68.97%\n",
            "Epoch 5532/10000, Train Loss: 0.6166, Train Acc: 65.61%, Test Loss: 0.5511, Test Acc: 72.41%\n",
            "Epoch 5533/10000, Train Loss: 0.6130, Train Acc: 62.14%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 5534/10000, Train Loss: 0.6255, Train Acc: 64.74%, Test Loss: 0.5499, Test Acc: 68.97%\n",
            "Epoch 5535/10000, Train Loss: 0.6044, Train Acc: 65.61%, Test Loss: 0.5487, Test Acc: 68.97%\n",
            "Epoch 5536/10000, Train Loss: 0.6149, Train Acc: 64.45%, Test Loss: 0.5480, Test Acc: 72.41%\n",
            "Epoch 5537/10000, Train Loss: 0.6062, Train Acc: 62.14%, Test Loss: 0.5482, Test Acc: 74.14%\n",
            "Epoch 5538/10000, Train Loss: 0.6223, Train Acc: 63.01%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 5539/10000, Train Loss: 0.6008, Train Acc: 63.87%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 5540/10000, Train Loss: 0.5867, Train Acc: 66.47%, Test Loss: 0.5581, Test Acc: 70.69%\n",
            "Epoch 5541/10000, Train Loss: 0.6335, Train Acc: 66.47%, Test Loss: 0.5591, Test Acc: 70.69%\n",
            "Epoch 5542/10000, Train Loss: 0.5988, Train Acc: 66.47%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 5543/10000, Train Loss: 0.5935, Train Acc: 63.01%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 5544/10000, Train Loss: 0.6178, Train Acc: 66.76%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 5545/10000, Train Loss: 0.6499, Train Acc: 61.85%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 5546/10000, Train Loss: 0.6084, Train Acc: 65.61%, Test Loss: 0.5585, Test Acc: 70.69%\n",
            "Epoch 5547/10000, Train Loss: 0.6289, Train Acc: 65.61%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 5548/10000, Train Loss: 0.6439, Train Acc: 63.01%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 5549/10000, Train Loss: 0.6246, Train Acc: 63.29%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 5550/10000, Train Loss: 0.6255, Train Acc: 63.58%, Test Loss: 0.5580, Test Acc: 70.69%\n",
            "Epoch 5551/10000, Train Loss: 0.6180, Train Acc: 67.34%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 5552/10000, Train Loss: 0.6330, Train Acc: 62.43%, Test Loss: 0.5533, Test Acc: 75.86%\n",
            "Epoch 5553/10000, Train Loss: 0.6210, Train Acc: 64.74%, Test Loss: 0.5521, Test Acc: 75.86%\n",
            "Epoch 5554/10000, Train Loss: 0.6158, Train Acc: 63.58%, Test Loss: 0.5495, Test Acc: 72.41%\n",
            "Epoch 5555/10000, Train Loss: 0.5983, Train Acc: 63.87%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 5556/10000, Train Loss: 0.6349, Train Acc: 63.58%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 5557/10000, Train Loss: 0.6154, Train Acc: 68.50%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5558/10000, Train Loss: 0.6351, Train Acc: 63.01%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 5559/10000, Train Loss: 0.6218, Train Acc: 63.01%, Test Loss: 0.5505, Test Acc: 72.41%\n",
            "Epoch 5560/10000, Train Loss: 0.6459, Train Acc: 62.43%, Test Loss: 0.5501, Test Acc: 72.41%\n",
            "Epoch 5561/10000, Train Loss: 0.6078, Train Acc: 68.21%, Test Loss: 0.5506, Test Acc: 68.97%\n",
            "Epoch 5562/10000, Train Loss: 0.5990, Train Acc: 64.45%, Test Loss: 0.5514, Test Acc: 72.41%\n",
            "Epoch 5563/10000, Train Loss: 0.6123, Train Acc: 63.87%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 5564/10000, Train Loss: 0.6353, Train Acc: 63.29%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 5565/10000, Train Loss: 0.6148, Train Acc: 67.05%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 5566/10000, Train Loss: 0.6255, Train Acc: 65.32%, Test Loss: 0.5511, Test Acc: 70.69%\n",
            "Epoch 5567/10000, Train Loss: 0.6354, Train Acc: 61.27%, Test Loss: 0.5503, Test Acc: 70.69%\n",
            "Epoch 5568/10000, Train Loss: 0.6281, Train Acc: 69.08%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 5569/10000, Train Loss: 0.6262, Train Acc: 63.29%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 5570/10000, Train Loss: 0.5994, Train Acc: 67.92%, Test Loss: 0.5589, Test Acc: 70.69%\n",
            "Epoch 5571/10000, Train Loss: 0.6229, Train Acc: 63.01%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 5572/10000, Train Loss: 0.6149, Train Acc: 66.18%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 5573/10000, Train Loss: 0.5940, Train Acc: 68.50%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 5574/10000, Train Loss: 0.6255, Train Acc: 63.87%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 5575/10000, Train Loss: 0.6172, Train Acc: 63.29%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 5576/10000, Train Loss: 0.6119, Train Acc: 64.45%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 5577/10000, Train Loss: 0.5980, Train Acc: 65.03%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 5578/10000, Train Loss: 0.6435, Train Acc: 63.58%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 5579/10000, Train Loss: 0.6383, Train Acc: 63.87%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 5580/10000, Train Loss: 0.6332, Train Acc: 63.58%, Test Loss: 0.5489, Test Acc: 68.97%\n",
            "Epoch 5581/10000, Train Loss: 0.6113, Train Acc: 65.03%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 5582/10000, Train Loss: 0.6202, Train Acc: 64.74%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 5583/10000, Train Loss: 0.6235, Train Acc: 65.32%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 5584/10000, Train Loss: 0.6276, Train Acc: 65.03%, Test Loss: 0.5589, Test Acc: 70.69%\n",
            "Epoch 5585/10000, Train Loss: 0.6373, Train Acc: 63.58%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 5586/10000, Train Loss: 0.6183, Train Acc: 63.29%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 5587/10000, Train Loss: 0.6226, Train Acc: 65.32%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 5588/10000, Train Loss: 0.6239, Train Acc: 63.87%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 5589/10000, Train Loss: 0.6184, Train Acc: 66.47%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 5590/10000, Train Loss: 0.6344, Train Acc: 62.43%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 5591/10000, Train Loss: 0.6305, Train Acc: 63.29%, Test Loss: 0.5492, Test Acc: 68.97%\n",
            "Epoch 5592/10000, Train Loss: 0.6093, Train Acc: 62.14%, Test Loss: 0.5505, Test Acc: 74.14%\n",
            "Epoch 5593/10000, Train Loss: 0.6081, Train Acc: 66.47%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 5594/10000, Train Loss: 0.6136, Train Acc: 64.45%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 5595/10000, Train Loss: 0.6181, Train Acc: 65.90%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 5596/10000, Train Loss: 0.6002, Train Acc: 66.76%, Test Loss: 0.5572, Test Acc: 72.41%\n",
            "Epoch 5597/10000, Train Loss: 0.6384, Train Acc: 64.74%, Test Loss: 0.5597, Test Acc: 70.69%\n",
            "Epoch 5598/10000, Train Loss: 0.6505, Train Acc: 64.16%, Test Loss: 0.5616, Test Acc: 70.69%\n",
            "Epoch 5599/10000, Train Loss: 0.6346, Train Acc: 67.63%, Test Loss: 0.5589, Test Acc: 70.69%\n",
            "Epoch 5600/10000, Train Loss: 0.5961, Train Acc: 67.05%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5601/10000, Train Loss: 0.6086, Train Acc: 67.05%, Test Loss: 0.5506, Test Acc: 68.97%\n",
            "Epoch 5602/10000, Train Loss: 0.6290, Train Acc: 64.45%, Test Loss: 0.5497, Test Acc: 74.14%\n",
            "Epoch 5603/10000, Train Loss: 0.6232, Train Acc: 62.43%, Test Loss: 0.5520, Test Acc: 74.14%\n",
            "Epoch 5604/10000, Train Loss: 0.6095, Train Acc: 66.76%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 5605/10000, Train Loss: 0.5953, Train Acc: 66.76%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 5606/10000, Train Loss: 0.6200, Train Acc: 65.90%, Test Loss: 0.5530, Test Acc: 70.69%\n",
            "Epoch 5607/10000, Train Loss: 0.5992, Train Acc: 66.76%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 5608/10000, Train Loss: 0.6488, Train Acc: 64.16%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 5609/10000, Train Loss: 0.6325, Train Acc: 65.03%, Test Loss: 0.5487, Test Acc: 68.97%\n",
            "Epoch 5610/10000, Train Loss: 0.6359, Train Acc: 60.98%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 5611/10000, Train Loss: 0.6298, Train Acc: 65.03%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 5612/10000, Train Loss: 0.6112, Train Acc: 64.74%, Test Loss: 0.5519, Test Acc: 70.69%\n",
            "Epoch 5613/10000, Train Loss: 0.6133, Train Acc: 64.16%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 5614/10000, Train Loss: 0.5950, Train Acc: 65.03%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 5615/10000, Train Loss: 0.6378, Train Acc: 63.58%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5616/10000, Train Loss: 0.6624, Train Acc: 58.67%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 5617/10000, Train Loss: 0.6116, Train Acc: 62.72%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 5618/10000, Train Loss: 0.6290, Train Acc: 62.72%, Test Loss: 0.5588, Test Acc: 72.41%\n",
            "Epoch 5619/10000, Train Loss: 0.6092, Train Acc: 65.03%, Test Loss: 0.5591, Test Acc: 72.41%\n",
            "Epoch 5620/10000, Train Loss: 0.6164, Train Acc: 62.72%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 5621/10000, Train Loss: 0.6114, Train Acc: 66.47%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 5622/10000, Train Loss: 0.6282, Train Acc: 65.03%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 5623/10000, Train Loss: 0.6142, Train Acc: 64.45%, Test Loss: 0.5549, Test Acc: 75.86%\n",
            "Epoch 5624/10000, Train Loss: 0.6299, Train Acc: 64.45%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 5625/10000, Train Loss: 0.6259, Train Acc: 66.76%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 5626/10000, Train Loss: 0.6266, Train Acc: 63.01%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 5627/10000, Train Loss: 0.6124, Train Acc: 62.14%, Test Loss: 0.5532, Test Acc: 74.14%\n",
            "Epoch 5628/10000, Train Loss: 0.5987, Train Acc: 69.36%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 5629/10000, Train Loss: 0.5961, Train Acc: 65.03%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 5630/10000, Train Loss: 0.6295, Train Acc: 64.74%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 5631/10000, Train Loss: 0.6179, Train Acc: 64.16%, Test Loss: 0.5585, Test Acc: 70.69%\n",
            "Epoch 5632/10000, Train Loss: 0.6017, Train Acc: 66.76%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 5633/10000, Train Loss: 0.6289, Train Acc: 61.85%, Test Loss: 0.5573, Test Acc: 72.41%\n",
            "Epoch 5634/10000, Train Loss: 0.6048, Train Acc: 64.74%, Test Loss: 0.5574, Test Acc: 72.41%\n",
            "Epoch 5635/10000, Train Loss: 0.6340, Train Acc: 59.54%, Test Loss: 0.5573, Test Acc: 72.41%\n",
            "Epoch 5636/10000, Train Loss: 0.6168, Train Acc: 63.29%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 5637/10000, Train Loss: 0.6057, Train Acc: 66.18%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 5638/10000, Train Loss: 0.6144, Train Acc: 65.03%, Test Loss: 0.5526, Test Acc: 70.69%\n",
            "Epoch 5639/10000, Train Loss: 0.6317, Train Acc: 62.14%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 5640/10000, Train Loss: 0.6168, Train Acc: 64.45%, Test Loss: 0.5542, Test Acc: 70.69%\n",
            "Epoch 5641/10000, Train Loss: 0.6003, Train Acc: 63.87%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 5642/10000, Train Loss: 0.6169, Train Acc: 64.16%, Test Loss: 0.5528, Test Acc: 75.86%\n",
            "Epoch 5643/10000, Train Loss: 0.6068, Train Acc: 67.63%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 5644/10000, Train Loss: 0.6222, Train Acc: 63.01%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 5645/10000, Train Loss: 0.6364, Train Acc: 63.58%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 5646/10000, Train Loss: 0.6182, Train Acc: 60.40%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5647/10000, Train Loss: 0.6162, Train Acc: 63.87%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 5648/10000, Train Loss: 0.6097, Train Acc: 66.18%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 5649/10000, Train Loss: 0.6097, Train Acc: 62.43%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 5650/10000, Train Loss: 0.6102, Train Acc: 63.01%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 5651/10000, Train Loss: 0.6340, Train Acc: 62.43%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 5652/10000, Train Loss: 0.6286, Train Acc: 67.63%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 5653/10000, Train Loss: 0.6098, Train Acc: 66.47%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5654/10000, Train Loss: 0.6095, Train Acc: 64.74%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 5655/10000, Train Loss: 0.6198, Train Acc: 65.32%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 5656/10000, Train Loss: 0.6064, Train Acc: 63.87%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 5657/10000, Train Loss: 0.6360, Train Acc: 61.85%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 5658/10000, Train Loss: 0.5930, Train Acc: 65.90%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 5659/10000, Train Loss: 0.6223, Train Acc: 63.58%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 5660/10000, Train Loss: 0.6086, Train Acc: 63.87%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 5661/10000, Train Loss: 0.6304, Train Acc: 65.03%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 5662/10000, Train Loss: 0.6073, Train Acc: 67.05%, Test Loss: 0.5515, Test Acc: 75.86%\n",
            "Epoch 5663/10000, Train Loss: 0.6186, Train Acc: 66.47%, Test Loss: 0.5507, Test Acc: 74.14%\n",
            "Epoch 5664/10000, Train Loss: 0.6056, Train Acc: 66.76%, Test Loss: 0.5482, Test Acc: 72.41%\n",
            "Epoch 5665/10000, Train Loss: 0.6228, Train Acc: 63.58%, Test Loss: 0.5492, Test Acc: 74.14%\n",
            "Epoch 5666/10000, Train Loss: 0.6174, Train Acc: 65.61%, Test Loss: 0.5468, Test Acc: 74.14%\n",
            "Epoch 5667/10000, Train Loss: 0.6154, Train Acc: 63.01%, Test Loss: 0.5458, Test Acc: 72.41%\n",
            "Epoch 5668/10000, Train Loss: 0.6415, Train Acc: 64.16%, Test Loss: 0.5483, Test Acc: 68.97%\n",
            "Epoch 5669/10000, Train Loss: 0.5941, Train Acc: 64.45%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 5670/10000, Train Loss: 0.6290, Train Acc: 62.43%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 5671/10000, Train Loss: 0.6261, Train Acc: 63.58%, Test Loss: 0.5551, Test Acc: 74.14%\n",
            "Epoch 5672/10000, Train Loss: 0.6157, Train Acc: 63.58%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 5673/10000, Train Loss: 0.6231, Train Acc: 63.58%, Test Loss: 0.5654, Test Acc: 72.41%\n",
            "Epoch 5674/10000, Train Loss: 0.6195, Train Acc: 65.03%, Test Loss: 0.5610, Test Acc: 72.41%\n",
            "Epoch 5675/10000, Train Loss: 0.6339, Train Acc: 63.29%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 5676/10000, Train Loss: 0.6084, Train Acc: 63.58%, Test Loss: 0.5612, Test Acc: 68.97%\n",
            "Epoch 5677/10000, Train Loss: 0.6303, Train Acc: 61.85%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 5678/10000, Train Loss: 0.6205, Train Acc: 64.45%, Test Loss: 0.5536, Test Acc: 70.69%\n",
            "Epoch 5679/10000, Train Loss: 0.6129, Train Acc: 67.05%, Test Loss: 0.5537, Test Acc: 74.14%\n",
            "Epoch 5680/10000, Train Loss: 0.6044, Train Acc: 63.58%, Test Loss: 0.5524, Test Acc: 74.14%\n",
            "Epoch 5681/10000, Train Loss: 0.6016, Train Acc: 63.01%, Test Loss: 0.5529, Test Acc: 74.14%\n",
            "Epoch 5682/10000, Train Loss: 0.6228, Train Acc: 63.58%, Test Loss: 0.5527, Test Acc: 74.14%\n",
            "Epoch 5683/10000, Train Loss: 0.6190, Train Acc: 65.90%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 5684/10000, Train Loss: 0.5869, Train Acc: 69.08%, Test Loss: 0.5530, Test Acc: 75.86%\n",
            "Epoch 5685/10000, Train Loss: 0.6096, Train Acc: 68.21%, Test Loss: 0.5527, Test Acc: 70.69%\n",
            "Epoch 5686/10000, Train Loss: 0.6199, Train Acc: 61.27%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 5687/10000, Train Loss: 0.6214, Train Acc: 64.16%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 5688/10000, Train Loss: 0.6267, Train Acc: 65.03%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 5689/10000, Train Loss: 0.6270, Train Acc: 62.43%, Test Loss: 0.5508, Test Acc: 68.97%\n",
            "Epoch 5690/10000, Train Loss: 0.6239, Train Acc: 67.63%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 5691/10000, Train Loss: 0.6313, Train Acc: 64.45%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 5692/10000, Train Loss: 0.6025, Train Acc: 67.05%, Test Loss: 0.5628, Test Acc: 72.41%\n",
            "Epoch 5693/10000, Train Loss: 0.6227, Train Acc: 65.03%, Test Loss: 0.5643, Test Acc: 68.97%\n",
            "Epoch 5694/10000, Train Loss: 0.5919, Train Acc: 66.18%, Test Loss: 0.5649, Test Acc: 68.97%\n",
            "Epoch 5695/10000, Train Loss: 0.6301, Train Acc: 62.72%, Test Loss: 0.5628, Test Acc: 70.69%\n",
            "Epoch 5696/10000, Train Loss: 0.6369, Train Acc: 61.85%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 5697/10000, Train Loss: 0.6238, Train Acc: 64.45%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 5698/10000, Train Loss: 0.6270, Train Acc: 64.45%, Test Loss: 0.5501, Test Acc: 74.14%\n",
            "Epoch 5699/10000, Train Loss: 0.6172, Train Acc: 63.58%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 5700/10000, Train Loss: 0.6054, Train Acc: 63.87%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 5701/10000, Train Loss: 0.6225, Train Acc: 63.01%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 5702/10000, Train Loss: 0.6328, Train Acc: 65.03%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 5703/10000, Train Loss: 0.6021, Train Acc: 63.29%, Test Loss: 0.5519, Test Acc: 74.14%\n",
            "Epoch 5704/10000, Train Loss: 0.6012, Train Acc: 59.83%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 5705/10000, Train Loss: 0.6169, Train Acc: 61.85%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 5706/10000, Train Loss: 0.6023, Train Acc: 65.32%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 5707/10000, Train Loss: 0.6159, Train Acc: 64.45%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 5708/10000, Train Loss: 0.6186, Train Acc: 62.14%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 5709/10000, Train Loss: 0.6205, Train Acc: 64.74%, Test Loss: 0.5517, Test Acc: 75.86%\n",
            "Epoch 5710/10000, Train Loss: 0.6170, Train Acc: 65.61%, Test Loss: 0.5498, Test Acc: 72.41%\n",
            "Epoch 5711/10000, Train Loss: 0.5945, Train Acc: 65.61%, Test Loss: 0.5489, Test Acc: 68.97%\n",
            "Epoch 5712/10000, Train Loss: 0.6018, Train Acc: 63.01%, Test Loss: 0.5496, Test Acc: 72.41%\n",
            "Epoch 5713/10000, Train Loss: 0.6238, Train Acc: 68.21%, Test Loss: 0.5487, Test Acc: 68.97%\n",
            "Epoch 5714/10000, Train Loss: 0.6115, Train Acc: 64.74%, Test Loss: 0.5513, Test Acc: 70.69%\n",
            "Epoch 5715/10000, Train Loss: 0.6322, Train Acc: 62.72%, Test Loss: 0.5532, Test Acc: 70.69%\n",
            "Epoch 5716/10000, Train Loss: 0.6196, Train Acc: 63.58%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 5717/10000, Train Loss: 0.6023, Train Acc: 67.92%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 5718/10000, Train Loss: 0.6112, Train Acc: 66.18%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 5719/10000, Train Loss: 0.6205, Train Acc: 63.29%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 5720/10000, Train Loss: 0.5795, Train Acc: 67.05%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 5721/10000, Train Loss: 0.6349, Train Acc: 63.29%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 5722/10000, Train Loss: 0.6139, Train Acc: 63.87%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 5723/10000, Train Loss: 0.6343, Train Acc: 61.27%, Test Loss: 0.5577, Test Acc: 70.69%\n",
            "Epoch 5724/10000, Train Loss: 0.6084, Train Acc: 60.69%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 5725/10000, Train Loss: 0.6191, Train Acc: 67.63%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 5726/10000, Train Loss: 0.6105, Train Acc: 65.32%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 5727/10000, Train Loss: 0.6002, Train Acc: 67.92%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 5728/10000, Train Loss: 0.6132, Train Acc: 64.16%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 5729/10000, Train Loss: 0.6165, Train Acc: 65.03%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 5730/10000, Train Loss: 0.6087, Train Acc: 65.90%, Test Loss: 0.5560, Test Acc: 70.69%\n",
            "Epoch 5731/10000, Train Loss: 0.6006, Train Acc: 65.32%, Test Loss: 0.5584, Test Acc: 70.69%\n",
            "Epoch 5732/10000, Train Loss: 0.6098, Train Acc: 65.61%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 5733/10000, Train Loss: 0.6104, Train Acc: 66.76%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 5734/10000, Train Loss: 0.5911, Train Acc: 66.18%, Test Loss: 0.5611, Test Acc: 72.41%\n",
            "Epoch 5735/10000, Train Loss: 0.6167, Train Acc: 61.27%, Test Loss: 0.5626, Test Acc: 68.97%\n",
            "Epoch 5736/10000, Train Loss: 0.6073, Train Acc: 67.34%, Test Loss: 0.5623, Test Acc: 70.69%\n",
            "Epoch 5737/10000, Train Loss: 0.5994, Train Acc: 67.92%, Test Loss: 0.5582, Test Acc: 70.69%\n",
            "Epoch 5738/10000, Train Loss: 0.6262, Train Acc: 62.43%, Test Loss: 0.5574, Test Acc: 72.41%\n",
            "Epoch 5739/10000, Train Loss: 0.6180, Train Acc: 64.74%, Test Loss: 0.5561, Test Acc: 74.14%\n",
            "Epoch 5740/10000, Train Loss: 0.5961, Train Acc: 66.47%, Test Loss: 0.5540, Test Acc: 74.14%\n",
            "Epoch 5741/10000, Train Loss: 0.6127, Train Acc: 63.01%, Test Loss: 0.5510, Test Acc: 74.14%\n",
            "Epoch 5742/10000, Train Loss: 0.5976, Train Acc: 63.87%, Test Loss: 0.5509, Test Acc: 74.14%\n",
            "Epoch 5743/10000, Train Loss: 0.6386, Train Acc: 63.01%, Test Loss: 0.5523, Test Acc: 74.14%\n",
            "Epoch 5744/10000, Train Loss: 0.6355, Train Acc: 63.01%, Test Loss: 0.5502, Test Acc: 72.41%\n",
            "Epoch 5745/10000, Train Loss: 0.6231, Train Acc: 68.21%, Test Loss: 0.5478, Test Acc: 68.97%\n",
            "Epoch 5746/10000, Train Loss: 0.6192, Train Acc: 66.18%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 5747/10000, Train Loss: 0.6194, Train Acc: 65.03%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 5748/10000, Train Loss: 0.6078, Train Acc: 66.18%, Test Loss: 0.5594, Test Acc: 70.69%\n",
            "Epoch 5749/10000, Train Loss: 0.6158, Train Acc: 63.01%, Test Loss: 0.5615, Test Acc: 68.97%\n",
            "Epoch 5750/10000, Train Loss: 0.6446, Train Acc: 65.03%, Test Loss: 0.5622, Test Acc: 72.41%\n",
            "Epoch 5751/10000, Train Loss: 0.6214, Train Acc: 63.87%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 5752/10000, Train Loss: 0.6030, Train Acc: 67.05%, Test Loss: 0.5520, Test Acc: 74.14%\n",
            "Epoch 5753/10000, Train Loss: 0.6235, Train Acc: 66.47%, Test Loss: 0.5541, Test Acc: 74.14%\n",
            "Epoch 5754/10000, Train Loss: 0.6217, Train Acc: 66.18%, Test Loss: 0.5538, Test Acc: 74.14%\n",
            "Epoch 5755/10000, Train Loss: 0.6413, Train Acc: 62.72%, Test Loss: 0.5497, Test Acc: 74.14%\n",
            "Epoch 5756/10000, Train Loss: 0.6140, Train Acc: 63.58%, Test Loss: 0.5463, Test Acc: 70.69%\n",
            "Epoch 5757/10000, Train Loss: 0.6214, Train Acc: 68.50%, Test Loss: 0.5473, Test Acc: 68.97%\n",
            "Epoch 5758/10000, Train Loss: 0.6199, Train Acc: 64.74%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 5759/10000, Train Loss: 0.6403, Train Acc: 65.03%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 5760/10000, Train Loss: 0.6188, Train Acc: 66.47%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 5761/10000, Train Loss: 0.6119, Train Acc: 65.32%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 5762/10000, Train Loss: 0.6267, Train Acc: 63.01%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 5763/10000, Train Loss: 0.6065, Train Acc: 66.18%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 5764/10000, Train Loss: 0.6321, Train Acc: 63.58%, Test Loss: 0.5588, Test Acc: 70.69%\n",
            "Epoch 5765/10000, Train Loss: 0.6048, Train Acc: 67.05%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 5766/10000, Train Loss: 0.6126, Train Acc: 65.61%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 5767/10000, Train Loss: 0.6154, Train Acc: 63.58%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 5768/10000, Train Loss: 0.6324, Train Acc: 64.74%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 5769/10000, Train Loss: 0.6383, Train Acc: 59.25%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 5770/10000, Train Loss: 0.6155, Train Acc: 65.90%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 5771/10000, Train Loss: 0.6077, Train Acc: 65.03%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 5772/10000, Train Loss: 0.6326, Train Acc: 66.76%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 5773/10000, Train Loss: 0.6129, Train Acc: 64.74%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 5774/10000, Train Loss: 0.6095, Train Acc: 65.32%, Test Loss: 0.5514, Test Acc: 70.69%\n",
            "Epoch 5775/10000, Train Loss: 0.6321, Train Acc: 58.96%, Test Loss: 0.5501, Test Acc: 74.14%\n",
            "Epoch 5776/10000, Train Loss: 0.6186, Train Acc: 65.61%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 5777/10000, Train Loss: 0.6256, Train Acc: 64.74%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 5778/10000, Train Loss: 0.6411, Train Acc: 60.69%, Test Loss: 0.5481, Test Acc: 68.97%\n",
            "Epoch 5779/10000, Train Loss: 0.6220, Train Acc: 62.14%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 5780/10000, Train Loss: 0.6285, Train Acc: 63.01%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 5781/10000, Train Loss: 0.6159, Train Acc: 62.72%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 5782/10000, Train Loss: 0.6239, Train Acc: 63.01%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 5783/10000, Train Loss: 0.6203, Train Acc: 64.45%, Test Loss: 0.5497, Test Acc: 70.69%\n",
            "Epoch 5784/10000, Train Loss: 0.6254, Train Acc: 65.03%, Test Loss: 0.5510, Test Acc: 74.14%\n",
            "Epoch 5785/10000, Train Loss: 0.6203, Train Acc: 62.43%, Test Loss: 0.5510, Test Acc: 74.14%\n",
            "Epoch 5786/10000, Train Loss: 0.6260, Train Acc: 65.61%, Test Loss: 0.5505, Test Acc: 72.41%\n",
            "Epoch 5787/10000, Train Loss: 0.6152, Train Acc: 66.18%, Test Loss: 0.5491, Test Acc: 70.69%\n",
            "Epoch 5788/10000, Train Loss: 0.6305, Train Acc: 63.01%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 5789/10000, Train Loss: 0.6067, Train Acc: 65.61%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 5790/10000, Train Loss: 0.6090, Train Acc: 62.43%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 5791/10000, Train Loss: 0.6118, Train Acc: 65.61%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 5792/10000, Train Loss: 0.6021, Train Acc: 66.18%, Test Loss: 0.5532, Test Acc: 70.69%\n",
            "Epoch 5793/10000, Train Loss: 0.6105, Train Acc: 66.76%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 5794/10000, Train Loss: 0.5947, Train Acc: 68.50%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 5795/10000, Train Loss: 0.6292, Train Acc: 64.16%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 5796/10000, Train Loss: 0.6427, Train Acc: 63.58%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 5797/10000, Train Loss: 0.5965, Train Acc: 65.61%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 5798/10000, Train Loss: 0.6013, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 5799/10000, Train Loss: 0.6155, Train Acc: 65.90%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 5800/10000, Train Loss: 0.5917, Train Acc: 65.90%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 5801/10000, Train Loss: 0.6271, Train Acc: 62.43%, Test Loss: 0.5508, Test Acc: 68.97%\n",
            "Epoch 5802/10000, Train Loss: 0.5988, Train Acc: 65.90%, Test Loss: 0.5494, Test Acc: 72.41%\n",
            "Epoch 5803/10000, Train Loss: 0.6107, Train Acc: 63.01%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 5804/10000, Train Loss: 0.6039, Train Acc: 66.76%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 5805/10000, Train Loss: 0.6131, Train Acc: 65.61%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 5806/10000, Train Loss: 0.6176, Train Acc: 67.05%, Test Loss: 0.5578, Test Acc: 70.69%\n",
            "Epoch 5807/10000, Train Loss: 0.6047, Train Acc: 62.43%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 5808/10000, Train Loss: 0.6438, Train Acc: 65.32%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 5809/10000, Train Loss: 0.6137, Train Acc: 67.34%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 5810/10000, Train Loss: 0.6193, Train Acc: 63.29%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 5811/10000, Train Loss: 0.6394, Train Acc: 65.03%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 5812/10000, Train Loss: 0.6103, Train Acc: 63.58%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 5813/10000, Train Loss: 0.6180, Train Acc: 65.90%, Test Loss: 0.5596, Test Acc: 70.69%\n",
            "Epoch 5814/10000, Train Loss: 0.6137, Train Acc: 62.14%, Test Loss: 0.5626, Test Acc: 70.69%\n",
            "Epoch 5815/10000, Train Loss: 0.6285, Train Acc: 68.79%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 5816/10000, Train Loss: 0.6227, Train Acc: 63.87%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 5817/10000, Train Loss: 0.6217, Train Acc: 66.76%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 5818/10000, Train Loss: 0.6193, Train Acc: 63.29%, Test Loss: 0.5512, Test Acc: 74.14%\n",
            "Epoch 5819/10000, Train Loss: 0.6267, Train Acc: 64.45%, Test Loss: 0.5516, Test Acc: 75.86%\n",
            "Epoch 5820/10000, Train Loss: 0.6107, Train Acc: 65.90%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 5821/10000, Train Loss: 0.6292, Train Acc: 62.72%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 5822/10000, Train Loss: 0.5964, Train Acc: 67.05%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 5823/10000, Train Loss: 0.6314, Train Acc: 63.87%, Test Loss: 0.5487, Test Acc: 74.14%\n",
            "Epoch 5824/10000, Train Loss: 0.6338, Train Acc: 63.58%, Test Loss: 0.5477, Test Acc: 72.41%\n",
            "Epoch 5825/10000, Train Loss: 0.6228, Train Acc: 62.43%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 5826/10000, Train Loss: 0.6159, Train Acc: 65.32%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 5827/10000, Train Loss: 0.6069, Train Acc: 61.85%, Test Loss: 0.5639, Test Acc: 68.97%\n",
            "Epoch 5828/10000, Train Loss: 0.6211, Train Acc: 62.72%, Test Loss: 0.5638, Test Acc: 70.69%\n",
            "Epoch 5829/10000, Train Loss: 0.6287, Train Acc: 65.32%, Test Loss: 0.5600, Test Acc: 68.97%\n",
            "Epoch 5830/10000, Train Loss: 0.6236, Train Acc: 62.14%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 5831/10000, Train Loss: 0.6365, Train Acc: 65.61%, Test Loss: 0.5532, Test Acc: 74.14%\n",
            "Epoch 5832/10000, Train Loss: 0.6083, Train Acc: 65.90%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 5833/10000, Train Loss: 0.6123, Train Acc: 62.72%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 5834/10000, Train Loss: 0.6339, Train Acc: 63.29%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 5835/10000, Train Loss: 0.6290, Train Acc: 63.29%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 5836/10000, Train Loss: 0.6527, Train Acc: 59.83%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 5837/10000, Train Loss: 0.6268, Train Acc: 62.14%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 5838/10000, Train Loss: 0.6080, Train Acc: 65.61%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 5839/10000, Train Loss: 0.6193, Train Acc: 67.05%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 5840/10000, Train Loss: 0.6019, Train Acc: 67.92%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 5841/10000, Train Loss: 0.6387, Train Acc: 69.08%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 5842/10000, Train Loss: 0.6323, Train Acc: 63.87%, Test Loss: 0.5529, Test Acc: 74.14%\n",
            "Epoch 5843/10000, Train Loss: 0.6232, Train Acc: 64.74%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 5844/10000, Train Loss: 0.6121, Train Acc: 63.01%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 5845/10000, Train Loss: 0.6262, Train Acc: 63.01%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 5846/10000, Train Loss: 0.6142, Train Acc: 63.29%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 5847/10000, Train Loss: 0.6123, Train Acc: 65.61%, Test Loss: 0.5575, Test Acc: 70.69%\n",
            "Epoch 5848/10000, Train Loss: 0.6179, Train Acc: 64.74%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 5849/10000, Train Loss: 0.6033, Train Acc: 62.43%, Test Loss: 0.5569, Test Acc: 74.14%\n",
            "Epoch 5850/10000, Train Loss: 0.6514, Train Acc: 61.27%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 5851/10000, Train Loss: 0.6248, Train Acc: 67.63%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 5852/10000, Train Loss: 0.6415, Train Acc: 60.69%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 5853/10000, Train Loss: 0.6074, Train Acc: 66.47%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 5854/10000, Train Loss: 0.6101, Train Acc: 67.63%, Test Loss: 0.5586, Test Acc: 68.97%\n",
            "Epoch 5855/10000, Train Loss: 0.5998, Train Acc: 67.92%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 5856/10000, Train Loss: 0.6112, Train Acc: 65.03%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 5857/10000, Train Loss: 0.5850, Train Acc: 65.61%, Test Loss: 0.5572, Test Acc: 72.41%\n",
            "Epoch 5858/10000, Train Loss: 0.6135, Train Acc: 67.34%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 5859/10000, Train Loss: 0.6055, Train Acc: 65.03%, Test Loss: 0.5582, Test Acc: 74.14%\n",
            "Epoch 5860/10000, Train Loss: 0.6315, Train Acc: 61.56%, Test Loss: 0.5580, Test Acc: 72.41%\n",
            "Epoch 5861/10000, Train Loss: 0.6334, Train Acc: 65.03%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 5862/10000, Train Loss: 0.5990, Train Acc: 66.47%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 5863/10000, Train Loss: 0.6203, Train Acc: 62.72%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 5864/10000, Train Loss: 0.5985, Train Acc: 65.61%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 5865/10000, Train Loss: 0.5952, Train Acc: 65.61%, Test Loss: 0.5580, Test Acc: 72.41%\n",
            "Epoch 5866/10000, Train Loss: 0.5977, Train Acc: 65.32%, Test Loss: 0.5575, Test Acc: 75.86%\n",
            "Epoch 5867/10000, Train Loss: 0.6074, Train Acc: 64.16%, Test Loss: 0.5544, Test Acc: 74.14%\n",
            "Epoch 5868/10000, Train Loss: 0.5993, Train Acc: 67.34%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 5869/10000, Train Loss: 0.5953, Train Acc: 66.76%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 5870/10000, Train Loss: 0.6116, Train Acc: 70.52%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 5871/10000, Train Loss: 0.6392, Train Acc: 67.34%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 5872/10000, Train Loss: 0.6111, Train Acc: 66.47%, Test Loss: 0.5517, Test Acc: 74.14%\n",
            "Epoch 5873/10000, Train Loss: 0.6169, Train Acc: 63.87%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 5874/10000, Train Loss: 0.6112, Train Acc: 65.03%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 5875/10000, Train Loss: 0.5977, Train Acc: 64.45%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 5876/10000, Train Loss: 0.5886, Train Acc: 66.76%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 5877/10000, Train Loss: 0.6038, Train Acc: 64.16%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 5878/10000, Train Loss: 0.6162, Train Acc: 67.92%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 5879/10000, Train Loss: 0.6211, Train Acc: 64.74%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 5880/10000, Train Loss: 0.6190, Train Acc: 64.74%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 5881/10000, Train Loss: 0.6094, Train Acc: 65.32%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 5882/10000, Train Loss: 0.6116, Train Acc: 66.18%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 5883/10000, Train Loss: 0.6309, Train Acc: 62.72%, Test Loss: 0.5603, Test Acc: 72.41%\n",
            "Epoch 5884/10000, Train Loss: 0.6235, Train Acc: 63.29%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 5885/10000, Train Loss: 0.6153, Train Acc: 60.98%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 5886/10000, Train Loss: 0.6268, Train Acc: 62.43%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 5887/10000, Train Loss: 0.6087, Train Acc: 67.92%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 5888/10000, Train Loss: 0.6242, Train Acc: 64.74%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 5889/10000, Train Loss: 0.6069, Train Acc: 66.18%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 5890/10000, Train Loss: 0.6188, Train Acc: 63.29%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 5891/10000, Train Loss: 0.6261, Train Acc: 62.14%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 5892/10000, Train Loss: 0.6254, Train Acc: 63.87%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 5893/10000, Train Loss: 0.6096, Train Acc: 63.58%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 5894/10000, Train Loss: 0.6169, Train Acc: 64.45%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 5895/10000, Train Loss: 0.6118, Train Acc: 61.27%, Test Loss: 0.5591, Test Acc: 72.41%\n",
            "Epoch 5896/10000, Train Loss: 0.6162, Train Acc: 62.72%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 5897/10000, Train Loss: 0.6019, Train Acc: 64.74%, Test Loss: 0.5509, Test Acc: 68.97%\n",
            "Epoch 5898/10000, Train Loss: 0.6187, Train Acc: 63.87%, Test Loss: 0.5522, Test Acc: 75.86%\n",
            "Epoch 5899/10000, Train Loss: 0.6039, Train Acc: 64.74%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 5900/10000, Train Loss: 0.6377, Train Acc: 60.12%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 5901/10000, Train Loss: 0.6111, Train Acc: 66.18%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 5902/10000, Train Loss: 0.6248, Train Acc: 63.01%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 5903/10000, Train Loss: 0.6338, Train Acc: 66.76%, Test Loss: 0.5506, Test Acc: 74.14%\n",
            "Epoch 5904/10000, Train Loss: 0.6417, Train Acc: 61.85%, Test Loss: 0.5523, Test Acc: 74.14%\n",
            "Epoch 5905/10000, Train Loss: 0.6263, Train Acc: 58.38%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 5906/10000, Train Loss: 0.6119, Train Acc: 67.05%, Test Loss: 0.5597, Test Acc: 72.41%\n",
            "Epoch 5907/10000, Train Loss: 0.6162, Train Acc: 62.14%, Test Loss: 0.5610, Test Acc: 70.69%\n",
            "Epoch 5908/10000, Train Loss: 0.6032, Train Acc: 63.01%, Test Loss: 0.5588, Test Acc: 72.41%\n",
            "Epoch 5909/10000, Train Loss: 0.6175, Train Acc: 65.03%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 5910/10000, Train Loss: 0.6382, Train Acc: 63.01%, Test Loss: 0.5533, Test Acc: 75.86%\n",
            "Epoch 5911/10000, Train Loss: 0.6189, Train Acc: 63.01%, Test Loss: 0.5533, Test Acc: 75.86%\n",
            "Epoch 5912/10000, Train Loss: 0.6056, Train Acc: 66.47%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 5913/10000, Train Loss: 0.6251, Train Acc: 67.05%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 5914/10000, Train Loss: 0.6306, Train Acc: 63.87%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 5915/10000, Train Loss: 0.6286, Train Acc: 63.87%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 5916/10000, Train Loss: 0.6189, Train Acc: 66.76%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 5917/10000, Train Loss: 0.6159, Train Acc: 66.76%, Test Loss: 0.5607, Test Acc: 68.97%\n",
            "Epoch 5918/10000, Train Loss: 0.6107, Train Acc: 66.76%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 5919/10000, Train Loss: 0.6177, Train Acc: 65.90%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 5920/10000, Train Loss: 0.6157, Train Acc: 63.01%, Test Loss: 0.5605, Test Acc: 70.69%\n",
            "Epoch 5921/10000, Train Loss: 0.6097, Train Acc: 68.79%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 5922/10000, Train Loss: 0.6291, Train Acc: 66.18%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 5923/10000, Train Loss: 0.6221, Train Acc: 66.47%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 5924/10000, Train Loss: 0.6350, Train Acc: 59.83%, Test Loss: 0.5535, Test Acc: 74.14%\n",
            "Epoch 5925/10000, Train Loss: 0.6375, Train Acc: 65.03%, Test Loss: 0.5559, Test Acc: 74.14%\n",
            "Epoch 5926/10000, Train Loss: 0.6176, Train Acc: 63.01%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 5927/10000, Train Loss: 0.6238, Train Acc: 62.43%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 5928/10000, Train Loss: 0.5955, Train Acc: 68.50%, Test Loss: 0.5533, Test Acc: 74.14%\n",
            "Epoch 5929/10000, Train Loss: 0.6320, Train Acc: 63.29%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 5930/10000, Train Loss: 0.5964, Train Acc: 66.47%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 5931/10000, Train Loss: 0.6287, Train Acc: 63.87%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5932/10000, Train Loss: 0.6093, Train Acc: 63.29%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 5933/10000, Train Loss: 0.6163, Train Acc: 64.16%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 5934/10000, Train Loss: 0.6110, Train Acc: 66.18%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 5935/10000, Train Loss: 0.6040, Train Acc: 61.85%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 5936/10000, Train Loss: 0.6255, Train Acc: 64.74%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 5937/10000, Train Loss: 0.5948, Train Acc: 65.03%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 5938/10000, Train Loss: 0.6077, Train Acc: 64.16%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 5939/10000, Train Loss: 0.6113, Train Acc: 63.87%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 5940/10000, Train Loss: 0.6038, Train Acc: 65.61%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 5941/10000, Train Loss: 0.6152, Train Acc: 64.45%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 5942/10000, Train Loss: 0.6113, Train Acc: 67.05%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 5943/10000, Train Loss: 0.6353, Train Acc: 62.14%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 5944/10000, Train Loss: 0.6488, Train Acc: 65.32%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 5945/10000, Train Loss: 0.6193, Train Acc: 62.43%, Test Loss: 0.5677, Test Acc: 70.69%\n",
            "Epoch 5946/10000, Train Loss: 0.6127, Train Acc: 64.16%, Test Loss: 0.5653, Test Acc: 68.97%\n",
            "Epoch 5947/10000, Train Loss: 0.6256, Train Acc: 64.74%, Test Loss: 0.5626, Test Acc: 68.97%\n",
            "Epoch 5948/10000, Train Loss: 0.6139, Train Acc: 63.87%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 5949/10000, Train Loss: 0.6071, Train Acc: 65.32%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 5950/10000, Train Loss: 0.6289, Train Acc: 65.32%, Test Loss: 0.5605, Test Acc: 70.69%\n",
            "Epoch 5951/10000, Train Loss: 0.6465, Train Acc: 63.29%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 5952/10000, Train Loss: 0.6050, Train Acc: 67.92%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 5953/10000, Train Loss: 0.6379, Train Acc: 65.03%, Test Loss: 0.5601, Test Acc: 74.14%\n",
            "Epoch 5954/10000, Train Loss: 0.6093, Train Acc: 65.03%, Test Loss: 0.5633, Test Acc: 72.41%\n",
            "Epoch 5955/10000, Train Loss: 0.6041, Train Acc: 66.18%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 5956/10000, Train Loss: 0.6275, Train Acc: 64.45%, Test Loss: 0.5501, Test Acc: 74.14%\n",
            "Epoch 5957/10000, Train Loss: 0.6207, Train Acc: 64.74%, Test Loss: 0.5471, Test Acc: 72.41%\n",
            "Epoch 5958/10000, Train Loss: 0.6228, Train Acc: 62.43%, Test Loss: 0.5502, Test Acc: 68.97%\n",
            "Epoch 5959/10000, Train Loss: 0.6467, Train Acc: 62.72%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 5960/10000, Train Loss: 0.6268, Train Acc: 66.18%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 5961/10000, Train Loss: 0.6145, Train Acc: 62.72%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 5962/10000, Train Loss: 0.6400, Train Acc: 60.12%, Test Loss: 0.5610, Test Acc: 72.41%\n",
            "Epoch 5963/10000, Train Loss: 0.5898, Train Acc: 64.74%, Test Loss: 0.5619, Test Acc: 72.41%\n",
            "Epoch 5964/10000, Train Loss: 0.6098, Train Acc: 63.87%, Test Loss: 0.5632, Test Acc: 72.41%\n",
            "Epoch 5965/10000, Train Loss: 0.6005, Train Acc: 66.47%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 5966/10000, Train Loss: 0.6280, Train Acc: 63.01%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 5967/10000, Train Loss: 0.6255, Train Acc: 64.16%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 5968/10000, Train Loss: 0.6102, Train Acc: 63.29%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 5969/10000, Train Loss: 0.6382, Train Acc: 64.45%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 5970/10000, Train Loss: 0.6026, Train Acc: 64.45%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 5971/10000, Train Loss: 0.5938, Train Acc: 67.05%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 5972/10000, Train Loss: 0.6139, Train Acc: 66.47%, Test Loss: 0.5586, Test Acc: 68.97%\n",
            "Epoch 5973/10000, Train Loss: 0.6081, Train Acc: 65.32%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 5974/10000, Train Loss: 0.6414, Train Acc: 63.87%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 5975/10000, Train Loss: 0.6273, Train Acc: 63.87%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 5976/10000, Train Loss: 0.6394, Train Acc: 66.47%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 5977/10000, Train Loss: 0.6172, Train Acc: 66.18%, Test Loss: 0.5539, Test Acc: 75.86%\n",
            "Epoch 5978/10000, Train Loss: 0.6094, Train Acc: 64.45%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 5979/10000, Train Loss: 0.6227, Train Acc: 62.72%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 5980/10000, Train Loss: 0.6145, Train Acc: 63.87%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 5981/10000, Train Loss: 0.6088, Train Acc: 66.18%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 5982/10000, Train Loss: 0.6113, Train Acc: 65.03%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 5983/10000, Train Loss: 0.6191, Train Acc: 63.58%, Test Loss: 0.5534, Test Acc: 74.14%\n",
            "Epoch 5984/10000, Train Loss: 0.6053, Train Acc: 66.47%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 5985/10000, Train Loss: 0.6053, Train Acc: 64.16%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 5986/10000, Train Loss: 0.6301, Train Acc: 64.16%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 5987/10000, Train Loss: 0.6227, Train Acc: 64.16%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 5988/10000, Train Loss: 0.6230, Train Acc: 64.16%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 5989/10000, Train Loss: 0.5996, Train Acc: 64.74%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 5990/10000, Train Loss: 0.6093, Train Acc: 68.21%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 5991/10000, Train Loss: 0.6128, Train Acc: 66.47%, Test Loss: 0.5611, Test Acc: 68.97%\n",
            "Epoch 5992/10000, Train Loss: 0.6103, Train Acc: 66.76%, Test Loss: 0.5618, Test Acc: 68.97%\n",
            "Epoch 5993/10000, Train Loss: 0.6235, Train Acc: 63.58%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 5994/10000, Train Loss: 0.6165, Train Acc: 62.72%, Test Loss: 0.5585, Test Acc: 72.41%\n",
            "Epoch 5995/10000, Train Loss: 0.6082, Train Acc: 63.01%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 5996/10000, Train Loss: 0.6163, Train Acc: 63.01%, Test Loss: 0.5556, Test Acc: 70.69%\n",
            "Epoch 5997/10000, Train Loss: 0.6243, Train Acc: 65.03%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 5998/10000, Train Loss: 0.6089, Train Acc: 66.76%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 5999/10000, Train Loss: 0.6296, Train Acc: 62.43%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 6000/10000, Train Loss: 0.6281, Train Acc: 62.14%, Test Loss: 0.5542, Test Acc: 75.86%\n",
            "Epoch 6001/10000, Train Loss: 0.6199, Train Acc: 65.90%, Test Loss: 0.5564, Test Acc: 74.14%\n",
            "Epoch 6002/10000, Train Loss: 0.6197, Train Acc: 60.98%, Test Loss: 0.5570, Test Acc: 72.41%\n",
            "Epoch 6003/10000, Train Loss: 0.6241, Train Acc: 61.85%, Test Loss: 0.5601, Test Acc: 70.69%\n",
            "Epoch 6004/10000, Train Loss: 0.6227, Train Acc: 64.16%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 6005/10000, Train Loss: 0.6210, Train Acc: 60.40%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6006/10000, Train Loss: 0.6307, Train Acc: 62.72%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 6007/10000, Train Loss: 0.6235, Train Acc: 63.87%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 6008/10000, Train Loss: 0.6247, Train Acc: 62.72%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 6009/10000, Train Loss: 0.6154, Train Acc: 64.16%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 6010/10000, Train Loss: 0.6091, Train Acc: 65.90%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 6011/10000, Train Loss: 0.6276, Train Acc: 66.47%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 6012/10000, Train Loss: 0.6113, Train Acc: 62.14%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 6013/10000, Train Loss: 0.6108, Train Acc: 65.90%, Test Loss: 0.5602, Test Acc: 68.97%\n",
            "Epoch 6014/10000, Train Loss: 0.6179, Train Acc: 65.61%, Test Loss: 0.5623, Test Acc: 68.97%\n",
            "Epoch 6015/10000, Train Loss: 0.6404, Train Acc: 64.45%, Test Loss: 0.5584, Test Acc: 74.14%\n",
            "Epoch 6016/10000, Train Loss: 0.5926, Train Acc: 68.21%, Test Loss: 0.5589, Test Acc: 74.14%\n",
            "Epoch 6017/10000, Train Loss: 0.6054, Train Acc: 66.76%, Test Loss: 0.5592, Test Acc: 70.69%\n",
            "Epoch 6018/10000, Train Loss: 0.6118, Train Acc: 62.72%, Test Loss: 0.5629, Test Acc: 70.69%\n",
            "Epoch 6019/10000, Train Loss: 0.6332, Train Acc: 65.03%, Test Loss: 0.5605, Test Acc: 70.69%\n",
            "Epoch 6020/10000, Train Loss: 0.6228, Train Acc: 64.45%, Test Loss: 0.5582, Test Acc: 74.14%\n",
            "Epoch 6021/10000, Train Loss: 0.6292, Train Acc: 62.72%, Test Loss: 0.5584, Test Acc: 74.14%\n",
            "Epoch 6022/10000, Train Loss: 0.6255, Train Acc: 64.16%, Test Loss: 0.5582, Test Acc: 70.69%\n",
            "Epoch 6023/10000, Train Loss: 0.6141, Train Acc: 62.14%, Test Loss: 0.5621, Test Acc: 70.69%\n",
            "Epoch 6024/10000, Train Loss: 0.5874, Train Acc: 67.92%, Test Loss: 0.5617, Test Acc: 72.41%\n",
            "Epoch 6025/10000, Train Loss: 0.5998, Train Acc: 65.32%, Test Loss: 0.5582, Test Acc: 70.69%\n",
            "Epoch 6026/10000, Train Loss: 0.6030, Train Acc: 67.05%, Test Loss: 0.5575, Test Acc: 70.69%\n",
            "Epoch 6027/10000, Train Loss: 0.6228, Train Acc: 63.87%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 6028/10000, Train Loss: 0.6118, Train Acc: 66.76%, Test Loss: 0.5581, Test Acc: 75.86%\n",
            "Epoch 6029/10000, Train Loss: 0.6027, Train Acc: 64.45%, Test Loss: 0.5584, Test Acc: 74.14%\n",
            "Epoch 6030/10000, Train Loss: 0.6205, Train Acc: 65.03%, Test Loss: 0.5579, Test Acc: 72.41%\n",
            "Epoch 6031/10000, Train Loss: 0.6108, Train Acc: 67.92%, Test Loss: 0.5578, Test Acc: 72.41%\n",
            "Epoch 6032/10000, Train Loss: 0.6127, Train Acc: 63.58%, Test Loss: 0.5577, Test Acc: 70.69%\n",
            "Epoch 6033/10000, Train Loss: 0.6205, Train Acc: 66.76%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 6034/10000, Train Loss: 0.6382, Train Acc: 62.14%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 6035/10000, Train Loss: 0.6401, Train Acc: 60.40%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 6036/10000, Train Loss: 0.6226, Train Acc: 65.03%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 6037/10000, Train Loss: 0.5962, Train Acc: 66.47%, Test Loss: 0.5542, Test Acc: 75.86%\n",
            "Epoch 6038/10000, Train Loss: 0.6188, Train Acc: 62.72%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 6039/10000, Train Loss: 0.6044, Train Acc: 67.63%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 6040/10000, Train Loss: 0.6313, Train Acc: 63.01%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 6041/10000, Train Loss: 0.6212, Train Acc: 65.03%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 6042/10000, Train Loss: 0.6200, Train Acc: 64.74%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 6043/10000, Train Loss: 0.6206, Train Acc: 65.03%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 6044/10000, Train Loss: 0.6001, Train Acc: 65.90%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 6045/10000, Train Loss: 0.6148, Train Acc: 63.87%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 6046/10000, Train Loss: 0.6106, Train Acc: 63.58%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 6047/10000, Train Loss: 0.6020, Train Acc: 64.74%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 6048/10000, Train Loss: 0.6375, Train Acc: 65.03%, Test Loss: 0.5527, Test Acc: 70.69%\n",
            "Epoch 6049/10000, Train Loss: 0.6221, Train Acc: 65.32%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 6050/10000, Train Loss: 0.5989, Train Acc: 65.61%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 6051/10000, Train Loss: 0.6288, Train Acc: 66.18%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 6052/10000, Train Loss: 0.6060, Train Acc: 64.16%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 6053/10000, Train Loss: 0.5998, Train Acc: 68.21%, Test Loss: 0.5587, Test Acc: 72.41%\n",
            "Epoch 6054/10000, Train Loss: 0.6153, Train Acc: 63.58%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 6055/10000, Train Loss: 0.6083, Train Acc: 64.16%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 6056/10000, Train Loss: 0.6033, Train Acc: 65.61%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 6057/10000, Train Loss: 0.6091, Train Acc: 67.34%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 6058/10000, Train Loss: 0.6466, Train Acc: 63.01%, Test Loss: 0.5514, Test Acc: 70.69%\n",
            "Epoch 6059/10000, Train Loss: 0.6325, Train Acc: 64.74%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 6060/10000, Train Loss: 0.6058, Train Acc: 65.32%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6061/10000, Train Loss: 0.6114, Train Acc: 62.72%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 6062/10000, Train Loss: 0.6207, Train Acc: 65.03%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 6063/10000, Train Loss: 0.6043, Train Acc: 66.76%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 6064/10000, Train Loss: 0.6314, Train Acc: 65.32%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 6065/10000, Train Loss: 0.5895, Train Acc: 65.90%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6066/10000, Train Loss: 0.6232, Train Acc: 63.58%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 6067/10000, Train Loss: 0.6147, Train Acc: 63.01%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6068/10000, Train Loss: 0.6168, Train Acc: 64.45%, Test Loss: 0.5536, Test Acc: 74.14%\n",
            "Epoch 6069/10000, Train Loss: 0.6258, Train Acc: 62.72%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 6070/10000, Train Loss: 0.6005, Train Acc: 65.32%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 6071/10000, Train Loss: 0.6573, Train Acc: 62.72%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 6072/10000, Train Loss: 0.5917, Train Acc: 68.50%, Test Loss: 0.5627, Test Acc: 70.69%\n",
            "Epoch 6073/10000, Train Loss: 0.6209, Train Acc: 67.63%, Test Loss: 0.5590, Test Acc: 70.69%\n",
            "Epoch 6074/10000, Train Loss: 0.6047, Train Acc: 64.74%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 6075/10000, Train Loss: 0.6337, Train Acc: 66.18%, Test Loss: 0.5505, Test Acc: 72.41%\n",
            "Epoch 6076/10000, Train Loss: 0.6122, Train Acc: 66.76%, Test Loss: 0.5507, Test Acc: 74.14%\n",
            "Epoch 6077/10000, Train Loss: 0.6188, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 6078/10000, Train Loss: 0.6423, Train Acc: 60.98%, Test Loss: 0.5604, Test Acc: 70.69%\n",
            "Epoch 6079/10000, Train Loss: 0.6053, Train Acc: 65.90%, Test Loss: 0.5642, Test Acc: 72.41%\n",
            "Epoch 6080/10000, Train Loss: 0.6054, Train Acc: 65.03%, Test Loss: 0.5610, Test Acc: 68.97%\n",
            "Epoch 6081/10000, Train Loss: 0.6333, Train Acc: 64.45%, Test Loss: 0.5594, Test Acc: 72.41%\n",
            "Epoch 6082/10000, Train Loss: 0.6268, Train Acc: 64.45%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 6083/10000, Train Loss: 0.6190, Train Acc: 67.05%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 6084/10000, Train Loss: 0.6170, Train Acc: 62.14%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 6085/10000, Train Loss: 0.6349, Train Acc: 59.54%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 6086/10000, Train Loss: 0.6362, Train Acc: 61.85%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 6087/10000, Train Loss: 0.6411, Train Acc: 63.58%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 6088/10000, Train Loss: 0.6166, Train Acc: 61.56%, Test Loss: 0.5641, Test Acc: 72.41%\n",
            "Epoch 6089/10000, Train Loss: 0.6176, Train Acc: 63.87%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 6090/10000, Train Loss: 0.6112, Train Acc: 65.90%, Test Loss: 0.5582, Test Acc: 75.86%\n",
            "Epoch 6091/10000, Train Loss: 0.6177, Train Acc: 63.01%, Test Loss: 0.5585, Test Acc: 74.14%\n",
            "Epoch 6092/10000, Train Loss: 0.6239, Train Acc: 65.61%, Test Loss: 0.5607, Test Acc: 70.69%\n",
            "Epoch 6093/10000, Train Loss: 0.6146, Train Acc: 64.45%, Test Loss: 0.5638, Test Acc: 68.97%\n",
            "Epoch 6094/10000, Train Loss: 0.6193, Train Acc: 65.61%, Test Loss: 0.5628, Test Acc: 68.97%\n",
            "Epoch 6095/10000, Train Loss: 0.6070, Train Acc: 69.08%, Test Loss: 0.5601, Test Acc: 70.69%\n",
            "Epoch 6096/10000, Train Loss: 0.6104, Train Acc: 66.18%, Test Loss: 0.5610, Test Acc: 74.14%\n",
            "Epoch 6097/10000, Train Loss: 0.6133, Train Acc: 65.61%, Test Loss: 0.5573, Test Acc: 74.14%\n",
            "Epoch 6098/10000, Train Loss: 0.6082, Train Acc: 65.90%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 6099/10000, Train Loss: 0.6024, Train Acc: 65.61%, Test Loss: 0.5517, Test Acc: 74.14%\n",
            "Epoch 6100/10000, Train Loss: 0.6156, Train Acc: 67.34%, Test Loss: 0.5497, Test Acc: 74.14%\n",
            "Epoch 6101/10000, Train Loss: 0.6126, Train Acc: 66.18%, Test Loss: 0.5510, Test Acc: 72.41%\n",
            "Epoch 6102/10000, Train Loss: 0.6387, Train Acc: 63.01%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 6103/10000, Train Loss: 0.6138, Train Acc: 66.76%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 6104/10000, Train Loss: 0.6284, Train Acc: 63.01%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 6105/10000, Train Loss: 0.6206, Train Acc: 65.03%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 6106/10000, Train Loss: 0.6228, Train Acc: 62.14%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 6107/10000, Train Loss: 0.6253, Train Acc: 65.61%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6108/10000, Train Loss: 0.6509, Train Acc: 62.72%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 6109/10000, Train Loss: 0.6157, Train Acc: 64.45%, Test Loss: 0.5584, Test Acc: 70.69%\n",
            "Epoch 6110/10000, Train Loss: 0.6165, Train Acc: 64.16%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 6111/10000, Train Loss: 0.6434, Train Acc: 63.29%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 6112/10000, Train Loss: 0.6174, Train Acc: 59.25%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 6113/10000, Train Loss: 0.6512, Train Acc: 63.87%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 6114/10000, Train Loss: 0.6355, Train Acc: 64.45%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 6115/10000, Train Loss: 0.6123, Train Acc: 64.74%, Test Loss: 0.5600, Test Acc: 70.69%\n",
            "Epoch 6116/10000, Train Loss: 0.6083, Train Acc: 64.16%, Test Loss: 0.5599, Test Acc: 68.97%\n",
            "Epoch 6117/10000, Train Loss: 0.5991, Train Acc: 65.90%, Test Loss: 0.5612, Test Acc: 72.41%\n",
            "Epoch 6118/10000, Train Loss: 0.6029, Train Acc: 68.21%, Test Loss: 0.5635, Test Acc: 72.41%\n",
            "Epoch 6119/10000, Train Loss: 0.6407, Train Acc: 61.56%, Test Loss: 0.5632, Test Acc: 70.69%\n",
            "Epoch 6120/10000, Train Loss: 0.6160, Train Acc: 67.63%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 6121/10000, Train Loss: 0.6021, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 6122/10000, Train Loss: 0.6119, Train Acc: 65.03%, Test Loss: 0.5537, Test Acc: 74.14%\n",
            "Epoch 6123/10000, Train Loss: 0.6197, Train Acc: 64.16%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 6124/10000, Train Loss: 0.6231, Train Acc: 63.87%, Test Loss: 0.5583, Test Acc: 72.41%\n",
            "Epoch 6125/10000, Train Loss: 0.6120, Train Acc: 65.03%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 6126/10000, Train Loss: 0.6102, Train Acc: 64.45%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 6127/10000, Train Loss: 0.5987, Train Acc: 65.90%, Test Loss: 0.5557, Test Acc: 74.14%\n",
            "Epoch 6128/10000, Train Loss: 0.6006, Train Acc: 65.61%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 6129/10000, Train Loss: 0.6283, Train Acc: 63.01%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 6130/10000, Train Loss: 0.6189, Train Acc: 61.85%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 6131/10000, Train Loss: 0.6355, Train Acc: 63.29%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 6132/10000, Train Loss: 0.6224, Train Acc: 64.74%, Test Loss: 0.5508, Test Acc: 68.97%\n",
            "Epoch 6133/10000, Train Loss: 0.6261, Train Acc: 62.14%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 6134/10000, Train Loss: 0.6201, Train Acc: 63.87%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 6135/10000, Train Loss: 0.6010, Train Acc: 64.45%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6136/10000, Train Loss: 0.6207, Train Acc: 63.58%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 6137/10000, Train Loss: 0.6189, Train Acc: 63.29%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 6138/10000, Train Loss: 0.6486, Train Acc: 64.16%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 6139/10000, Train Loss: 0.6210, Train Acc: 60.69%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 6140/10000, Train Loss: 0.6174, Train Acc: 63.87%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 6141/10000, Train Loss: 0.6392, Train Acc: 63.58%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 6142/10000, Train Loss: 0.6042, Train Acc: 62.14%, Test Loss: 0.5586, Test Acc: 72.41%\n",
            "Epoch 6143/10000, Train Loss: 0.6382, Train Acc: 65.61%, Test Loss: 0.5536, Test Acc: 75.86%\n",
            "Epoch 6144/10000, Train Loss: 0.6322, Train Acc: 60.40%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 6145/10000, Train Loss: 0.5967, Train Acc: 66.76%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 6146/10000, Train Loss: 0.6296, Train Acc: 64.74%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6147/10000, Train Loss: 0.6037, Train Acc: 68.50%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 6148/10000, Train Loss: 0.6173, Train Acc: 67.34%, Test Loss: 0.5612, Test Acc: 68.97%\n",
            "Epoch 6149/10000, Train Loss: 0.6077, Train Acc: 65.61%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 6150/10000, Train Loss: 0.6434, Train Acc: 64.45%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 6151/10000, Train Loss: 0.6059, Train Acc: 65.03%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 6152/10000, Train Loss: 0.6235, Train Acc: 63.01%, Test Loss: 0.5581, Test Acc: 70.69%\n",
            "Epoch 6153/10000, Train Loss: 0.6141, Train Acc: 65.61%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 6154/10000, Train Loss: 0.6088, Train Acc: 64.16%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 6155/10000, Train Loss: 0.6188, Train Acc: 64.16%, Test Loss: 0.5625, Test Acc: 68.97%\n",
            "Epoch 6156/10000, Train Loss: 0.6253, Train Acc: 65.90%, Test Loss: 0.5618, Test Acc: 68.97%\n",
            "Epoch 6157/10000, Train Loss: 0.6142, Train Acc: 63.87%, Test Loss: 0.5637, Test Acc: 72.41%\n",
            "Epoch 6158/10000, Train Loss: 0.6188, Train Acc: 61.27%, Test Loss: 0.5677, Test Acc: 68.97%\n",
            "Epoch 6159/10000, Train Loss: 0.6135, Train Acc: 64.74%, Test Loss: 0.5660, Test Acc: 68.97%\n",
            "Epoch 6160/10000, Train Loss: 0.6197, Train Acc: 63.29%, Test Loss: 0.5644, Test Acc: 70.69%\n",
            "Epoch 6161/10000, Train Loss: 0.6220, Train Acc: 63.87%, Test Loss: 0.5627, Test Acc: 72.41%\n",
            "Epoch 6162/10000, Train Loss: 0.6054, Train Acc: 66.18%, Test Loss: 0.5574, Test Acc: 74.14%\n",
            "Epoch 6163/10000, Train Loss: 0.6221, Train Acc: 65.61%, Test Loss: 0.5549, Test Acc: 75.86%\n",
            "Epoch 6164/10000, Train Loss: 0.6149, Train Acc: 64.16%, Test Loss: 0.5511, Test Acc: 74.14%\n",
            "Epoch 6165/10000, Train Loss: 0.6321, Train Acc: 63.58%, Test Loss: 0.5501, Test Acc: 74.14%\n",
            "Epoch 6166/10000, Train Loss: 0.6214, Train Acc: 63.01%, Test Loss: 0.5562, Test Acc: 75.86%\n",
            "Epoch 6167/10000, Train Loss: 0.6098, Train Acc: 64.74%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 6168/10000, Train Loss: 0.6092, Train Acc: 64.16%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 6169/10000, Train Loss: 0.6053, Train Acc: 66.76%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 6170/10000, Train Loss: 0.6162, Train Acc: 63.29%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 6171/10000, Train Loss: 0.6153, Train Acc: 65.03%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 6172/10000, Train Loss: 0.6274, Train Acc: 65.90%, Test Loss: 0.5616, Test Acc: 68.97%\n",
            "Epoch 6173/10000, Train Loss: 0.6234, Train Acc: 66.18%, Test Loss: 0.5649, Test Acc: 70.69%\n",
            "Epoch 6174/10000, Train Loss: 0.6124, Train Acc: 65.32%, Test Loss: 0.5617, Test Acc: 68.97%\n",
            "Epoch 6175/10000, Train Loss: 0.6039, Train Acc: 63.87%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 6176/10000, Train Loss: 0.6232, Train Acc: 65.32%, Test Loss: 0.5566, Test Acc: 70.69%\n",
            "Epoch 6177/10000, Train Loss: 0.6109, Train Acc: 63.87%, Test Loss: 0.5561, Test Acc: 75.86%\n",
            "Epoch 6178/10000, Train Loss: 0.6246, Train Acc: 60.69%, Test Loss: 0.5565, Test Acc: 74.14%\n",
            "Epoch 6179/10000, Train Loss: 0.6022, Train Acc: 65.61%, Test Loss: 0.5597, Test Acc: 74.14%\n",
            "Epoch 6180/10000, Train Loss: 0.6498, Train Acc: 62.72%, Test Loss: 0.5586, Test Acc: 74.14%\n",
            "Epoch 6181/10000, Train Loss: 0.6034, Train Acc: 65.03%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 6182/10000, Train Loss: 0.5954, Train Acc: 65.03%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 6183/10000, Train Loss: 0.6101, Train Acc: 64.16%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6184/10000, Train Loss: 0.6178, Train Acc: 66.18%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 6185/10000, Train Loss: 0.6266, Train Acc: 64.16%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6186/10000, Train Loss: 0.6019, Train Acc: 64.45%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 6187/10000, Train Loss: 0.6062, Train Acc: 63.58%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 6188/10000, Train Loss: 0.5925, Train Acc: 67.92%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6189/10000, Train Loss: 0.6026, Train Acc: 67.63%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 6190/10000, Train Loss: 0.6311, Train Acc: 61.85%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 6191/10000, Train Loss: 0.6218, Train Acc: 66.76%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6192/10000, Train Loss: 0.6155, Train Acc: 62.14%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6193/10000, Train Loss: 0.6061, Train Acc: 65.90%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 6194/10000, Train Loss: 0.6423, Train Acc: 59.83%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6195/10000, Train Loss: 0.6103, Train Acc: 67.34%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6196/10000, Train Loss: 0.6032, Train Acc: 66.18%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 6197/10000, Train Loss: 0.6208, Train Acc: 66.47%, Test Loss: 0.5536, Test Acc: 74.14%\n",
            "Epoch 6198/10000, Train Loss: 0.6151, Train Acc: 65.61%, Test Loss: 0.5513, Test Acc: 72.41%\n",
            "Epoch 6199/10000, Train Loss: 0.6151, Train Acc: 67.05%, Test Loss: 0.5506, Test Acc: 70.69%\n",
            "Epoch 6200/10000, Train Loss: 0.6344, Train Acc: 64.16%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 6201/10000, Train Loss: 0.6445, Train Acc: 63.87%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 6202/10000, Train Loss: 0.5997, Train Acc: 67.34%, Test Loss: 0.5623, Test Acc: 68.97%\n",
            "Epoch 6203/10000, Train Loss: 0.5970, Train Acc: 65.90%, Test Loss: 0.5679, Test Acc: 70.69%\n",
            "Epoch 6204/10000, Train Loss: 0.6141, Train Acc: 65.03%, Test Loss: 0.5659, Test Acc: 72.41%\n",
            "Epoch 6205/10000, Train Loss: 0.6035, Train Acc: 65.03%, Test Loss: 0.5648, Test Acc: 70.69%\n",
            "Epoch 6206/10000, Train Loss: 0.6263, Train Acc: 63.58%, Test Loss: 0.5616, Test Acc: 68.97%\n",
            "Epoch 6207/10000, Train Loss: 0.6130, Train Acc: 64.74%, Test Loss: 0.5612, Test Acc: 68.97%\n",
            "Epoch 6208/10000, Train Loss: 0.6359, Train Acc: 63.58%, Test Loss: 0.5670, Test Acc: 68.97%\n",
            "Epoch 6209/10000, Train Loss: 0.6027, Train Acc: 65.61%, Test Loss: 0.5685, Test Acc: 67.24%\n",
            "Epoch 6210/10000, Train Loss: 0.6029, Train Acc: 65.61%, Test Loss: 0.5655, Test Acc: 68.97%\n",
            "Epoch 6211/10000, Train Loss: 0.6079, Train Acc: 67.34%, Test Loss: 0.5609, Test Acc: 70.69%\n",
            "Epoch 6212/10000, Train Loss: 0.6112, Train Acc: 63.29%, Test Loss: 0.5570, Test Acc: 75.86%\n",
            "Epoch 6213/10000, Train Loss: 0.6414, Train Acc: 61.56%, Test Loss: 0.5569, Test Acc: 74.14%\n",
            "Epoch 6214/10000, Train Loss: 0.6251, Train Acc: 62.72%, Test Loss: 0.5581, Test Acc: 74.14%\n",
            "Epoch 6215/10000, Train Loss: 0.6327, Train Acc: 64.74%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 6216/10000, Train Loss: 0.6069, Train Acc: 65.32%, Test Loss: 0.5553, Test Acc: 74.14%\n",
            "Epoch 6217/10000, Train Loss: 0.6159, Train Acc: 66.18%, Test Loss: 0.5534, Test Acc: 74.14%\n",
            "Epoch 6218/10000, Train Loss: 0.6172, Train Acc: 65.61%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 6219/10000, Train Loss: 0.6178, Train Acc: 64.16%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 6220/10000, Train Loss: 0.6083, Train Acc: 63.29%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6221/10000, Train Loss: 0.6042, Train Acc: 65.61%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 6222/10000, Train Loss: 0.6045, Train Acc: 65.03%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 6223/10000, Train Loss: 0.6169, Train Acc: 67.34%, Test Loss: 0.5584, Test Acc: 70.69%\n",
            "Epoch 6224/10000, Train Loss: 0.6276, Train Acc: 64.16%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6225/10000, Train Loss: 0.6092, Train Acc: 62.72%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 6226/10000, Train Loss: 0.6118, Train Acc: 65.90%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 6227/10000, Train Loss: 0.6228, Train Acc: 64.45%, Test Loss: 0.5605, Test Acc: 72.41%\n",
            "Epoch 6228/10000, Train Loss: 0.6253, Train Acc: 64.74%, Test Loss: 0.5634, Test Acc: 70.69%\n",
            "Epoch 6229/10000, Train Loss: 0.5982, Train Acc: 67.34%, Test Loss: 0.5652, Test Acc: 68.97%\n",
            "Epoch 6230/10000, Train Loss: 0.5946, Train Acc: 68.21%, Test Loss: 0.5685, Test Acc: 67.24%\n",
            "Epoch 6231/10000, Train Loss: 0.6272, Train Acc: 65.90%, Test Loss: 0.5610, Test Acc: 68.97%\n",
            "Epoch 6232/10000, Train Loss: 0.6183, Train Acc: 64.74%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 6233/10000, Train Loss: 0.5933, Train Acc: 64.45%, Test Loss: 0.5585, Test Acc: 72.41%\n",
            "Epoch 6234/10000, Train Loss: 0.6192, Train Acc: 65.32%, Test Loss: 0.5582, Test Acc: 74.14%\n",
            "Epoch 6235/10000, Train Loss: 0.6209, Train Acc: 61.56%, Test Loss: 0.5596, Test Acc: 75.86%\n",
            "Epoch 6236/10000, Train Loss: 0.6256, Train Acc: 67.34%, Test Loss: 0.5529, Test Acc: 74.14%\n",
            "Epoch 6237/10000, Train Loss: 0.6065, Train Acc: 65.03%, Test Loss: 0.5514, Test Acc: 74.14%\n",
            "Epoch 6238/10000, Train Loss: 0.6014, Train Acc: 69.36%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 6239/10000, Train Loss: 0.6277, Train Acc: 64.45%, Test Loss: 0.5541, Test Acc: 74.14%\n",
            "Epoch 6240/10000, Train Loss: 0.6108, Train Acc: 63.58%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 6241/10000, Train Loss: 0.6167, Train Acc: 68.21%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 6242/10000, Train Loss: 0.6072, Train Acc: 64.74%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 6243/10000, Train Loss: 0.6104, Train Acc: 66.18%, Test Loss: 0.5498, Test Acc: 70.69%\n",
            "Epoch 6244/10000, Train Loss: 0.6445, Train Acc: 64.16%, Test Loss: 0.5511, Test Acc: 72.41%\n",
            "Epoch 6245/10000, Train Loss: 0.6164, Train Acc: 63.01%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 6246/10000, Train Loss: 0.6079, Train Acc: 64.74%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 6247/10000, Train Loss: 0.6210, Train Acc: 63.29%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6248/10000, Train Loss: 0.5988, Train Acc: 66.18%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 6249/10000, Train Loss: 0.6053, Train Acc: 67.63%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 6250/10000, Train Loss: 0.6039, Train Acc: 63.58%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 6251/10000, Train Loss: 0.6056, Train Acc: 65.03%, Test Loss: 0.5516, Test Acc: 70.69%\n",
            "Epoch 6252/10000, Train Loss: 0.6053, Train Acc: 67.63%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 6253/10000, Train Loss: 0.6449, Train Acc: 63.58%, Test Loss: 0.5596, Test Acc: 72.41%\n",
            "Epoch 6254/10000, Train Loss: 0.6474, Train Acc: 63.01%, Test Loss: 0.5600, Test Acc: 68.97%\n",
            "Epoch 6255/10000, Train Loss: 0.6052, Train Acc: 69.08%, Test Loss: 0.5586, Test Acc: 72.41%\n",
            "Epoch 6256/10000, Train Loss: 0.5996, Train Acc: 65.32%, Test Loss: 0.5586, Test Acc: 74.14%\n",
            "Epoch 6257/10000, Train Loss: 0.6218, Train Acc: 62.72%, Test Loss: 0.5555, Test Acc: 74.14%\n",
            "Epoch 6258/10000, Train Loss: 0.6546, Train Acc: 63.58%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 6259/10000, Train Loss: 0.6236, Train Acc: 65.32%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 6260/10000, Train Loss: 0.6313, Train Acc: 62.14%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 6261/10000, Train Loss: 0.6091, Train Acc: 64.74%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 6262/10000, Train Loss: 0.6135, Train Acc: 64.74%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 6263/10000, Train Loss: 0.6286, Train Acc: 64.16%, Test Loss: 0.5553, Test Acc: 74.14%\n",
            "Epoch 6264/10000, Train Loss: 0.6164, Train Acc: 63.58%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 6265/10000, Train Loss: 0.6102, Train Acc: 66.18%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 6266/10000, Train Loss: 0.6216, Train Acc: 65.32%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 6267/10000, Train Loss: 0.6134, Train Acc: 62.14%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 6268/10000, Train Loss: 0.6231, Train Acc: 62.43%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 6269/10000, Train Loss: 0.6087, Train Acc: 62.14%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 6270/10000, Train Loss: 0.6238, Train Acc: 65.90%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 6271/10000, Train Loss: 0.6251, Train Acc: 65.03%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 6272/10000, Train Loss: 0.6236, Train Acc: 60.40%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 6273/10000, Train Loss: 0.6110, Train Acc: 64.74%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 6274/10000, Train Loss: 0.6219, Train Acc: 65.32%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 6275/10000, Train Loss: 0.6046, Train Acc: 65.61%, Test Loss: 0.5546, Test Acc: 75.86%\n",
            "Epoch 6276/10000, Train Loss: 0.6280, Train Acc: 65.32%, Test Loss: 0.5521, Test Acc: 74.14%\n",
            "Epoch 6277/10000, Train Loss: 0.6184, Train Acc: 64.45%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 6278/10000, Train Loss: 0.6131, Train Acc: 64.45%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 6279/10000, Train Loss: 0.6175, Train Acc: 64.74%, Test Loss: 0.5566, Test Acc: 74.14%\n",
            "Epoch 6280/10000, Train Loss: 0.6021, Train Acc: 64.45%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 6281/10000, Train Loss: 0.6011, Train Acc: 65.32%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 6282/10000, Train Loss: 0.6119, Train Acc: 63.87%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 6283/10000, Train Loss: 0.6044, Train Acc: 69.08%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 6284/10000, Train Loss: 0.5926, Train Acc: 68.79%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 6285/10000, Train Loss: 0.6015, Train Acc: 66.76%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 6286/10000, Train Loss: 0.6005, Train Acc: 65.03%, Test Loss: 0.5589, Test Acc: 72.41%\n",
            "Epoch 6287/10000, Train Loss: 0.6159, Train Acc: 65.32%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6288/10000, Train Loss: 0.6090, Train Acc: 69.36%, Test Loss: 0.5602, Test Acc: 68.97%\n",
            "Epoch 6289/10000, Train Loss: 0.6195, Train Acc: 66.18%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 6290/10000, Train Loss: 0.6003, Train Acc: 65.90%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 6291/10000, Train Loss: 0.6168, Train Acc: 64.16%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 6292/10000, Train Loss: 0.6509, Train Acc: 62.72%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 6293/10000, Train Loss: 0.6233, Train Acc: 64.45%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6294/10000, Train Loss: 0.6149, Train Acc: 67.05%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 6295/10000, Train Loss: 0.6277, Train Acc: 61.56%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 6296/10000, Train Loss: 0.6279, Train Acc: 65.32%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 6297/10000, Train Loss: 0.5896, Train Acc: 67.05%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 6298/10000, Train Loss: 0.6409, Train Acc: 63.01%, Test Loss: 0.5620, Test Acc: 68.97%\n",
            "Epoch 6299/10000, Train Loss: 0.6298, Train Acc: 64.74%, Test Loss: 0.5600, Test Acc: 68.97%\n",
            "Epoch 6300/10000, Train Loss: 0.6085, Train Acc: 64.45%, Test Loss: 0.5570, Test Acc: 70.69%\n",
            "Epoch 6301/10000, Train Loss: 0.5862, Train Acc: 66.76%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 6302/10000, Train Loss: 0.6206, Train Acc: 65.90%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 6303/10000, Train Loss: 0.6230, Train Acc: 65.61%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 6304/10000, Train Loss: 0.6193, Train Acc: 62.14%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 6305/10000, Train Loss: 0.6083, Train Acc: 64.74%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 6306/10000, Train Loss: 0.6058, Train Acc: 67.34%, Test Loss: 0.5536, Test Acc: 74.14%\n",
            "Epoch 6307/10000, Train Loss: 0.6038, Train Acc: 65.90%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 6308/10000, Train Loss: 0.6192, Train Acc: 65.61%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 6309/10000, Train Loss: 0.6211, Train Acc: 64.45%, Test Loss: 0.5592, Test Acc: 70.69%\n",
            "Epoch 6310/10000, Train Loss: 0.6344, Train Acc: 64.16%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 6311/10000, Train Loss: 0.5920, Train Acc: 67.05%, Test Loss: 0.5587, Test Acc: 72.41%\n",
            "Epoch 6312/10000, Train Loss: 0.6044, Train Acc: 65.03%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 6313/10000, Train Loss: 0.6051, Train Acc: 67.92%, Test Loss: 0.5569, Test Acc: 74.14%\n",
            "Epoch 6314/10000, Train Loss: 0.6283, Train Acc: 63.29%, Test Loss: 0.5531, Test Acc: 74.14%\n",
            "Epoch 6315/10000, Train Loss: 0.6358, Train Acc: 63.58%, Test Loss: 0.5496, Test Acc: 70.69%\n",
            "Epoch 6316/10000, Train Loss: 0.6294, Train Acc: 61.27%, Test Loss: 0.5492, Test Acc: 70.69%\n",
            "Epoch 6317/10000, Train Loss: 0.6260, Train Acc: 65.61%, Test Loss: 0.5492, Test Acc: 70.69%\n",
            "Epoch 6318/10000, Train Loss: 0.6298, Train Acc: 63.87%, Test Loss: 0.5509, Test Acc: 74.14%\n",
            "Epoch 6319/10000, Train Loss: 0.5930, Train Acc: 66.47%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 6320/10000, Train Loss: 0.5915, Train Acc: 65.90%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 6321/10000, Train Loss: 0.6253, Train Acc: 64.16%, Test Loss: 0.5545, Test Acc: 74.14%\n",
            "Epoch 6322/10000, Train Loss: 0.6172, Train Acc: 66.18%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 6323/10000, Train Loss: 0.6144, Train Acc: 65.61%, Test Loss: 0.5505, Test Acc: 70.69%\n",
            "Epoch 6324/10000, Train Loss: 0.6290, Train Acc: 67.63%, Test Loss: 0.5489, Test Acc: 70.69%\n",
            "Epoch 6325/10000, Train Loss: 0.6485, Train Acc: 65.32%, Test Loss: 0.5499, Test Acc: 70.69%\n",
            "Epoch 6326/10000, Train Loss: 0.6232, Train Acc: 63.58%, Test Loss: 0.5497, Test Acc: 68.97%\n",
            "Epoch 6327/10000, Train Loss: 0.6233, Train Acc: 64.74%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 6328/10000, Train Loss: 0.6579, Train Acc: 64.16%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 6329/10000, Train Loss: 0.6198, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 6330/10000, Train Loss: 0.6089, Train Acc: 66.18%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 6331/10000, Train Loss: 0.6014, Train Acc: 66.47%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 6332/10000, Train Loss: 0.5882, Train Acc: 68.79%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 6333/10000, Train Loss: 0.6141, Train Acc: 65.32%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 6334/10000, Train Loss: 0.6285, Train Acc: 64.16%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 6335/10000, Train Loss: 0.6033, Train Acc: 66.76%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 6336/10000, Train Loss: 0.5971, Train Acc: 65.90%, Test Loss: 0.5584, Test Acc: 72.41%\n",
            "Epoch 6337/10000, Train Loss: 0.6361, Train Acc: 66.18%, Test Loss: 0.5544, Test Acc: 74.14%\n",
            "Epoch 6338/10000, Train Loss: 0.6208, Train Acc: 60.69%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 6339/10000, Train Loss: 0.6191, Train Acc: 65.90%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 6340/10000, Train Loss: 0.6354, Train Acc: 63.29%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 6341/10000, Train Loss: 0.6207, Train Acc: 64.16%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 6342/10000, Train Loss: 0.5907, Train Acc: 67.92%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 6343/10000, Train Loss: 0.6165, Train Acc: 63.01%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6344/10000, Train Loss: 0.6017, Train Acc: 68.21%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 6345/10000, Train Loss: 0.6134, Train Acc: 65.61%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 6346/10000, Train Loss: 0.5972, Train Acc: 66.18%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 6347/10000, Train Loss: 0.6032, Train Acc: 66.18%, Test Loss: 0.5646, Test Acc: 68.97%\n",
            "Epoch 6348/10000, Train Loss: 0.6271, Train Acc: 64.74%, Test Loss: 0.5641, Test Acc: 70.69%\n",
            "Epoch 6349/10000, Train Loss: 0.6059, Train Acc: 65.61%, Test Loss: 0.5654, Test Acc: 70.69%\n",
            "Epoch 6350/10000, Train Loss: 0.6243, Train Acc: 65.03%, Test Loss: 0.5627, Test Acc: 68.97%\n",
            "Epoch 6351/10000, Train Loss: 0.6087, Train Acc: 67.63%, Test Loss: 0.5623, Test Acc: 70.69%\n",
            "Epoch 6352/10000, Train Loss: 0.6215, Train Acc: 67.63%, Test Loss: 0.5565, Test Acc: 74.14%\n",
            "Epoch 6353/10000, Train Loss: 0.5984, Train Acc: 66.76%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 6354/10000, Train Loss: 0.6349, Train Acc: 62.43%, Test Loss: 0.5531, Test Acc: 74.14%\n",
            "Epoch 6355/10000, Train Loss: 0.6037, Train Acc: 63.58%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 6356/10000, Train Loss: 0.6231, Train Acc: 64.16%, Test Loss: 0.5541, Test Acc: 74.14%\n",
            "Epoch 6357/10000, Train Loss: 0.6513, Train Acc: 61.56%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 6358/10000, Train Loss: 0.6168, Train Acc: 65.32%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6359/10000, Train Loss: 0.6431, Train Acc: 64.45%, Test Loss: 0.5542, Test Acc: 74.14%\n",
            "Epoch 6360/10000, Train Loss: 0.6227, Train Acc: 64.45%, Test Loss: 0.5552, Test Acc: 74.14%\n",
            "Epoch 6361/10000, Train Loss: 0.6068, Train Acc: 62.43%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 6362/10000, Train Loss: 0.6084, Train Acc: 63.29%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 6363/10000, Train Loss: 0.6114, Train Acc: 64.45%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6364/10000, Train Loss: 0.6313, Train Acc: 65.03%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 6365/10000, Train Loss: 0.6153, Train Acc: 65.32%, Test Loss: 0.5474, Test Acc: 74.14%\n",
            "Epoch 6366/10000, Train Loss: 0.6026, Train Acc: 63.87%, Test Loss: 0.5464, Test Acc: 72.41%\n",
            "Epoch 6367/10000, Train Loss: 0.5976, Train Acc: 63.01%, Test Loss: 0.5463, Test Acc: 70.69%\n",
            "Epoch 6368/10000, Train Loss: 0.6193, Train Acc: 67.34%, Test Loss: 0.5490, Test Acc: 68.97%\n",
            "Epoch 6369/10000, Train Loss: 0.6039, Train Acc: 65.03%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 6370/10000, Train Loss: 0.6030, Train Acc: 64.45%, Test Loss: 0.5525, Test Acc: 70.69%\n",
            "Epoch 6371/10000, Train Loss: 0.6349, Train Acc: 62.43%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 6372/10000, Train Loss: 0.6207, Train Acc: 61.56%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 6373/10000, Train Loss: 0.6333, Train Acc: 63.29%, Test Loss: 0.5632, Test Acc: 70.69%\n",
            "Epoch 6374/10000, Train Loss: 0.6093, Train Acc: 64.16%, Test Loss: 0.5637, Test Acc: 68.97%\n",
            "Epoch 6375/10000, Train Loss: 0.6010, Train Acc: 64.16%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 6376/10000, Train Loss: 0.6384, Train Acc: 62.43%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6377/10000, Train Loss: 0.6173, Train Acc: 66.18%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 6378/10000, Train Loss: 0.6078, Train Acc: 65.32%, Test Loss: 0.5514, Test Acc: 74.14%\n",
            "Epoch 6379/10000, Train Loss: 0.5889, Train Acc: 65.32%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 6380/10000, Train Loss: 0.6245, Train Acc: 65.32%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 6381/10000, Train Loss: 0.6073, Train Acc: 65.32%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 6382/10000, Train Loss: 0.5985, Train Acc: 66.76%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 6383/10000, Train Loss: 0.6226, Train Acc: 66.18%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 6384/10000, Train Loss: 0.6153, Train Acc: 63.58%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 6385/10000, Train Loss: 0.6078, Train Acc: 65.90%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6386/10000, Train Loss: 0.6229, Train Acc: 61.85%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 6387/10000, Train Loss: 0.6391, Train Acc: 65.03%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 6388/10000, Train Loss: 0.6039, Train Acc: 64.45%, Test Loss: 0.5652, Test Acc: 72.41%\n",
            "Epoch 6389/10000, Train Loss: 0.6224, Train Acc: 64.45%, Test Loss: 0.5700, Test Acc: 68.97%\n",
            "Epoch 6390/10000, Train Loss: 0.6392, Train Acc: 63.01%, Test Loss: 0.5632, Test Acc: 68.97%\n",
            "Epoch 6391/10000, Train Loss: 0.6207, Train Acc: 66.76%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 6392/10000, Train Loss: 0.6195, Train Acc: 61.27%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 6393/10000, Train Loss: 0.6248, Train Acc: 67.05%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 6394/10000, Train Loss: 0.6339, Train Acc: 61.85%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 6395/10000, Train Loss: 0.6211, Train Acc: 62.14%, Test Loss: 0.5559, Test Acc: 74.14%\n",
            "Epoch 6396/10000, Train Loss: 0.6104, Train Acc: 65.32%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 6397/10000, Train Loss: 0.6168, Train Acc: 63.87%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 6398/10000, Train Loss: 0.6171, Train Acc: 65.61%, Test Loss: 0.5556, Test Acc: 74.14%\n",
            "Epoch 6399/10000, Train Loss: 0.6169, Train Acc: 60.12%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 6400/10000, Train Loss: 0.6257, Train Acc: 65.90%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 6401/10000, Train Loss: 0.6159, Train Acc: 64.74%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 6402/10000, Train Loss: 0.6163, Train Acc: 63.87%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 6403/10000, Train Loss: 0.5930, Train Acc: 64.45%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 6404/10000, Train Loss: 0.6097, Train Acc: 65.32%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 6405/10000, Train Loss: 0.6282, Train Acc: 65.03%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 6406/10000, Train Loss: 0.6176, Train Acc: 65.61%, Test Loss: 0.5515, Test Acc: 72.41%\n",
            "Epoch 6407/10000, Train Loss: 0.6171, Train Acc: 65.61%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 6408/10000, Train Loss: 0.6036, Train Acc: 65.90%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 6409/10000, Train Loss: 0.6146, Train Acc: 65.90%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 6410/10000, Train Loss: 0.6134, Train Acc: 66.76%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 6411/10000, Train Loss: 0.6490, Train Acc: 63.29%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 6412/10000, Train Loss: 0.6094, Train Acc: 67.92%, Test Loss: 0.5585, Test Acc: 70.69%\n",
            "Epoch 6413/10000, Train Loss: 0.6237, Train Acc: 65.61%, Test Loss: 0.5625, Test Acc: 70.69%\n",
            "Epoch 6414/10000, Train Loss: 0.6348, Train Acc: 62.72%, Test Loss: 0.5678, Test Acc: 72.41%\n",
            "Epoch 6415/10000, Train Loss: 0.6013, Train Acc: 67.34%, Test Loss: 0.5727, Test Acc: 68.97%\n",
            "Epoch 6416/10000, Train Loss: 0.6035, Train Acc: 66.47%, Test Loss: 0.5661, Test Acc: 70.69%\n",
            "Epoch 6417/10000, Train Loss: 0.5913, Train Acc: 65.32%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 6418/10000, Train Loss: 0.6151, Train Acc: 65.61%, Test Loss: 0.5596, Test Acc: 74.14%\n",
            "Epoch 6419/10000, Train Loss: 0.6049, Train Acc: 65.03%, Test Loss: 0.5589, Test Acc: 74.14%\n",
            "Epoch 6420/10000, Train Loss: 0.6192, Train Acc: 64.16%, Test Loss: 0.5571, Test Acc: 74.14%\n",
            "Epoch 6421/10000, Train Loss: 0.6022, Train Acc: 66.76%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 6422/10000, Train Loss: 0.6226, Train Acc: 63.87%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 6423/10000, Train Loss: 0.6130, Train Acc: 65.03%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 6424/10000, Train Loss: 0.6278, Train Acc: 68.50%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6425/10000, Train Loss: 0.6167, Train Acc: 63.87%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 6426/10000, Train Loss: 0.6120, Train Acc: 64.74%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 6427/10000, Train Loss: 0.6373, Train Acc: 64.74%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 6428/10000, Train Loss: 0.6257, Train Acc: 65.03%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 6429/10000, Train Loss: 0.6105, Train Acc: 63.58%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 6430/10000, Train Loss: 0.6176, Train Acc: 61.85%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 6431/10000, Train Loss: 0.6344, Train Acc: 67.92%, Test Loss: 0.5588, Test Acc: 70.69%\n",
            "Epoch 6432/10000, Train Loss: 0.6156, Train Acc: 63.87%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 6433/10000, Train Loss: 0.6256, Train Acc: 67.92%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 6434/10000, Train Loss: 0.6249, Train Acc: 61.85%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 6435/10000, Train Loss: 0.6129, Train Acc: 61.85%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 6436/10000, Train Loss: 0.6156, Train Acc: 61.85%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 6437/10000, Train Loss: 0.6142, Train Acc: 63.29%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 6438/10000, Train Loss: 0.6398, Train Acc: 63.01%, Test Loss: 0.5611, Test Acc: 68.97%\n",
            "Epoch 6439/10000, Train Loss: 0.6060, Train Acc: 64.74%, Test Loss: 0.5586, Test Acc: 70.69%\n",
            "Epoch 6440/10000, Train Loss: 0.5935, Train Acc: 63.58%, Test Loss: 0.5566, Test Acc: 74.14%\n",
            "Epoch 6441/10000, Train Loss: 0.6343, Train Acc: 61.85%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 6442/10000, Train Loss: 0.6124, Train Acc: 64.74%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 6443/10000, Train Loss: 0.6216, Train Acc: 67.92%, Test Loss: 0.5583, Test Acc: 70.69%\n",
            "Epoch 6444/10000, Train Loss: 0.5989, Train Acc: 63.87%, Test Loss: 0.5619, Test Acc: 68.97%\n",
            "Epoch 6445/10000, Train Loss: 0.6146, Train Acc: 67.63%, Test Loss: 0.5624, Test Acc: 70.69%\n",
            "Epoch 6446/10000, Train Loss: 0.5948, Train Acc: 68.50%, Test Loss: 0.5627, Test Acc: 68.97%\n",
            "Epoch 6447/10000, Train Loss: 0.6022, Train Acc: 66.76%, Test Loss: 0.5636, Test Acc: 68.97%\n",
            "Epoch 6448/10000, Train Loss: 0.6172, Train Acc: 67.34%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 6449/10000, Train Loss: 0.6036, Train Acc: 66.18%, Test Loss: 0.5583, Test Acc: 74.14%\n",
            "Epoch 6450/10000, Train Loss: 0.6091, Train Acc: 63.87%, Test Loss: 0.5579, Test Acc: 74.14%\n",
            "Epoch 6451/10000, Train Loss: 0.5996, Train Acc: 67.34%, Test Loss: 0.5578, Test Acc: 74.14%\n",
            "Epoch 6452/10000, Train Loss: 0.5981, Train Acc: 66.18%, Test Loss: 0.5616, Test Acc: 70.69%\n",
            "Epoch 6453/10000, Train Loss: 0.6374, Train Acc: 65.32%, Test Loss: 0.5604, Test Acc: 72.41%\n",
            "Epoch 6454/10000, Train Loss: 0.6172, Train Acc: 65.90%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 6455/10000, Train Loss: 0.6224, Train Acc: 64.16%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 6456/10000, Train Loss: 0.6096, Train Acc: 68.79%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 6457/10000, Train Loss: 0.5985, Train Acc: 65.61%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 6458/10000, Train Loss: 0.6299, Train Acc: 64.74%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 6459/10000, Train Loss: 0.6071, Train Acc: 65.61%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 6460/10000, Train Loss: 0.5917, Train Acc: 64.45%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 6461/10000, Train Loss: 0.6168, Train Acc: 63.29%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 6462/10000, Train Loss: 0.6082, Train Acc: 65.03%, Test Loss: 0.5609, Test Acc: 72.41%\n",
            "Epoch 6463/10000, Train Loss: 0.6099, Train Acc: 66.18%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 6464/10000, Train Loss: 0.6128, Train Acc: 64.45%, Test Loss: 0.5579, Test Acc: 74.14%\n",
            "Epoch 6465/10000, Train Loss: 0.6327, Train Acc: 63.87%, Test Loss: 0.5571, Test Acc: 74.14%\n",
            "Epoch 6466/10000, Train Loss: 0.6182, Train Acc: 63.87%, Test Loss: 0.5556, Test Acc: 72.41%\n",
            "Epoch 6467/10000, Train Loss: 0.6279, Train Acc: 63.58%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 6468/10000, Train Loss: 0.5914, Train Acc: 67.92%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 6469/10000, Train Loss: 0.6290, Train Acc: 64.16%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 6470/10000, Train Loss: 0.6343, Train Acc: 61.56%, Test Loss: 0.5563, Test Acc: 70.69%\n",
            "Epoch 6471/10000, Train Loss: 0.6065, Train Acc: 66.18%, Test Loss: 0.5596, Test Acc: 70.69%\n",
            "Epoch 6472/10000, Train Loss: 0.6375, Train Acc: 65.03%, Test Loss: 0.5606, Test Acc: 70.69%\n",
            "Epoch 6473/10000, Train Loss: 0.6232, Train Acc: 63.29%, Test Loss: 0.5658, Test Acc: 70.69%\n",
            "Epoch 6474/10000, Train Loss: 0.6010, Train Acc: 67.92%, Test Loss: 0.5671, Test Acc: 68.97%\n",
            "Epoch 6475/10000, Train Loss: 0.6045, Train Acc: 66.18%, Test Loss: 0.5629, Test Acc: 68.97%\n",
            "Epoch 6476/10000, Train Loss: 0.6341, Train Acc: 63.58%, Test Loss: 0.5579, Test Acc: 74.14%\n",
            "Epoch 6477/10000, Train Loss: 0.6190, Train Acc: 64.74%, Test Loss: 0.5588, Test Acc: 74.14%\n",
            "Epoch 6478/10000, Train Loss: 0.6160, Train Acc: 61.27%, Test Loss: 0.5544, Test Acc: 74.14%\n",
            "Epoch 6479/10000, Train Loss: 0.6044, Train Acc: 63.58%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 6480/10000, Train Loss: 0.6235, Train Acc: 66.47%, Test Loss: 0.5513, Test Acc: 74.14%\n",
            "Epoch 6481/10000, Train Loss: 0.6301, Train Acc: 67.34%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 6482/10000, Train Loss: 0.6046, Train Acc: 65.61%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 6483/10000, Train Loss: 0.5876, Train Acc: 67.05%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6484/10000, Train Loss: 0.6107, Train Acc: 67.92%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 6485/10000, Train Loss: 0.6020, Train Acc: 65.03%, Test Loss: 0.5643, Test Acc: 68.97%\n",
            "Epoch 6486/10000, Train Loss: 0.5991, Train Acc: 62.43%, Test Loss: 0.5618, Test Acc: 70.69%\n",
            "Epoch 6487/10000, Train Loss: 0.6037, Train Acc: 65.90%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 6488/10000, Train Loss: 0.6068, Train Acc: 63.87%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 6489/10000, Train Loss: 0.6268, Train Acc: 66.47%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 6490/10000, Train Loss: 0.6236, Train Acc: 62.43%, Test Loss: 0.5606, Test Acc: 68.97%\n",
            "Epoch 6491/10000, Train Loss: 0.6211, Train Acc: 66.47%, Test Loss: 0.5623, Test Acc: 72.41%\n",
            "Epoch 6492/10000, Train Loss: 0.6289, Train Acc: 61.27%, Test Loss: 0.5616, Test Acc: 72.41%\n",
            "Epoch 6493/10000, Train Loss: 0.6252, Train Acc: 63.58%, Test Loss: 0.5582, Test Acc: 74.14%\n",
            "Epoch 6494/10000, Train Loss: 0.6009, Train Acc: 63.87%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 6495/10000, Train Loss: 0.6138, Train Acc: 63.87%, Test Loss: 0.5560, Test Acc: 74.14%\n",
            "Epoch 6496/10000, Train Loss: 0.6117, Train Acc: 67.63%, Test Loss: 0.5570, Test Acc: 70.69%\n",
            "Epoch 6497/10000, Train Loss: 0.6038, Train Acc: 65.32%, Test Loss: 0.5559, Test Acc: 74.14%\n",
            "Epoch 6498/10000, Train Loss: 0.6250, Train Acc: 62.43%, Test Loss: 0.5565, Test Acc: 72.41%\n",
            "Epoch 6499/10000, Train Loss: 0.6097, Train Acc: 65.32%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 6500/10000, Train Loss: 0.6057, Train Acc: 64.45%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 6501/10000, Train Loss: 0.6252, Train Acc: 61.27%, Test Loss: 0.5510, Test Acc: 74.14%\n",
            "Epoch 6502/10000, Train Loss: 0.5867, Train Acc: 68.79%, Test Loss: 0.5507, Test Acc: 70.69%\n",
            "Epoch 6503/10000, Train Loss: 0.5975, Train Acc: 67.63%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 6504/10000, Train Loss: 0.6129, Train Acc: 62.72%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 6505/10000, Train Loss: 0.6356, Train Acc: 67.34%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 6506/10000, Train Loss: 0.6140, Train Acc: 65.61%, Test Loss: 0.5625, Test Acc: 70.69%\n",
            "Epoch 6507/10000, Train Loss: 0.6127, Train Acc: 65.32%, Test Loss: 0.5641, Test Acc: 70.69%\n",
            "Epoch 6508/10000, Train Loss: 0.6015, Train Acc: 63.87%, Test Loss: 0.5640, Test Acc: 68.97%\n",
            "Epoch 6509/10000, Train Loss: 0.6149, Train Acc: 61.56%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 6510/10000, Train Loss: 0.6149, Train Acc: 64.45%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 6511/10000, Train Loss: 0.6135, Train Acc: 66.18%, Test Loss: 0.5584, Test Acc: 74.14%\n",
            "Epoch 6512/10000, Train Loss: 0.6409, Train Acc: 64.74%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 6513/10000, Train Loss: 0.5828, Train Acc: 64.16%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 6514/10000, Train Loss: 0.6161, Train Acc: 65.03%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 6515/10000, Train Loss: 0.6062, Train Acc: 64.74%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 6516/10000, Train Loss: 0.6339, Train Acc: 66.18%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 6517/10000, Train Loss: 0.6160, Train Acc: 68.50%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6518/10000, Train Loss: 0.6113, Train Acc: 68.50%, Test Loss: 0.5619, Test Acc: 68.97%\n",
            "Epoch 6519/10000, Train Loss: 0.6134, Train Acc: 61.85%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 6520/10000, Train Loss: 0.5943, Train Acc: 64.16%, Test Loss: 0.5578, Test Acc: 74.14%\n",
            "Epoch 6521/10000, Train Loss: 0.6216, Train Acc: 63.29%, Test Loss: 0.5591, Test Acc: 72.41%\n",
            "Epoch 6522/10000, Train Loss: 0.6107, Train Acc: 67.34%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 6523/10000, Train Loss: 0.6050, Train Acc: 67.05%, Test Loss: 0.5500, Test Acc: 72.41%\n",
            "Epoch 6524/10000, Train Loss: 0.6058, Train Acc: 68.21%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 6525/10000, Train Loss: 0.6077, Train Acc: 65.90%, Test Loss: 0.5517, Test Acc: 74.14%\n",
            "Epoch 6526/10000, Train Loss: 0.6128, Train Acc: 67.34%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 6527/10000, Train Loss: 0.5981, Train Acc: 67.63%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 6528/10000, Train Loss: 0.6138, Train Acc: 63.01%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6529/10000, Train Loss: 0.6333, Train Acc: 63.29%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 6530/10000, Train Loss: 0.6003, Train Acc: 64.74%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 6531/10000, Train Loss: 0.6172, Train Acc: 66.18%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 6532/10000, Train Loss: 0.6275, Train Acc: 63.01%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 6533/10000, Train Loss: 0.6021, Train Acc: 64.45%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 6534/10000, Train Loss: 0.5960, Train Acc: 64.45%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 6535/10000, Train Loss: 0.6153, Train Acc: 62.43%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6536/10000, Train Loss: 0.6118, Train Acc: 65.90%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 6537/10000, Train Loss: 0.6016, Train Acc: 66.47%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 6538/10000, Train Loss: 0.5870, Train Acc: 66.76%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 6539/10000, Train Loss: 0.6177, Train Acc: 64.74%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 6540/10000, Train Loss: 0.6298, Train Acc: 63.87%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 6541/10000, Train Loss: 0.6077, Train Acc: 61.85%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 6542/10000, Train Loss: 0.6221, Train Acc: 62.72%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 6543/10000, Train Loss: 0.6121, Train Acc: 66.47%, Test Loss: 0.5580, Test Acc: 74.14%\n",
            "Epoch 6544/10000, Train Loss: 0.6039, Train Acc: 64.16%, Test Loss: 0.5558, Test Acc: 74.14%\n",
            "Epoch 6545/10000, Train Loss: 0.6036, Train Acc: 65.32%, Test Loss: 0.5555, Test Acc: 74.14%\n",
            "Epoch 6546/10000, Train Loss: 0.6100, Train Acc: 67.05%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 6547/10000, Train Loss: 0.6059, Train Acc: 68.21%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 6548/10000, Train Loss: 0.6354, Train Acc: 62.43%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 6549/10000, Train Loss: 0.6290, Train Acc: 59.83%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 6550/10000, Train Loss: 0.6239, Train Acc: 63.01%, Test Loss: 0.5550, Test Acc: 74.14%\n",
            "Epoch 6551/10000, Train Loss: 0.6063, Train Acc: 65.61%, Test Loss: 0.5536, Test Acc: 74.14%\n",
            "Epoch 6552/10000, Train Loss: 0.5987, Train Acc: 68.21%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 6553/10000, Train Loss: 0.5948, Train Acc: 65.61%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 6554/10000, Train Loss: 0.6090, Train Acc: 63.58%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 6555/10000, Train Loss: 0.5959, Train Acc: 66.18%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 6556/10000, Train Loss: 0.5989, Train Acc: 68.50%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 6557/10000, Train Loss: 0.6118, Train Acc: 66.18%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 6558/10000, Train Loss: 0.6133, Train Acc: 65.03%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6559/10000, Train Loss: 0.6061, Train Acc: 65.32%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 6560/10000, Train Loss: 0.6232, Train Acc: 67.05%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 6561/10000, Train Loss: 0.6105, Train Acc: 65.90%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 6562/10000, Train Loss: 0.6385, Train Acc: 65.03%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 6563/10000, Train Loss: 0.6194, Train Acc: 62.43%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 6564/10000, Train Loss: 0.6251, Train Acc: 65.32%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 6565/10000, Train Loss: 0.5747, Train Acc: 69.36%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6566/10000, Train Loss: 0.6056, Train Acc: 64.16%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 6567/10000, Train Loss: 0.5910, Train Acc: 65.90%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 6568/10000, Train Loss: 0.6293, Train Acc: 66.76%, Test Loss: 0.5510, Test Acc: 68.97%\n",
            "Epoch 6569/10000, Train Loss: 0.6234, Train Acc: 63.87%, Test Loss: 0.5527, Test Acc: 74.14%\n",
            "Epoch 6570/10000, Train Loss: 0.6149, Train Acc: 65.90%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 6571/10000, Train Loss: 0.6143, Train Acc: 67.63%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6572/10000, Train Loss: 0.6577, Train Acc: 61.85%, Test Loss: 0.5609, Test Acc: 70.69%\n",
            "Epoch 6573/10000, Train Loss: 0.6337, Train Acc: 63.87%, Test Loss: 0.5579, Test Acc: 74.14%\n",
            "Epoch 6574/10000, Train Loss: 0.6209, Train Acc: 65.90%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 6575/10000, Train Loss: 0.5990, Train Acc: 65.61%, Test Loss: 0.5550, Test Acc: 74.14%\n",
            "Epoch 6576/10000, Train Loss: 0.6310, Train Acc: 63.58%, Test Loss: 0.5540, Test Acc: 74.14%\n",
            "Epoch 6577/10000, Train Loss: 0.6004, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 74.14%\n",
            "Epoch 6578/10000, Train Loss: 0.5925, Train Acc: 63.58%, Test Loss: 0.5538, Test Acc: 74.14%\n",
            "Epoch 6579/10000, Train Loss: 0.6109, Train Acc: 65.61%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 6580/10000, Train Loss: 0.6056, Train Acc: 65.61%, Test Loss: 0.5498, Test Acc: 68.97%\n",
            "Epoch 6581/10000, Train Loss: 0.6313, Train Acc: 64.45%, Test Loss: 0.5495, Test Acc: 68.97%\n",
            "Epoch 6582/10000, Train Loss: 0.6026, Train Acc: 62.72%, Test Loss: 0.5499, Test Acc: 68.97%\n",
            "Epoch 6583/10000, Train Loss: 0.6273, Train Acc: 64.16%, Test Loss: 0.5506, Test Acc: 68.97%\n",
            "Epoch 6584/10000, Train Loss: 0.6136, Train Acc: 65.32%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 6585/10000, Train Loss: 0.6183, Train Acc: 67.34%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 6586/10000, Train Loss: 0.6190, Train Acc: 63.87%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 6587/10000, Train Loss: 0.6191, Train Acc: 62.72%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 6588/10000, Train Loss: 0.6440, Train Acc: 59.83%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 6589/10000, Train Loss: 0.6419, Train Acc: 63.87%, Test Loss: 0.5589, Test Acc: 72.41%\n",
            "Epoch 6590/10000, Train Loss: 0.6013, Train Acc: 67.05%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 6591/10000, Train Loss: 0.6118, Train Acc: 65.03%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 6592/10000, Train Loss: 0.6115, Train Acc: 62.14%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 6593/10000, Train Loss: 0.6033, Train Acc: 66.47%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6594/10000, Train Loss: 0.6082, Train Acc: 65.03%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 6595/10000, Train Loss: 0.5862, Train Acc: 64.16%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 6596/10000, Train Loss: 0.6102, Train Acc: 62.43%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 6597/10000, Train Loss: 0.5987, Train Acc: 66.47%, Test Loss: 0.5496, Test Acc: 68.97%\n",
            "Epoch 6598/10000, Train Loss: 0.6094, Train Acc: 64.45%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 6599/10000, Train Loss: 0.6258, Train Acc: 65.90%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6600/10000, Train Loss: 0.6168, Train Acc: 64.45%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 6601/10000, Train Loss: 0.6017, Train Acc: 66.18%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 6602/10000, Train Loss: 0.6210, Train Acc: 63.58%, Test Loss: 0.5504, Test Acc: 72.41%\n",
            "Epoch 6603/10000, Train Loss: 0.6017, Train Acc: 68.21%, Test Loss: 0.5481, Test Acc: 70.69%\n",
            "Epoch 6604/10000, Train Loss: 0.6003, Train Acc: 66.76%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 6605/10000, Train Loss: 0.6297, Train Acc: 62.43%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 6606/10000, Train Loss: 0.6182, Train Acc: 63.29%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 6607/10000, Train Loss: 0.6016, Train Acc: 67.34%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 6608/10000, Train Loss: 0.6081, Train Acc: 66.18%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 6609/10000, Train Loss: 0.6180, Train Acc: 65.32%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 6610/10000, Train Loss: 0.6074, Train Acc: 65.03%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6611/10000, Train Loss: 0.6145, Train Acc: 65.32%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6612/10000, Train Loss: 0.6190, Train Acc: 64.74%, Test Loss: 0.5570, Test Acc: 70.69%\n",
            "Epoch 6613/10000, Train Loss: 0.6307, Train Acc: 64.16%, Test Loss: 0.5541, Test Acc: 74.14%\n",
            "Epoch 6614/10000, Train Loss: 0.6211, Train Acc: 65.90%, Test Loss: 0.5532, Test Acc: 74.14%\n",
            "Epoch 6615/10000, Train Loss: 0.6121, Train Acc: 63.58%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 6616/10000, Train Loss: 0.6052, Train Acc: 66.18%, Test Loss: 0.5521, Test Acc: 68.97%\n",
            "Epoch 6617/10000, Train Loss: 0.6250, Train Acc: 62.14%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 6618/10000, Train Loss: 0.6090, Train Acc: 67.63%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 6619/10000, Train Loss: 0.6194, Train Acc: 66.47%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 6620/10000, Train Loss: 0.6111, Train Acc: 63.58%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 6621/10000, Train Loss: 0.6118, Train Acc: 68.21%, Test Loss: 0.5487, Test Acc: 70.69%\n",
            "Epoch 6622/10000, Train Loss: 0.6555, Train Acc: 65.61%, Test Loss: 0.5471, Test Acc: 72.41%\n",
            "Epoch 6623/10000, Train Loss: 0.6159, Train Acc: 64.45%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 6624/10000, Train Loss: 0.6041, Train Acc: 67.63%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 6625/10000, Train Loss: 0.6073, Train Acc: 64.45%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 6626/10000, Train Loss: 0.6183, Train Acc: 66.47%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 6627/10000, Train Loss: 0.6152, Train Acc: 67.34%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 6628/10000, Train Loss: 0.5892, Train Acc: 65.90%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 6629/10000, Train Loss: 0.6524, Train Acc: 63.01%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 6630/10000, Train Loss: 0.6542, Train Acc: 60.12%, Test Loss: 0.5589, Test Acc: 70.69%\n",
            "Epoch 6631/10000, Train Loss: 0.6057, Train Acc: 67.63%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 6632/10000, Train Loss: 0.5969, Train Acc: 66.47%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 6633/10000, Train Loss: 0.5987, Train Acc: 66.47%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 6634/10000, Train Loss: 0.6057, Train Acc: 66.47%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 6635/10000, Train Loss: 0.6121, Train Acc: 65.03%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6636/10000, Train Loss: 0.6262, Train Acc: 58.96%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 6637/10000, Train Loss: 0.6039, Train Acc: 70.23%, Test Loss: 0.5600, Test Acc: 68.97%\n",
            "Epoch 6638/10000, Train Loss: 0.6347, Train Acc: 65.03%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 6639/10000, Train Loss: 0.6131, Train Acc: 65.90%, Test Loss: 0.5552, Test Acc: 70.69%\n",
            "Epoch 6640/10000, Train Loss: 0.6166, Train Acc: 66.76%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 6641/10000, Train Loss: 0.6126, Train Acc: 60.69%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 6642/10000, Train Loss: 0.6007, Train Acc: 65.61%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 6643/10000, Train Loss: 0.6027, Train Acc: 65.03%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 6644/10000, Train Loss: 0.5959, Train Acc: 66.76%, Test Loss: 0.5620, Test Acc: 70.69%\n",
            "Epoch 6645/10000, Train Loss: 0.6280, Train Acc: 67.05%, Test Loss: 0.5590, Test Acc: 68.97%\n",
            "Epoch 6646/10000, Train Loss: 0.6377, Train Acc: 60.12%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 6647/10000, Train Loss: 0.6322, Train Acc: 61.85%, Test Loss: 0.5523, Test Acc: 74.14%\n",
            "Epoch 6648/10000, Train Loss: 0.5918, Train Acc: 66.47%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 6649/10000, Train Loss: 0.5878, Train Acc: 65.61%, Test Loss: 0.5550, Test Acc: 74.14%\n",
            "Epoch 6650/10000, Train Loss: 0.6381, Train Acc: 65.32%, Test Loss: 0.5556, Test Acc: 74.14%\n",
            "Epoch 6651/10000, Train Loss: 0.6123, Train Acc: 66.76%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 6652/10000, Train Loss: 0.5997, Train Acc: 65.90%, Test Loss: 0.5580, Test Acc: 70.69%\n",
            "Epoch 6653/10000, Train Loss: 0.6417, Train Acc: 64.74%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 6654/10000, Train Loss: 0.5994, Train Acc: 68.50%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 6655/10000, Train Loss: 0.5951, Train Acc: 65.61%, Test Loss: 0.5599, Test Acc: 68.97%\n",
            "Epoch 6656/10000, Train Loss: 0.6286, Train Acc: 63.58%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6657/10000, Train Loss: 0.6218, Train Acc: 65.32%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 6658/10000, Train Loss: 0.6157, Train Acc: 62.14%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 6659/10000, Train Loss: 0.6146, Train Acc: 65.90%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 6660/10000, Train Loss: 0.5985, Train Acc: 64.16%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6661/10000, Train Loss: 0.5980, Train Acc: 66.47%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 6662/10000, Train Loss: 0.6208, Train Acc: 63.29%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 6663/10000, Train Loss: 0.6126, Train Acc: 66.18%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 6664/10000, Train Loss: 0.6083, Train Acc: 66.47%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 6665/10000, Train Loss: 0.6158, Train Acc: 67.63%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 6666/10000, Train Loss: 0.6093, Train Acc: 64.74%, Test Loss: 0.5566, Test Acc: 70.69%\n",
            "Epoch 6667/10000, Train Loss: 0.5981, Train Acc: 65.61%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 6668/10000, Train Loss: 0.6251, Train Acc: 66.47%, Test Loss: 0.5566, Test Acc: 74.14%\n",
            "Epoch 6669/10000, Train Loss: 0.6239, Train Acc: 66.18%, Test Loss: 0.5531, Test Acc: 74.14%\n",
            "Epoch 6670/10000, Train Loss: 0.6122, Train Acc: 64.45%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 6671/10000, Train Loss: 0.6315, Train Acc: 60.69%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 6672/10000, Train Loss: 0.6120, Train Acc: 63.29%, Test Loss: 0.5571, Test Acc: 70.69%\n",
            "Epoch 6673/10000, Train Loss: 0.6159, Train Acc: 65.03%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6674/10000, Train Loss: 0.6083, Train Acc: 65.90%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6675/10000, Train Loss: 0.6119, Train Acc: 64.16%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 6676/10000, Train Loss: 0.6044, Train Acc: 66.76%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6677/10000, Train Loss: 0.5951, Train Acc: 66.18%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 6678/10000, Train Loss: 0.5990, Train Acc: 67.05%, Test Loss: 0.5489, Test Acc: 74.14%\n",
            "Epoch 6679/10000, Train Loss: 0.5986, Train Acc: 66.47%, Test Loss: 0.5509, Test Acc: 68.97%\n",
            "Epoch 6680/10000, Train Loss: 0.6245, Train Acc: 67.63%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 6681/10000, Train Loss: 0.6012, Train Acc: 65.32%, Test Loss: 0.5586, Test Acc: 70.69%\n",
            "Epoch 6682/10000, Train Loss: 0.6015, Train Acc: 65.61%, Test Loss: 0.5643, Test Acc: 68.97%\n",
            "Epoch 6683/10000, Train Loss: 0.6053, Train Acc: 65.32%, Test Loss: 0.5597, Test Acc: 72.41%\n",
            "Epoch 6684/10000, Train Loss: 0.6191, Train Acc: 65.32%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 6685/10000, Train Loss: 0.6069, Train Acc: 67.34%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 6686/10000, Train Loss: 0.5987, Train Acc: 68.21%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 6687/10000, Train Loss: 0.6222, Train Acc: 61.56%, Test Loss: 0.5583, Test Acc: 72.41%\n",
            "Epoch 6688/10000, Train Loss: 0.6046, Train Acc: 61.56%, Test Loss: 0.5548, Test Acc: 74.14%\n",
            "Epoch 6689/10000, Train Loss: 0.6290, Train Acc: 62.72%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 6690/10000, Train Loss: 0.5940, Train Acc: 66.18%, Test Loss: 0.5531, Test Acc: 74.14%\n",
            "Epoch 6691/10000, Train Loss: 0.5866, Train Acc: 68.79%, Test Loss: 0.5508, Test Acc: 74.14%\n",
            "Epoch 6692/10000, Train Loss: 0.6106, Train Acc: 64.74%, Test Loss: 0.5511, Test Acc: 70.69%\n",
            "Epoch 6693/10000, Train Loss: 0.6090, Train Acc: 65.90%, Test Loss: 0.5514, Test Acc: 70.69%\n",
            "Epoch 6694/10000, Train Loss: 0.6149, Train Acc: 65.32%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 6695/10000, Train Loss: 0.6238, Train Acc: 58.96%, Test Loss: 0.5488, Test Acc: 70.69%\n",
            "Epoch 6696/10000, Train Loss: 0.6096, Train Acc: 65.03%, Test Loss: 0.5494, Test Acc: 68.97%\n",
            "Epoch 6697/10000, Train Loss: 0.6293, Train Acc: 66.18%, Test Loss: 0.5482, Test Acc: 70.69%\n",
            "Epoch 6698/10000, Train Loss: 0.6110, Train Acc: 63.87%, Test Loss: 0.5495, Test Acc: 70.69%\n",
            "Epoch 6699/10000, Train Loss: 0.6106, Train Acc: 65.90%, Test Loss: 0.5489, Test Acc: 70.69%\n",
            "Epoch 6700/10000, Train Loss: 0.6117, Train Acc: 66.47%, Test Loss: 0.5488, Test Acc: 68.97%\n",
            "Epoch 6701/10000, Train Loss: 0.6285, Train Acc: 65.90%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 6702/10000, Train Loss: 0.6151, Train Acc: 61.85%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 6703/10000, Train Loss: 0.6225, Train Acc: 62.72%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 6704/10000, Train Loss: 0.6082, Train Acc: 66.18%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 6705/10000, Train Loss: 0.6043, Train Acc: 63.87%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 6706/10000, Train Loss: 0.5961, Train Acc: 67.34%, Test Loss: 0.5557, Test Acc: 70.69%\n",
            "Epoch 6707/10000, Train Loss: 0.6131, Train Acc: 64.74%, Test Loss: 0.5584, Test Acc: 70.69%\n",
            "Epoch 6708/10000, Train Loss: 0.6283, Train Acc: 63.87%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 6709/10000, Train Loss: 0.6214, Train Acc: 63.29%, Test Loss: 0.5607, Test Acc: 70.69%\n",
            "Epoch 6710/10000, Train Loss: 0.6237, Train Acc: 63.87%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 6711/10000, Train Loss: 0.6328, Train Acc: 62.72%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 6712/10000, Train Loss: 0.6117, Train Acc: 61.56%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 6713/10000, Train Loss: 0.6211, Train Acc: 65.03%, Test Loss: 0.5523, Test Acc: 74.14%\n",
            "Epoch 6714/10000, Train Loss: 0.6343, Train Acc: 61.85%, Test Loss: 0.5523, Test Acc: 74.14%\n",
            "Epoch 6715/10000, Train Loss: 0.6093, Train Acc: 64.74%, Test Loss: 0.5515, Test Acc: 70.69%\n",
            "Epoch 6716/10000, Train Loss: 0.6051, Train Acc: 61.27%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 6717/10000, Train Loss: 0.5977, Train Acc: 67.63%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6718/10000, Train Loss: 0.6118, Train Acc: 63.58%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 6719/10000, Train Loss: 0.6152, Train Acc: 65.90%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 6720/10000, Train Loss: 0.6233, Train Acc: 64.16%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 6721/10000, Train Loss: 0.6094, Train Acc: 66.47%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 6722/10000, Train Loss: 0.6162, Train Acc: 65.03%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 6723/10000, Train Loss: 0.6136, Train Acc: 64.74%, Test Loss: 0.5537, Test Acc: 74.14%\n",
            "Epoch 6724/10000, Train Loss: 0.6117, Train Acc: 67.63%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 6725/10000, Train Loss: 0.6533, Train Acc: 62.14%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 6726/10000, Train Loss: 0.6252, Train Acc: 65.61%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 6727/10000, Train Loss: 0.6093, Train Acc: 64.16%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 6728/10000, Train Loss: 0.6248, Train Acc: 62.72%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 6729/10000, Train Loss: 0.6298, Train Acc: 66.76%, Test Loss: 0.5494, Test Acc: 72.41%\n",
            "Epoch 6730/10000, Train Loss: 0.6309, Train Acc: 66.76%, Test Loss: 0.5489, Test Acc: 74.14%\n",
            "Epoch 6731/10000, Train Loss: 0.6265, Train Acc: 63.29%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 6732/10000, Train Loss: 0.6000, Train Acc: 65.32%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 6733/10000, Train Loss: 0.6326, Train Acc: 63.58%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 6734/10000, Train Loss: 0.6084, Train Acc: 65.03%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 6735/10000, Train Loss: 0.6166, Train Acc: 62.43%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 6736/10000, Train Loss: 0.6087, Train Acc: 66.47%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 6737/10000, Train Loss: 0.6131, Train Acc: 63.01%, Test Loss: 0.5556, Test Acc: 74.14%\n",
            "Epoch 6738/10000, Train Loss: 0.6210, Train Acc: 63.87%, Test Loss: 0.5526, Test Acc: 74.14%\n",
            "Epoch 6739/10000, Train Loss: 0.6078, Train Acc: 63.29%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 6740/10000, Train Loss: 0.6409, Train Acc: 66.47%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 6741/10000, Train Loss: 0.6071, Train Acc: 63.58%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6742/10000, Train Loss: 0.6216, Train Acc: 63.58%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 6743/10000, Train Loss: 0.6163, Train Acc: 64.16%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 6744/10000, Train Loss: 0.6076, Train Acc: 65.61%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 6745/10000, Train Loss: 0.6020, Train Acc: 66.47%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 6746/10000, Train Loss: 0.6186, Train Acc: 65.61%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 6747/10000, Train Loss: 0.6059, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 6748/10000, Train Loss: 0.6134, Train Acc: 67.34%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 6749/10000, Train Loss: 0.6072, Train Acc: 66.76%, Test Loss: 0.5558, Test Acc: 74.14%\n",
            "Epoch 6750/10000, Train Loss: 0.6044, Train Acc: 66.76%, Test Loss: 0.5567, Test Acc: 74.14%\n",
            "Epoch 6751/10000, Train Loss: 0.6183, Train Acc: 65.90%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 6752/10000, Train Loss: 0.6333, Train Acc: 67.63%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 6753/10000, Train Loss: 0.6130, Train Acc: 64.45%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 6754/10000, Train Loss: 0.5923, Train Acc: 69.94%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 6755/10000, Train Loss: 0.6196, Train Acc: 61.56%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 6756/10000, Train Loss: 0.6386, Train Acc: 64.45%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 6757/10000, Train Loss: 0.6048, Train Acc: 65.03%, Test Loss: 0.5591, Test Acc: 74.14%\n",
            "Epoch 6758/10000, Train Loss: 0.6024, Train Acc: 65.61%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 6759/10000, Train Loss: 0.6082, Train Acc: 64.16%, Test Loss: 0.5542, Test Acc: 74.14%\n",
            "Epoch 6760/10000, Train Loss: 0.6118, Train Acc: 63.29%, Test Loss: 0.5572, Test Acc: 72.41%\n",
            "Epoch 6761/10000, Train Loss: 0.6053, Train Acc: 66.47%, Test Loss: 0.5558, Test Acc: 74.14%\n",
            "Epoch 6762/10000, Train Loss: 0.6150, Train Acc: 63.87%, Test Loss: 0.5515, Test Acc: 70.69%\n",
            "Epoch 6763/10000, Train Loss: 0.6383, Train Acc: 62.14%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 6764/10000, Train Loss: 0.6248, Train Acc: 61.56%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 6765/10000, Train Loss: 0.6230, Train Acc: 61.56%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6766/10000, Train Loss: 0.6125, Train Acc: 63.29%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 6767/10000, Train Loss: 0.6210, Train Acc: 61.27%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 6768/10000, Train Loss: 0.6147, Train Acc: 67.05%, Test Loss: 0.5556, Test Acc: 72.41%\n",
            "Epoch 6769/10000, Train Loss: 0.6099, Train Acc: 63.29%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 6770/10000, Train Loss: 0.6160, Train Acc: 63.58%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 6771/10000, Train Loss: 0.6133, Train Acc: 62.43%, Test Loss: 0.5516, Test Acc: 70.69%\n",
            "Epoch 6772/10000, Train Loss: 0.6194, Train Acc: 62.14%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 6773/10000, Train Loss: 0.6006, Train Acc: 63.87%, Test Loss: 0.5523, Test Acc: 72.41%\n",
            "Epoch 6774/10000, Train Loss: 0.6058, Train Acc: 65.03%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 6775/10000, Train Loss: 0.6256, Train Acc: 67.34%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 6776/10000, Train Loss: 0.6221, Train Acc: 63.58%, Test Loss: 0.5489, Test Acc: 68.97%\n",
            "Epoch 6777/10000, Train Loss: 0.6353, Train Acc: 64.16%, Test Loss: 0.5489, Test Acc: 70.69%\n",
            "Epoch 6778/10000, Train Loss: 0.6198, Train Acc: 65.32%, Test Loss: 0.5493, Test Acc: 68.97%\n",
            "Epoch 6779/10000, Train Loss: 0.6439, Train Acc: 63.29%, Test Loss: 0.5492, Test Acc: 68.97%\n",
            "Epoch 6780/10000, Train Loss: 0.6195, Train Acc: 63.29%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 6781/10000, Train Loss: 0.6017, Train Acc: 66.18%, Test Loss: 0.5595, Test Acc: 70.69%\n",
            "Epoch 6782/10000, Train Loss: 0.5989, Train Acc: 63.58%, Test Loss: 0.5578, Test Acc: 70.69%\n",
            "Epoch 6783/10000, Train Loss: 0.6232, Train Acc: 65.90%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 6784/10000, Train Loss: 0.6114, Train Acc: 62.72%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 6785/10000, Train Loss: 0.6278, Train Acc: 62.14%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6786/10000, Train Loss: 0.5939, Train Acc: 67.63%, Test Loss: 0.5602, Test Acc: 68.97%\n",
            "Epoch 6787/10000, Train Loss: 0.6219, Train Acc: 63.58%, Test Loss: 0.5672, Test Acc: 68.97%\n",
            "Epoch 6788/10000, Train Loss: 0.6178, Train Acc: 64.74%, Test Loss: 0.5654, Test Acc: 68.97%\n",
            "Epoch 6789/10000, Train Loss: 0.6393, Train Acc: 63.87%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 6790/10000, Train Loss: 0.6119, Train Acc: 67.05%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 6791/10000, Train Loss: 0.6314, Train Acc: 65.32%, Test Loss: 0.5514, Test Acc: 72.41%\n",
            "Epoch 6792/10000, Train Loss: 0.6233, Train Acc: 62.72%, Test Loss: 0.5544, Test Acc: 74.14%\n",
            "Epoch 6793/10000, Train Loss: 0.6088, Train Acc: 64.74%, Test Loss: 0.5583, Test Acc: 70.69%\n",
            "Epoch 6794/10000, Train Loss: 0.6260, Train Acc: 64.74%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 6795/10000, Train Loss: 0.6142, Train Acc: 63.58%, Test Loss: 0.5600, Test Acc: 68.97%\n",
            "Epoch 6796/10000, Train Loss: 0.6093, Train Acc: 67.34%, Test Loss: 0.5568, Test Acc: 70.69%\n",
            "Epoch 6797/10000, Train Loss: 0.6018, Train Acc: 65.32%, Test Loss: 0.5568, Test Acc: 72.41%\n",
            "Epoch 6798/10000, Train Loss: 0.6213, Train Acc: 64.45%, Test Loss: 0.5567, Test Acc: 74.14%\n",
            "Epoch 6799/10000, Train Loss: 0.6079, Train Acc: 66.47%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 6800/10000, Train Loss: 0.6010, Train Acc: 64.45%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 6801/10000, Train Loss: 0.6135, Train Acc: 62.72%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 6802/10000, Train Loss: 0.6160, Train Acc: 61.85%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 6803/10000, Train Loss: 0.6264, Train Acc: 63.29%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 6804/10000, Train Loss: 0.5986, Train Acc: 64.45%, Test Loss: 0.5570, Test Acc: 74.14%\n",
            "Epoch 6805/10000, Train Loss: 0.6153, Train Acc: 64.45%, Test Loss: 0.5548, Test Acc: 74.14%\n",
            "Epoch 6806/10000, Train Loss: 0.6333, Train Acc: 63.58%, Test Loss: 0.5555, Test Acc: 74.14%\n",
            "Epoch 6807/10000, Train Loss: 0.5969, Train Acc: 66.47%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 6808/10000, Train Loss: 0.6236, Train Acc: 66.76%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 6809/10000, Train Loss: 0.6151, Train Acc: 65.90%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 6810/10000, Train Loss: 0.5935, Train Acc: 66.47%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 6811/10000, Train Loss: 0.6074, Train Acc: 65.61%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 6812/10000, Train Loss: 0.6285, Train Acc: 63.87%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 6813/10000, Train Loss: 0.6243, Train Acc: 63.29%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 6814/10000, Train Loss: 0.6028, Train Acc: 65.03%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 6815/10000, Train Loss: 0.5973, Train Acc: 63.58%, Test Loss: 0.5525, Test Acc: 72.41%\n",
            "Epoch 6816/10000, Train Loss: 0.6324, Train Acc: 63.01%, Test Loss: 0.5528, Test Acc: 70.69%\n",
            "Epoch 6817/10000, Train Loss: 0.6202, Train Acc: 66.47%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 6818/10000, Train Loss: 0.5980, Train Acc: 65.61%, Test Loss: 0.5525, Test Acc: 72.41%\n",
            "Epoch 6819/10000, Train Loss: 0.6081, Train Acc: 64.45%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 6820/10000, Train Loss: 0.5923, Train Acc: 65.90%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 6821/10000, Train Loss: 0.6141, Train Acc: 68.50%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6822/10000, Train Loss: 0.6211, Train Acc: 63.58%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 6823/10000, Train Loss: 0.6272, Train Acc: 63.29%, Test Loss: 0.5588, Test Acc: 70.69%\n",
            "Epoch 6824/10000, Train Loss: 0.6329, Train Acc: 65.90%, Test Loss: 0.5577, Test Acc: 70.69%\n",
            "Epoch 6825/10000, Train Loss: 0.6281, Train Acc: 63.29%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 6826/10000, Train Loss: 0.6075, Train Acc: 65.03%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 6827/10000, Train Loss: 0.6147, Train Acc: 63.58%, Test Loss: 0.5556, Test Acc: 74.14%\n",
            "Epoch 6828/10000, Train Loss: 0.6033, Train Acc: 65.32%, Test Loss: 0.5583, Test Acc: 72.41%\n",
            "Epoch 6829/10000, Train Loss: 0.6524, Train Acc: 62.14%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 6830/10000, Train Loss: 0.6181, Train Acc: 63.29%, Test Loss: 0.5521, Test Acc: 68.97%\n",
            "Epoch 6831/10000, Train Loss: 0.6169, Train Acc: 66.76%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 6832/10000, Train Loss: 0.5969, Train Acc: 64.74%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 6833/10000, Train Loss: 0.6007, Train Acc: 66.76%, Test Loss: 0.5571, Test Acc: 70.69%\n",
            "Epoch 6834/10000, Train Loss: 0.6306, Train Acc: 67.34%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6835/10000, Train Loss: 0.5825, Train Acc: 70.23%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6836/10000, Train Loss: 0.5860, Train Acc: 64.45%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 6837/10000, Train Loss: 0.6079, Train Acc: 63.01%, Test Loss: 0.5602, Test Acc: 68.97%\n",
            "Epoch 6838/10000, Train Loss: 0.5958, Train Acc: 66.18%, Test Loss: 0.5624, Test Acc: 70.69%\n",
            "Epoch 6839/10000, Train Loss: 0.6165, Train Acc: 65.90%, Test Loss: 0.5590, Test Acc: 70.69%\n",
            "Epoch 6840/10000, Train Loss: 0.6293, Train Acc: 66.18%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 6841/10000, Train Loss: 0.5912, Train Acc: 65.61%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 6842/10000, Train Loss: 0.6151, Train Acc: 63.58%, Test Loss: 0.5552, Test Acc: 74.14%\n",
            "Epoch 6843/10000, Train Loss: 0.6031, Train Acc: 65.90%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6844/10000, Train Loss: 0.6165, Train Acc: 63.58%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 6845/10000, Train Loss: 0.6082, Train Acc: 64.45%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 6846/10000, Train Loss: 0.6192, Train Acc: 66.47%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 6847/10000, Train Loss: 0.6134, Train Acc: 65.03%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 6848/10000, Train Loss: 0.6113, Train Acc: 65.90%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 6849/10000, Train Loss: 0.6098, Train Acc: 66.18%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 6850/10000, Train Loss: 0.6090, Train Acc: 63.29%, Test Loss: 0.5575, Test Acc: 70.69%\n",
            "Epoch 6851/10000, Train Loss: 0.6097, Train Acc: 67.05%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 6852/10000, Train Loss: 0.5867, Train Acc: 67.34%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 6853/10000, Train Loss: 0.6343, Train Acc: 63.29%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 6854/10000, Train Loss: 0.5972, Train Acc: 65.03%, Test Loss: 0.5533, Test Acc: 74.14%\n",
            "Epoch 6855/10000, Train Loss: 0.6300, Train Acc: 63.87%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 6856/10000, Train Loss: 0.6371, Train Acc: 60.40%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 6857/10000, Train Loss: 0.6358, Train Acc: 66.47%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 6858/10000, Train Loss: 0.6148, Train Acc: 65.32%, Test Loss: 0.5485, Test Acc: 68.97%\n",
            "Epoch 6859/10000, Train Loss: 0.6287, Train Acc: 63.87%, Test Loss: 0.5488, Test Acc: 68.97%\n",
            "Epoch 6860/10000, Train Loss: 0.6348, Train Acc: 62.14%, Test Loss: 0.5500, Test Acc: 72.41%\n",
            "Epoch 6861/10000, Train Loss: 0.6160, Train Acc: 63.29%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 6862/10000, Train Loss: 0.5982, Train Acc: 65.61%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 6863/10000, Train Loss: 0.6262, Train Acc: 63.87%, Test Loss: 0.5483, Test Acc: 72.41%\n",
            "Epoch 6864/10000, Train Loss: 0.6171, Train Acc: 64.16%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 6865/10000, Train Loss: 0.6190, Train Acc: 62.43%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 6866/10000, Train Loss: 0.6154, Train Acc: 61.85%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 6867/10000, Train Loss: 0.6299, Train Acc: 65.03%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 6868/10000, Train Loss: 0.6184, Train Acc: 63.01%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 6869/10000, Train Loss: 0.6222, Train Acc: 66.76%, Test Loss: 0.5583, Test Acc: 72.41%\n",
            "Epoch 6870/10000, Train Loss: 0.6092, Train Acc: 65.61%, Test Loss: 0.5591, Test Acc: 70.69%\n",
            "Epoch 6871/10000, Train Loss: 0.6165, Train Acc: 65.90%, Test Loss: 0.5631, Test Acc: 68.97%\n",
            "Epoch 6872/10000, Train Loss: 0.6201, Train Acc: 65.90%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 6873/10000, Train Loss: 0.6128, Train Acc: 64.45%, Test Loss: 0.5556, Test Acc: 74.14%\n",
            "Epoch 6874/10000, Train Loss: 0.5950, Train Acc: 67.63%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 6875/10000, Train Loss: 0.6174, Train Acc: 63.29%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 6876/10000, Train Loss: 0.6201, Train Acc: 61.27%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 6877/10000, Train Loss: 0.6209, Train Acc: 65.32%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 6878/10000, Train Loss: 0.6488, Train Acc: 64.74%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 6879/10000, Train Loss: 0.6211, Train Acc: 62.43%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 6880/10000, Train Loss: 0.6310, Train Acc: 65.32%, Test Loss: 0.5551, Test Acc: 70.69%\n",
            "Epoch 6881/10000, Train Loss: 0.6016, Train Acc: 67.63%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 6882/10000, Train Loss: 0.6272, Train Acc: 63.58%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 6883/10000, Train Loss: 0.6406, Train Acc: 62.72%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 6884/10000, Train Loss: 0.6232, Train Acc: 68.21%, Test Loss: 0.5545, Test Acc: 74.14%\n",
            "Epoch 6885/10000, Train Loss: 0.6124, Train Acc: 63.58%, Test Loss: 0.5544, Test Acc: 74.14%\n",
            "Epoch 6886/10000, Train Loss: 0.6005, Train Acc: 63.58%, Test Loss: 0.5495, Test Acc: 72.41%\n",
            "Epoch 6887/10000, Train Loss: 0.6234, Train Acc: 63.58%, Test Loss: 0.5519, Test Acc: 74.14%\n",
            "Epoch 6888/10000, Train Loss: 0.6204, Train Acc: 63.87%, Test Loss: 0.5512, Test Acc: 72.41%\n",
            "Epoch 6889/10000, Train Loss: 0.6188, Train Acc: 63.29%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 6890/10000, Train Loss: 0.6052, Train Acc: 66.47%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 6891/10000, Train Loss: 0.6233, Train Acc: 67.05%, Test Loss: 0.5578, Test Acc: 72.41%\n",
            "Epoch 6892/10000, Train Loss: 0.6363, Train Acc: 63.58%, Test Loss: 0.5628, Test Acc: 70.69%\n",
            "Epoch 6893/10000, Train Loss: 0.6086, Train Acc: 64.45%, Test Loss: 0.5667, Test Acc: 72.41%\n",
            "Epoch 6894/10000, Train Loss: 0.5975, Train Acc: 67.05%, Test Loss: 0.5736, Test Acc: 68.97%\n",
            "Epoch 6895/10000, Train Loss: 0.6053, Train Acc: 67.63%, Test Loss: 0.5748, Test Acc: 67.24%\n",
            "Epoch 6896/10000, Train Loss: 0.6148, Train Acc: 64.16%, Test Loss: 0.5616, Test Acc: 70.69%\n",
            "Epoch 6897/10000, Train Loss: 0.5980, Train Acc: 66.47%, Test Loss: 0.5580, Test Acc: 70.69%\n",
            "Epoch 6898/10000, Train Loss: 0.6240, Train Acc: 63.87%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 6899/10000, Train Loss: 0.6289, Train Acc: 65.61%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 6900/10000, Train Loss: 0.6316, Train Acc: 63.58%, Test Loss: 0.5544, Test Acc: 74.14%\n",
            "Epoch 6901/10000, Train Loss: 0.6060, Train Acc: 63.01%, Test Loss: 0.5585, Test Acc: 74.14%\n",
            "Epoch 6902/10000, Train Loss: 0.6288, Train Acc: 63.01%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 6903/10000, Train Loss: 0.6155, Train Acc: 62.72%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 6904/10000, Train Loss: 0.5878, Train Acc: 68.50%, Test Loss: 0.5499, Test Acc: 68.97%\n",
            "Epoch 6905/10000, Train Loss: 0.6058, Train Acc: 67.63%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 6906/10000, Train Loss: 0.6059, Train Acc: 62.43%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 6907/10000, Train Loss: 0.6061, Train Acc: 64.45%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 6908/10000, Train Loss: 0.6043, Train Acc: 63.58%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 6909/10000, Train Loss: 0.6301, Train Acc: 62.43%, Test Loss: 0.5493, Test Acc: 68.97%\n",
            "Epoch 6910/10000, Train Loss: 0.6249, Train Acc: 66.76%, Test Loss: 0.5471, Test Acc: 74.14%\n",
            "Epoch 6911/10000, Train Loss: 0.5936, Train Acc: 67.34%, Test Loss: 0.5494, Test Acc: 72.41%\n",
            "Epoch 6912/10000, Train Loss: 0.6124, Train Acc: 64.74%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 6913/10000, Train Loss: 0.6364, Train Acc: 64.16%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 6914/10000, Train Loss: 0.6133, Train Acc: 66.18%, Test Loss: 0.5509, Test Acc: 70.69%\n",
            "Epoch 6915/10000, Train Loss: 0.6411, Train Acc: 65.90%, Test Loss: 0.5497, Test Acc: 68.97%\n",
            "Epoch 6916/10000, Train Loss: 0.6354, Train Acc: 60.98%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 6917/10000, Train Loss: 0.6193, Train Acc: 63.87%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 6918/10000, Train Loss: 0.6297, Train Acc: 63.01%, Test Loss: 0.5599, Test Acc: 72.41%\n",
            "Epoch 6919/10000, Train Loss: 0.6231, Train Acc: 64.16%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 6920/10000, Train Loss: 0.6108, Train Acc: 61.85%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 6921/10000, Train Loss: 0.6157, Train Acc: 66.76%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 6922/10000, Train Loss: 0.6550, Train Acc: 65.03%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 6923/10000, Train Loss: 0.6108, Train Acc: 64.16%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 6924/10000, Train Loss: 0.6205, Train Acc: 66.18%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 6925/10000, Train Loss: 0.6152, Train Acc: 64.74%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 6926/10000, Train Loss: 0.6185, Train Acc: 66.18%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 6927/10000, Train Loss: 0.5946, Train Acc: 65.61%, Test Loss: 0.5624, Test Acc: 68.97%\n",
            "Epoch 6928/10000, Train Loss: 0.6358, Train Acc: 63.58%, Test Loss: 0.5614, Test Acc: 68.97%\n",
            "Epoch 6929/10000, Train Loss: 0.6066, Train Acc: 65.03%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 6930/10000, Train Loss: 0.6126, Train Acc: 65.03%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 6931/10000, Train Loss: 0.5825, Train Acc: 66.18%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 6932/10000, Train Loss: 0.6202, Train Acc: 62.72%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 6933/10000, Train Loss: 0.6348, Train Acc: 63.87%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 6934/10000, Train Loss: 0.6220, Train Acc: 64.45%, Test Loss: 0.5566, Test Acc: 72.41%\n",
            "Epoch 6935/10000, Train Loss: 0.6338, Train Acc: 63.87%, Test Loss: 0.5548, Test Acc: 74.14%\n",
            "Epoch 6936/10000, Train Loss: 0.6301, Train Acc: 60.98%, Test Loss: 0.5514, Test Acc: 72.41%\n",
            "Epoch 6937/10000, Train Loss: 0.6339, Train Acc: 62.14%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 6938/10000, Train Loss: 0.6122, Train Acc: 62.72%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 6939/10000, Train Loss: 0.6166, Train Acc: 65.03%, Test Loss: 0.5602, Test Acc: 70.69%\n",
            "Epoch 6940/10000, Train Loss: 0.6165, Train Acc: 67.05%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 6941/10000, Train Loss: 0.5990, Train Acc: 65.90%, Test Loss: 0.5607, Test Acc: 72.41%\n",
            "Epoch 6942/10000, Train Loss: 0.5974, Train Acc: 65.32%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 6943/10000, Train Loss: 0.6025, Train Acc: 69.65%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 6944/10000, Train Loss: 0.6169, Train Acc: 64.45%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 6945/10000, Train Loss: 0.6098, Train Acc: 64.45%, Test Loss: 0.5555, Test Acc: 74.14%\n",
            "Epoch 6946/10000, Train Loss: 0.6267, Train Acc: 64.74%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 6947/10000, Train Loss: 0.6040, Train Acc: 63.87%, Test Loss: 0.5570, Test Acc: 72.41%\n",
            "Epoch 6948/10000, Train Loss: 0.6096, Train Acc: 61.56%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6949/10000, Train Loss: 0.6158, Train Acc: 66.47%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 6950/10000, Train Loss: 0.6118, Train Acc: 66.18%, Test Loss: 0.5666, Test Acc: 70.69%\n",
            "Epoch 6951/10000, Train Loss: 0.6318, Train Acc: 65.90%, Test Loss: 0.5702, Test Acc: 68.97%\n",
            "Epoch 6952/10000, Train Loss: 0.6191, Train Acc: 64.74%, Test Loss: 0.5654, Test Acc: 68.97%\n",
            "Epoch 6953/10000, Train Loss: 0.6143, Train Acc: 62.14%, Test Loss: 0.5619, Test Acc: 74.14%\n",
            "Epoch 6954/10000, Train Loss: 0.6174, Train Acc: 63.87%, Test Loss: 0.5574, Test Acc: 75.86%\n",
            "Epoch 6955/10000, Train Loss: 0.6318, Train Acc: 67.92%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 6956/10000, Train Loss: 0.6250, Train Acc: 64.16%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 6957/10000, Train Loss: 0.6129, Train Acc: 63.87%, Test Loss: 0.5552, Test Acc: 74.14%\n",
            "Epoch 6958/10000, Train Loss: 0.6133, Train Acc: 66.47%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 6959/10000, Train Loss: 0.6170, Train Acc: 66.18%, Test Loss: 0.5580, Test Acc: 72.41%\n",
            "Epoch 6960/10000, Train Loss: 0.6098, Train Acc: 66.76%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 6961/10000, Train Loss: 0.6157, Train Acc: 65.03%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 6962/10000, Train Loss: 0.6262, Train Acc: 64.16%, Test Loss: 0.5495, Test Acc: 70.69%\n",
            "Epoch 6963/10000, Train Loss: 0.6086, Train Acc: 63.01%, Test Loss: 0.5512, Test Acc: 70.69%\n",
            "Epoch 6964/10000, Train Loss: 0.6197, Train Acc: 65.90%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 6965/10000, Train Loss: 0.6279, Train Acc: 62.43%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 6966/10000, Train Loss: 0.5976, Train Acc: 68.21%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 6967/10000, Train Loss: 0.6005, Train Acc: 61.85%, Test Loss: 0.5548, Test Acc: 70.69%\n",
            "Epoch 6968/10000, Train Loss: 0.6007, Train Acc: 65.32%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 6969/10000, Train Loss: 0.6123, Train Acc: 67.63%, Test Loss: 0.5561, Test Acc: 70.69%\n",
            "Epoch 6970/10000, Train Loss: 0.6206, Train Acc: 65.32%, Test Loss: 0.5595, Test Acc: 70.69%\n",
            "Epoch 6971/10000, Train Loss: 0.6027, Train Acc: 66.18%, Test Loss: 0.5614, Test Acc: 68.97%\n",
            "Epoch 6972/10000, Train Loss: 0.6246, Train Acc: 63.87%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 6973/10000, Train Loss: 0.6078, Train Acc: 65.90%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 6974/10000, Train Loss: 0.6054, Train Acc: 65.32%, Test Loss: 0.5590, Test Acc: 68.97%\n",
            "Epoch 6975/10000, Train Loss: 0.6179, Train Acc: 66.76%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 6976/10000, Train Loss: 0.6181, Train Acc: 63.87%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 6977/10000, Train Loss: 0.6134, Train Acc: 65.61%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 6978/10000, Train Loss: 0.6255, Train Acc: 63.87%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 6979/10000, Train Loss: 0.6048, Train Acc: 64.16%, Test Loss: 0.5515, Test Acc: 74.14%\n",
            "Epoch 6980/10000, Train Loss: 0.6287, Train Acc: 62.72%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 6981/10000, Train Loss: 0.6398, Train Acc: 61.56%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 6982/10000, Train Loss: 0.6295, Train Acc: 64.45%, Test Loss: 0.5545, Test Acc: 74.14%\n",
            "Epoch 6983/10000, Train Loss: 0.6312, Train Acc: 63.87%, Test Loss: 0.5552, Test Acc: 70.69%\n",
            "Epoch 6984/10000, Train Loss: 0.6434, Train Acc: 64.45%, Test Loss: 0.5573, Test Acc: 72.41%\n",
            "Epoch 6985/10000, Train Loss: 0.6278, Train Acc: 61.85%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 6986/10000, Train Loss: 0.6017, Train Acc: 66.76%, Test Loss: 0.5513, Test Acc: 70.69%\n",
            "Epoch 6987/10000, Train Loss: 0.6085, Train Acc: 63.87%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 6988/10000, Train Loss: 0.6295, Train Acc: 61.56%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 6989/10000, Train Loss: 0.6020, Train Acc: 67.05%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 6990/10000, Train Loss: 0.6362, Train Acc: 66.47%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 6991/10000, Train Loss: 0.6051, Train Acc: 65.90%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 6992/10000, Train Loss: 0.6116, Train Acc: 67.63%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 6993/10000, Train Loss: 0.6461, Train Acc: 65.03%, Test Loss: 0.5632, Test Acc: 68.97%\n",
            "Epoch 6994/10000, Train Loss: 0.6026, Train Acc: 65.03%, Test Loss: 0.5627, Test Acc: 72.41%\n",
            "Epoch 6995/10000, Train Loss: 0.6331, Train Acc: 64.16%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 6996/10000, Train Loss: 0.6214, Train Acc: 64.16%, Test Loss: 0.5586, Test Acc: 70.69%\n",
            "Epoch 6997/10000, Train Loss: 0.5994, Train Acc: 65.03%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 6998/10000, Train Loss: 0.6129, Train Acc: 63.01%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 6999/10000, Train Loss: 0.6124, Train Acc: 64.16%, Test Loss: 0.5599, Test Acc: 72.41%\n",
            "Epoch 7000/10000, Train Loss: 0.6180, Train Acc: 67.05%, Test Loss: 0.5588, Test Acc: 72.41%\n",
            "Epoch 7001/10000, Train Loss: 0.6102, Train Acc: 63.87%, Test Loss: 0.5556, Test Acc: 70.69%\n",
            "Epoch 7002/10000, Train Loss: 0.6184, Train Acc: 65.61%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 7003/10000, Train Loss: 0.6113, Train Acc: 62.14%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 7004/10000, Train Loss: 0.6211, Train Acc: 63.29%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7005/10000, Train Loss: 0.6009, Train Acc: 68.79%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7006/10000, Train Loss: 0.6102, Train Acc: 68.21%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 7007/10000, Train Loss: 0.5881, Train Acc: 62.14%, Test Loss: 0.5623, Test Acc: 68.97%\n",
            "Epoch 7008/10000, Train Loss: 0.5994, Train Acc: 63.01%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 7009/10000, Train Loss: 0.6243, Train Acc: 65.90%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 7010/10000, Train Loss: 0.6188, Train Acc: 65.90%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 7011/10000, Train Loss: 0.6388, Train Acc: 63.29%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 7012/10000, Train Loss: 0.6201, Train Acc: 63.87%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 7013/10000, Train Loss: 0.6178, Train Acc: 65.32%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 7014/10000, Train Loss: 0.6076, Train Acc: 63.87%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 7015/10000, Train Loss: 0.6165, Train Acc: 62.72%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 7016/10000, Train Loss: 0.6382, Train Acc: 62.43%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 7017/10000, Train Loss: 0.6080, Train Acc: 65.61%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 7018/10000, Train Loss: 0.6342, Train Acc: 63.58%, Test Loss: 0.5552, Test Acc: 70.69%\n",
            "Epoch 7019/10000, Train Loss: 0.6160, Train Acc: 63.87%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 7020/10000, Train Loss: 0.6102, Train Acc: 59.54%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 7021/10000, Train Loss: 0.6189, Train Acc: 65.03%, Test Loss: 0.5611, Test Acc: 70.69%\n",
            "Epoch 7022/10000, Train Loss: 0.6022, Train Acc: 66.76%, Test Loss: 0.5638, Test Acc: 70.69%\n",
            "Epoch 7023/10000, Train Loss: 0.6036, Train Acc: 66.18%, Test Loss: 0.5620, Test Acc: 70.69%\n",
            "Epoch 7024/10000, Train Loss: 0.6303, Train Acc: 62.72%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 7025/10000, Train Loss: 0.5997, Train Acc: 63.58%, Test Loss: 0.5548, Test Acc: 74.14%\n",
            "Epoch 7026/10000, Train Loss: 0.6237, Train Acc: 65.61%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 7027/10000, Train Loss: 0.6167, Train Acc: 64.74%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 7028/10000, Train Loss: 0.6114, Train Acc: 66.18%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 7029/10000, Train Loss: 0.6188, Train Acc: 68.21%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 7030/10000, Train Loss: 0.6055, Train Acc: 65.03%, Test Loss: 0.5570, Test Acc: 70.69%\n",
            "Epoch 7031/10000, Train Loss: 0.6096, Train Acc: 63.01%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 7032/10000, Train Loss: 0.6097, Train Acc: 66.76%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 7033/10000, Train Loss: 0.6105, Train Acc: 65.90%, Test Loss: 0.5573, Test Acc: 72.41%\n",
            "Epoch 7034/10000, Train Loss: 0.5944, Train Acc: 68.79%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 7035/10000, Train Loss: 0.6239, Train Acc: 62.72%, Test Loss: 0.5630, Test Acc: 70.69%\n",
            "Epoch 7036/10000, Train Loss: 0.6211, Train Acc: 65.32%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 7037/10000, Train Loss: 0.6422, Train Acc: 61.27%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 7038/10000, Train Loss: 0.6283, Train Acc: 67.05%, Test Loss: 0.5586, Test Acc: 74.14%\n",
            "Epoch 7039/10000, Train Loss: 0.6316, Train Acc: 61.56%, Test Loss: 0.5585, Test Acc: 72.41%\n",
            "Epoch 7040/10000, Train Loss: 0.6203, Train Acc: 60.98%, Test Loss: 0.5580, Test Acc: 74.14%\n",
            "Epoch 7041/10000, Train Loss: 0.6097, Train Acc: 64.45%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 7042/10000, Train Loss: 0.6232, Train Acc: 64.45%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 7043/10000, Train Loss: 0.6087, Train Acc: 65.03%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 7044/10000, Train Loss: 0.6196, Train Acc: 63.87%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 7045/10000, Train Loss: 0.6149, Train Acc: 66.76%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 7046/10000, Train Loss: 0.6205, Train Acc: 64.74%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 7047/10000, Train Loss: 0.6159, Train Acc: 65.90%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7048/10000, Train Loss: 0.6113, Train Acc: 63.29%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 7049/10000, Train Loss: 0.6265, Train Acc: 66.47%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 7050/10000, Train Loss: 0.6075, Train Acc: 64.74%, Test Loss: 0.5551, Test Acc: 74.14%\n",
            "Epoch 7051/10000, Train Loss: 0.6097, Train Acc: 65.90%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 7052/10000, Train Loss: 0.6012, Train Acc: 67.05%, Test Loss: 0.5530, Test Acc: 70.69%\n",
            "Epoch 7053/10000, Train Loss: 0.6109, Train Acc: 63.01%, Test Loss: 0.5493, Test Acc: 72.41%\n",
            "Epoch 7054/10000, Train Loss: 0.5856, Train Acc: 65.03%, Test Loss: 0.5511, Test Acc: 68.97%\n",
            "Epoch 7055/10000, Train Loss: 0.5945, Train Acc: 66.18%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 7056/10000, Train Loss: 0.6352, Train Acc: 64.74%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 7057/10000, Train Loss: 0.6083, Train Acc: 68.50%, Test Loss: 0.5481, Test Acc: 70.69%\n",
            "Epoch 7058/10000, Train Loss: 0.6293, Train Acc: 66.47%, Test Loss: 0.5508, Test Acc: 70.69%\n",
            "Epoch 7059/10000, Train Loss: 0.6112, Train Acc: 64.45%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 7060/10000, Train Loss: 0.6250, Train Acc: 65.32%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 7061/10000, Train Loss: 0.6162, Train Acc: 62.43%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 7062/10000, Train Loss: 0.5995, Train Acc: 63.58%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 7063/10000, Train Loss: 0.6097, Train Acc: 66.47%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 7064/10000, Train Loss: 0.6012, Train Acc: 65.32%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 7065/10000, Train Loss: 0.6001, Train Acc: 63.87%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 7066/10000, Train Loss: 0.6189, Train Acc: 61.56%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 7067/10000, Train Loss: 0.6179, Train Acc: 64.45%, Test Loss: 0.5618, Test Acc: 68.97%\n",
            "Epoch 7068/10000, Train Loss: 0.6032, Train Acc: 66.18%, Test Loss: 0.5600, Test Acc: 70.69%\n",
            "Epoch 7069/10000, Train Loss: 0.6145, Train Acc: 64.45%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 7070/10000, Train Loss: 0.6212, Train Acc: 63.58%, Test Loss: 0.5512, Test Acc: 74.14%\n",
            "Epoch 7071/10000, Train Loss: 0.6346, Train Acc: 64.45%, Test Loss: 0.5511, Test Acc: 72.41%\n",
            "Epoch 7072/10000, Train Loss: 0.6155, Train Acc: 64.16%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 7073/10000, Train Loss: 0.6025, Train Acc: 63.58%, Test Loss: 0.5570, Test Acc: 74.14%\n",
            "Epoch 7074/10000, Train Loss: 0.5839, Train Acc: 65.61%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 7075/10000, Train Loss: 0.6190, Train Acc: 63.87%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 7076/10000, Train Loss: 0.6321, Train Acc: 64.74%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 7077/10000, Train Loss: 0.5976, Train Acc: 69.94%, Test Loss: 0.5482, Test Acc: 70.69%\n",
            "Epoch 7078/10000, Train Loss: 0.6061, Train Acc: 67.34%, Test Loss: 0.5514, Test Acc: 70.69%\n",
            "Epoch 7079/10000, Train Loss: 0.6267, Train Acc: 67.34%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 7080/10000, Train Loss: 0.6048, Train Acc: 65.90%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 7081/10000, Train Loss: 0.6080, Train Acc: 67.05%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 7082/10000, Train Loss: 0.6031, Train Acc: 64.16%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 7083/10000, Train Loss: 0.6160, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7084/10000, Train Loss: 0.6002, Train Acc: 65.61%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 7085/10000, Train Loss: 0.6144, Train Acc: 63.58%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 7086/10000, Train Loss: 0.6087, Train Acc: 60.40%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7087/10000, Train Loss: 0.5778, Train Acc: 66.76%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 7088/10000, Train Loss: 0.6149, Train Acc: 65.61%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 7089/10000, Train Loss: 0.6212, Train Acc: 65.61%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7090/10000, Train Loss: 0.6220, Train Acc: 64.45%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 7091/10000, Train Loss: 0.6064, Train Acc: 63.87%, Test Loss: 0.5578, Test Acc: 70.69%\n",
            "Epoch 7092/10000, Train Loss: 0.6300, Train Acc: 60.40%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 7093/10000, Train Loss: 0.6196, Train Acc: 63.87%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 7094/10000, Train Loss: 0.6252, Train Acc: 65.61%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 7095/10000, Train Loss: 0.6224, Train Acc: 64.45%, Test Loss: 0.5493, Test Acc: 72.41%\n",
            "Epoch 7096/10000, Train Loss: 0.6037, Train Acc: 66.47%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 7097/10000, Train Loss: 0.6185, Train Acc: 64.45%, Test Loss: 0.5504, Test Acc: 68.97%\n",
            "Epoch 7098/10000, Train Loss: 0.6122, Train Acc: 67.05%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 7099/10000, Train Loss: 0.6089, Train Acc: 65.32%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 7100/10000, Train Loss: 0.6222, Train Acc: 64.16%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7101/10000, Train Loss: 0.6136, Train Acc: 64.16%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 7102/10000, Train Loss: 0.6289, Train Acc: 62.43%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 7103/10000, Train Loss: 0.6174, Train Acc: 66.47%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 7104/10000, Train Loss: 0.6201, Train Acc: 63.87%, Test Loss: 0.5553, Test Acc: 74.14%\n",
            "Epoch 7105/10000, Train Loss: 0.6159, Train Acc: 64.74%, Test Loss: 0.5536, Test Acc: 70.69%\n",
            "Epoch 7106/10000, Train Loss: 0.6022, Train Acc: 65.61%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 7107/10000, Train Loss: 0.6009, Train Acc: 64.45%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7108/10000, Train Loss: 0.6512, Train Acc: 64.45%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 7109/10000, Train Loss: 0.6228, Train Acc: 63.29%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 7110/10000, Train Loss: 0.6205, Train Acc: 64.74%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 7111/10000, Train Loss: 0.6096, Train Acc: 67.34%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 7112/10000, Train Loss: 0.6182, Train Acc: 66.76%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 7113/10000, Train Loss: 0.6272, Train Acc: 61.56%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7114/10000, Train Loss: 0.6026, Train Acc: 67.34%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 7115/10000, Train Loss: 0.6050, Train Acc: 67.63%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 7116/10000, Train Loss: 0.5834, Train Acc: 63.58%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 7117/10000, Train Loss: 0.6199, Train Acc: 62.72%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 7118/10000, Train Loss: 0.6340, Train Acc: 61.27%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 7119/10000, Train Loss: 0.6337, Train Acc: 62.72%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 7120/10000, Train Loss: 0.6228, Train Acc: 62.43%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 7121/10000, Train Loss: 0.6249, Train Acc: 64.45%, Test Loss: 0.5560, Test Acc: 74.14%\n",
            "Epoch 7122/10000, Train Loss: 0.6313, Train Acc: 62.14%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 7123/10000, Train Loss: 0.6165, Train Acc: 64.74%, Test Loss: 0.5506, Test Acc: 74.14%\n",
            "Epoch 7124/10000, Train Loss: 0.6118, Train Acc: 65.61%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 7125/10000, Train Loss: 0.6350, Train Acc: 58.09%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7126/10000, Train Loss: 0.5826, Train Acc: 64.16%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 7127/10000, Train Loss: 0.6390, Train Acc: 63.58%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 7128/10000, Train Loss: 0.5964, Train Acc: 65.32%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7129/10000, Train Loss: 0.6131, Train Acc: 65.61%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 7130/10000, Train Loss: 0.6167, Train Acc: 64.74%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7131/10000, Train Loss: 0.5994, Train Acc: 66.18%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 7132/10000, Train Loss: 0.6227, Train Acc: 65.61%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 7133/10000, Train Loss: 0.6007, Train Acc: 66.47%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7134/10000, Train Loss: 0.6143, Train Acc: 62.43%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7135/10000, Train Loss: 0.6124, Train Acc: 64.16%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 7136/10000, Train Loss: 0.6116, Train Acc: 64.74%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 7137/10000, Train Loss: 0.6085, Train Acc: 66.76%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 7138/10000, Train Loss: 0.6228, Train Acc: 64.74%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 7139/10000, Train Loss: 0.6247, Train Acc: 67.63%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 7140/10000, Train Loss: 0.6147, Train Acc: 62.72%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7141/10000, Train Loss: 0.6177, Train Acc: 65.61%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 7142/10000, Train Loss: 0.6234, Train Acc: 62.72%, Test Loss: 0.5565, Test Acc: 72.41%\n",
            "Epoch 7143/10000, Train Loss: 0.6297, Train Acc: 63.87%, Test Loss: 0.5571, Test Acc: 70.69%\n",
            "Epoch 7144/10000, Train Loss: 0.6051, Train Acc: 65.61%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 7145/10000, Train Loss: 0.6347, Train Acc: 59.83%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 7146/10000, Train Loss: 0.5992, Train Acc: 65.90%, Test Loss: 0.5611, Test Acc: 68.97%\n",
            "Epoch 7147/10000, Train Loss: 0.6337, Train Acc: 63.87%, Test Loss: 0.5603, Test Acc: 72.41%\n",
            "Epoch 7148/10000, Train Loss: 0.6100, Train Acc: 66.76%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 7149/10000, Train Loss: 0.6352, Train Acc: 65.03%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 7150/10000, Train Loss: 0.6071, Train Acc: 67.92%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 7151/10000, Train Loss: 0.6253, Train Acc: 65.03%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 7152/10000, Train Loss: 0.6160, Train Acc: 63.01%, Test Loss: 0.5587, Test Acc: 70.69%\n",
            "Epoch 7153/10000, Train Loss: 0.6108, Train Acc: 63.58%, Test Loss: 0.5556, Test Acc: 72.41%\n",
            "Epoch 7154/10000, Train Loss: 0.6110, Train Acc: 63.29%, Test Loss: 0.5545, Test Acc: 74.14%\n",
            "Epoch 7155/10000, Train Loss: 0.6076, Train Acc: 69.08%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 7156/10000, Train Loss: 0.6124, Train Acc: 67.34%, Test Loss: 0.5561, Test Acc: 70.69%\n",
            "Epoch 7157/10000, Train Loss: 0.6268, Train Acc: 65.61%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 7158/10000, Train Loss: 0.6219, Train Acc: 66.18%, Test Loss: 0.5552, Test Acc: 74.14%\n",
            "Epoch 7159/10000, Train Loss: 0.6305, Train Acc: 64.74%, Test Loss: 0.5556, Test Acc: 72.41%\n",
            "Epoch 7160/10000, Train Loss: 0.6166, Train Acc: 66.47%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 7161/10000, Train Loss: 0.6426, Train Acc: 63.01%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7162/10000, Train Loss: 0.6121, Train Acc: 67.92%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 7163/10000, Train Loss: 0.6132, Train Acc: 64.74%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 7164/10000, Train Loss: 0.6206, Train Acc: 63.58%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 7165/10000, Train Loss: 0.5837, Train Acc: 65.61%, Test Loss: 0.5577, Test Acc: 70.69%\n",
            "Epoch 7166/10000, Train Loss: 0.5948, Train Acc: 67.05%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 7167/10000, Train Loss: 0.6198, Train Acc: 65.32%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 7168/10000, Train Loss: 0.6000, Train Acc: 66.47%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 7169/10000, Train Loss: 0.6362, Train Acc: 62.72%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 7170/10000, Train Loss: 0.6121, Train Acc: 61.85%, Test Loss: 0.5586, Test Acc: 70.69%\n",
            "Epoch 7171/10000, Train Loss: 0.6494, Train Acc: 66.18%, Test Loss: 0.5567, Test Acc: 74.14%\n",
            "Epoch 7172/10000, Train Loss: 0.6166, Train Acc: 65.03%, Test Loss: 0.5564, Test Acc: 74.14%\n",
            "Epoch 7173/10000, Train Loss: 0.6025, Train Acc: 63.87%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 7174/10000, Train Loss: 0.6096, Train Acc: 69.08%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 7175/10000, Train Loss: 0.6256, Train Acc: 63.58%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 7176/10000, Train Loss: 0.6407, Train Acc: 65.90%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 7177/10000, Train Loss: 0.6048, Train Acc: 65.03%, Test Loss: 0.5513, Test Acc: 72.41%\n",
            "Epoch 7178/10000, Train Loss: 0.6261, Train Acc: 65.32%, Test Loss: 0.5486, Test Acc: 74.14%\n",
            "Epoch 7179/10000, Train Loss: 0.6493, Train Acc: 60.98%, Test Loss: 0.5499, Test Acc: 74.14%\n",
            "Epoch 7180/10000, Train Loss: 0.6013, Train Acc: 65.32%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 7181/10000, Train Loss: 0.6109, Train Acc: 65.03%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 7182/10000, Train Loss: 0.6523, Train Acc: 61.85%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 7183/10000, Train Loss: 0.6162, Train Acc: 64.45%, Test Loss: 0.5605, Test Acc: 72.41%\n",
            "Epoch 7184/10000, Train Loss: 0.6097, Train Acc: 64.45%, Test Loss: 0.5616, Test Acc: 72.41%\n",
            "Epoch 7185/10000, Train Loss: 0.6054, Train Acc: 64.74%, Test Loss: 0.5611, Test Acc: 68.97%\n",
            "Epoch 7186/10000, Train Loss: 0.6201, Train Acc: 64.45%, Test Loss: 0.5580, Test Acc: 70.69%\n",
            "Epoch 7187/10000, Train Loss: 0.6172, Train Acc: 63.87%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 7188/10000, Train Loss: 0.6316, Train Acc: 65.03%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 7189/10000, Train Loss: 0.6069, Train Acc: 68.21%, Test Loss: 0.5666, Test Acc: 70.69%\n",
            "Epoch 7190/10000, Train Loss: 0.6059, Train Acc: 64.74%, Test Loss: 0.5632, Test Acc: 68.97%\n",
            "Epoch 7191/10000, Train Loss: 0.6104, Train Acc: 67.34%, Test Loss: 0.5601, Test Acc: 74.14%\n",
            "Epoch 7192/10000, Train Loss: 0.6154, Train Acc: 62.43%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 7193/10000, Train Loss: 0.6119, Train Acc: 65.32%, Test Loss: 0.5559, Test Acc: 74.14%\n",
            "Epoch 7194/10000, Train Loss: 0.6269, Train Acc: 66.76%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 7195/10000, Train Loss: 0.6013, Train Acc: 65.32%, Test Loss: 0.5605, Test Acc: 74.14%\n",
            "Epoch 7196/10000, Train Loss: 0.6005, Train Acc: 64.45%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 7197/10000, Train Loss: 0.6183, Train Acc: 63.29%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 7198/10000, Train Loss: 0.6207, Train Acc: 63.87%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 7199/10000, Train Loss: 0.6080, Train Acc: 65.32%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 7200/10000, Train Loss: 0.6035, Train Acc: 63.87%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 7201/10000, Train Loss: 0.6419, Train Acc: 65.03%, Test Loss: 0.5524, Test Acc: 74.14%\n",
            "Epoch 7202/10000, Train Loss: 0.6389, Train Acc: 65.32%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 7203/10000, Train Loss: 0.6180, Train Acc: 63.29%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 7204/10000, Train Loss: 0.5907, Train Acc: 65.61%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 7205/10000, Train Loss: 0.5876, Train Acc: 67.34%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 7206/10000, Train Loss: 0.6474, Train Acc: 60.98%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7207/10000, Train Loss: 0.6082, Train Acc: 65.32%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 7208/10000, Train Loss: 0.6103, Train Acc: 68.21%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 7209/10000, Train Loss: 0.6110, Train Acc: 63.58%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 7210/10000, Train Loss: 0.6150, Train Acc: 63.29%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 7211/10000, Train Loss: 0.6189, Train Acc: 64.45%, Test Loss: 0.5575, Test Acc: 70.69%\n",
            "Epoch 7212/10000, Train Loss: 0.6341, Train Acc: 61.85%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 7213/10000, Train Loss: 0.6290, Train Acc: 63.58%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 7214/10000, Train Loss: 0.6334, Train Acc: 63.01%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 7215/10000, Train Loss: 0.5996, Train Acc: 66.47%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 7216/10000, Train Loss: 0.6204, Train Acc: 64.74%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 7217/10000, Train Loss: 0.6043, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7218/10000, Train Loss: 0.6147, Train Acc: 62.43%, Test Loss: 0.5556, Test Acc: 70.69%\n",
            "Epoch 7219/10000, Train Loss: 0.6261, Train Acc: 64.74%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 7220/10000, Train Loss: 0.6191, Train Acc: 63.01%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 7221/10000, Train Loss: 0.6249, Train Acc: 64.45%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 7222/10000, Train Loss: 0.6064, Train Acc: 66.76%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 7223/10000, Train Loss: 0.6188, Train Acc: 61.56%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 7224/10000, Train Loss: 0.6256, Train Acc: 62.72%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 7225/10000, Train Loss: 0.6433, Train Acc: 65.61%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 7226/10000, Train Loss: 0.6428, Train Acc: 63.58%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 7227/10000, Train Loss: 0.6149, Train Acc: 68.50%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 7228/10000, Train Loss: 0.5988, Train Acc: 66.18%, Test Loss: 0.5619, Test Acc: 68.97%\n",
            "Epoch 7229/10000, Train Loss: 0.6091, Train Acc: 69.08%, Test Loss: 0.5615, Test Acc: 68.97%\n",
            "Epoch 7230/10000, Train Loss: 0.6334, Train Acc: 63.01%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 7231/10000, Train Loss: 0.5993, Train Acc: 65.61%, Test Loss: 0.5558, Test Acc: 74.14%\n",
            "Epoch 7232/10000, Train Loss: 0.5969, Train Acc: 67.34%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 7233/10000, Train Loss: 0.6252, Train Acc: 62.43%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 7234/10000, Train Loss: 0.6116, Train Acc: 65.61%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 7235/10000, Train Loss: 0.6277, Train Acc: 63.58%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 7236/10000, Train Loss: 0.6126, Train Acc: 66.18%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 7237/10000, Train Loss: 0.5889, Train Acc: 66.76%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 7238/10000, Train Loss: 0.6333, Train Acc: 61.56%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 7239/10000, Train Loss: 0.6326, Train Acc: 66.47%, Test Loss: 0.5565, Test Acc: 74.14%\n",
            "Epoch 7240/10000, Train Loss: 0.5969, Train Acc: 68.50%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 7241/10000, Train Loss: 0.6113, Train Acc: 62.43%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 7242/10000, Train Loss: 0.5900, Train Acc: 67.63%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 7243/10000, Train Loss: 0.6027, Train Acc: 66.76%, Test Loss: 0.5582, Test Acc: 70.69%\n",
            "Epoch 7244/10000, Train Loss: 0.6235, Train Acc: 64.45%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7245/10000, Train Loss: 0.5917, Train Acc: 66.18%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7246/10000, Train Loss: 0.6339, Train Acc: 63.87%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 7247/10000, Train Loss: 0.6160, Train Acc: 63.87%, Test Loss: 0.5577, Test Acc: 74.14%\n",
            "Epoch 7248/10000, Train Loss: 0.5997, Train Acc: 65.32%, Test Loss: 0.5621, Test Acc: 68.97%\n",
            "Epoch 7249/10000, Train Loss: 0.6241, Train Acc: 65.90%, Test Loss: 0.5616, Test Acc: 68.97%\n",
            "Epoch 7250/10000, Train Loss: 0.6034, Train Acc: 65.61%, Test Loss: 0.5610, Test Acc: 68.97%\n",
            "Epoch 7251/10000, Train Loss: 0.6108, Train Acc: 67.34%, Test Loss: 0.5648, Test Acc: 68.97%\n",
            "Epoch 7252/10000, Train Loss: 0.6189, Train Acc: 62.72%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 7253/10000, Train Loss: 0.6124, Train Acc: 65.90%, Test Loss: 0.5580, Test Acc: 72.41%\n",
            "Epoch 7254/10000, Train Loss: 0.6037, Train Acc: 66.18%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 7255/10000, Train Loss: 0.6193, Train Acc: 64.74%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 7256/10000, Train Loss: 0.6187, Train Acc: 62.43%, Test Loss: 0.5578, Test Acc: 74.14%\n",
            "Epoch 7257/10000, Train Loss: 0.5904, Train Acc: 64.74%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 7258/10000, Train Loss: 0.6328, Train Acc: 65.03%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 7259/10000, Train Loss: 0.6086, Train Acc: 64.45%, Test Loss: 0.5579, Test Acc: 74.14%\n",
            "Epoch 7260/10000, Train Loss: 0.6152, Train Acc: 67.63%, Test Loss: 0.5561, Test Acc: 70.69%\n",
            "Epoch 7261/10000, Train Loss: 0.6196, Train Acc: 61.85%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 7262/10000, Train Loss: 0.6251, Train Acc: 61.85%, Test Loss: 0.5546, Test Acc: 74.14%\n",
            "Epoch 7263/10000, Train Loss: 0.6276, Train Acc: 65.03%, Test Loss: 0.5585, Test Acc: 74.14%\n",
            "Epoch 7264/10000, Train Loss: 0.5930, Train Acc: 67.63%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 7265/10000, Train Loss: 0.6150, Train Acc: 65.03%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 7266/10000, Train Loss: 0.6055, Train Acc: 65.90%, Test Loss: 0.5545, Test Acc: 74.14%\n",
            "Epoch 7267/10000, Train Loss: 0.6008, Train Acc: 65.03%, Test Loss: 0.5530, Test Acc: 70.69%\n",
            "Epoch 7268/10000, Train Loss: 0.6227, Train Acc: 65.32%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 7269/10000, Train Loss: 0.6151, Train Acc: 62.43%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 7270/10000, Train Loss: 0.6159, Train Acc: 65.90%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7271/10000, Train Loss: 0.6032, Train Acc: 65.32%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 7272/10000, Train Loss: 0.6179, Train Acc: 65.90%, Test Loss: 0.5584, Test Acc: 74.14%\n",
            "Epoch 7273/10000, Train Loss: 0.6204, Train Acc: 65.03%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 7274/10000, Train Loss: 0.5889, Train Acc: 66.76%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 7275/10000, Train Loss: 0.6052, Train Acc: 67.92%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 7276/10000, Train Loss: 0.6305, Train Acc: 65.61%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7277/10000, Train Loss: 0.6112, Train Acc: 65.90%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 7278/10000, Train Loss: 0.6330, Train Acc: 69.08%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 7279/10000, Train Loss: 0.6224, Train Acc: 65.32%, Test Loss: 0.5559, Test Acc: 74.14%\n",
            "Epoch 7280/10000, Train Loss: 0.6127, Train Acc: 67.05%, Test Loss: 0.5553, Test Acc: 74.14%\n",
            "Epoch 7281/10000, Train Loss: 0.6029, Train Acc: 60.12%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 7282/10000, Train Loss: 0.6149, Train Acc: 64.74%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 7283/10000, Train Loss: 0.6037, Train Acc: 64.16%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 7284/10000, Train Loss: 0.6013, Train Acc: 64.45%, Test Loss: 0.5557, Test Acc: 70.69%\n",
            "Epoch 7285/10000, Train Loss: 0.6098, Train Acc: 66.18%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 7286/10000, Train Loss: 0.5976, Train Acc: 65.90%, Test Loss: 0.5610, Test Acc: 68.97%\n",
            "Epoch 7287/10000, Train Loss: 0.6037, Train Acc: 66.76%, Test Loss: 0.5638, Test Acc: 70.69%\n",
            "Epoch 7288/10000, Train Loss: 0.6085, Train Acc: 64.16%, Test Loss: 0.5624, Test Acc: 68.97%\n",
            "Epoch 7289/10000, Train Loss: 0.6162, Train Acc: 65.61%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 7290/10000, Train Loss: 0.6291, Train Acc: 65.32%, Test Loss: 0.5601, Test Acc: 70.69%\n",
            "Epoch 7291/10000, Train Loss: 0.6300, Train Acc: 62.43%, Test Loss: 0.5594, Test Acc: 72.41%\n",
            "Epoch 7292/10000, Train Loss: 0.6225, Train Acc: 64.74%, Test Loss: 0.5599, Test Acc: 75.86%\n",
            "Epoch 7293/10000, Train Loss: 0.5913, Train Acc: 68.79%, Test Loss: 0.5536, Test Acc: 74.14%\n",
            "Epoch 7294/10000, Train Loss: 0.6352, Train Acc: 63.58%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 7295/10000, Train Loss: 0.6042, Train Acc: 65.90%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 7296/10000, Train Loss: 0.6251, Train Acc: 64.74%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 7297/10000, Train Loss: 0.6136, Train Acc: 65.03%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 7298/10000, Train Loss: 0.6218, Train Acc: 63.87%, Test Loss: 0.5624, Test Acc: 68.97%\n",
            "Epoch 7299/10000, Train Loss: 0.6114, Train Acc: 67.05%, Test Loss: 0.5629, Test Acc: 72.41%\n",
            "Epoch 7300/10000, Train Loss: 0.6095, Train Acc: 67.05%, Test Loss: 0.5636, Test Acc: 70.69%\n",
            "Epoch 7301/10000, Train Loss: 0.6542, Train Acc: 61.27%, Test Loss: 0.5659, Test Acc: 68.97%\n",
            "Epoch 7302/10000, Train Loss: 0.6326, Train Acc: 62.43%, Test Loss: 0.5637, Test Acc: 68.97%\n",
            "Epoch 7303/10000, Train Loss: 0.6072, Train Acc: 66.76%, Test Loss: 0.5603, Test Acc: 70.69%\n",
            "Epoch 7304/10000, Train Loss: 0.5884, Train Acc: 68.79%, Test Loss: 0.5630, Test Acc: 72.41%\n",
            "Epoch 7305/10000, Train Loss: 0.6386, Train Acc: 63.87%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 7306/10000, Train Loss: 0.6216, Train Acc: 62.43%, Test Loss: 0.5559, Test Acc: 75.86%\n",
            "Epoch 7307/10000, Train Loss: 0.6227, Train Acc: 67.63%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 7308/10000, Train Loss: 0.6137, Train Acc: 65.90%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 7309/10000, Train Loss: 0.6281, Train Acc: 61.85%, Test Loss: 0.5589, Test Acc: 74.14%\n",
            "Epoch 7310/10000, Train Loss: 0.6307, Train Acc: 61.56%, Test Loss: 0.5596, Test Acc: 72.41%\n",
            "Epoch 7311/10000, Train Loss: 0.6416, Train Acc: 65.90%, Test Loss: 0.5603, Test Acc: 74.14%\n",
            "Epoch 7312/10000, Train Loss: 0.6234, Train Acc: 64.45%, Test Loss: 0.5615, Test Acc: 75.86%\n",
            "Epoch 7313/10000, Train Loss: 0.5998, Train Acc: 63.01%, Test Loss: 0.5587, Test Acc: 74.14%\n",
            "Epoch 7314/10000, Train Loss: 0.5989, Train Acc: 65.61%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 7315/10000, Train Loss: 0.6134, Train Acc: 64.45%, Test Loss: 0.5499, Test Acc: 70.69%\n",
            "Epoch 7316/10000, Train Loss: 0.5898, Train Acc: 67.34%, Test Loss: 0.5505, Test Acc: 70.69%\n",
            "Epoch 7317/10000, Train Loss: 0.6231, Train Acc: 65.03%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 7318/10000, Train Loss: 0.6055, Train Acc: 64.45%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 7319/10000, Train Loss: 0.6442, Train Acc: 60.69%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 7320/10000, Train Loss: 0.6139, Train Acc: 60.98%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 7321/10000, Train Loss: 0.5780, Train Acc: 66.76%, Test Loss: 0.5599, Test Acc: 68.97%\n",
            "Epoch 7322/10000, Train Loss: 0.5868, Train Acc: 66.47%, Test Loss: 0.5617, Test Acc: 70.69%\n",
            "Epoch 7323/10000, Train Loss: 0.5944, Train Acc: 67.92%, Test Loss: 0.5615, Test Acc: 72.41%\n",
            "Epoch 7324/10000, Train Loss: 0.5972, Train Acc: 65.90%, Test Loss: 0.5619, Test Acc: 72.41%\n",
            "Epoch 7325/10000, Train Loss: 0.6103, Train Acc: 65.90%, Test Loss: 0.5653, Test Acc: 68.97%\n",
            "Epoch 7326/10000, Train Loss: 0.6323, Train Acc: 61.27%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 7327/10000, Train Loss: 0.6311, Train Acc: 63.58%, Test Loss: 0.5601, Test Acc: 70.69%\n",
            "Epoch 7328/10000, Train Loss: 0.6191, Train Acc: 64.74%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 7329/10000, Train Loss: 0.5932, Train Acc: 65.61%, Test Loss: 0.5611, Test Acc: 70.69%\n",
            "Epoch 7330/10000, Train Loss: 0.6157, Train Acc: 64.45%, Test Loss: 0.5597, Test Acc: 70.69%\n",
            "Epoch 7331/10000, Train Loss: 0.6146, Train Acc: 64.74%, Test Loss: 0.5574, Test Acc: 72.41%\n",
            "Epoch 7332/10000, Train Loss: 0.6343, Train Acc: 64.74%, Test Loss: 0.5554, Test Acc: 75.86%\n",
            "Epoch 7333/10000, Train Loss: 0.6090, Train Acc: 67.63%, Test Loss: 0.5579, Test Acc: 74.14%\n",
            "Epoch 7334/10000, Train Loss: 0.5913, Train Acc: 65.03%, Test Loss: 0.5616, Test Acc: 74.14%\n",
            "Epoch 7335/10000, Train Loss: 0.6150, Train Acc: 65.32%, Test Loss: 0.5585, Test Acc: 72.41%\n",
            "Epoch 7336/10000, Train Loss: 0.6143, Train Acc: 67.05%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 7337/10000, Train Loss: 0.6248, Train Acc: 62.14%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 7338/10000, Train Loss: 0.6219, Train Acc: 63.01%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 7339/10000, Train Loss: 0.6195, Train Acc: 63.01%, Test Loss: 0.5518, Test Acc: 74.14%\n",
            "Epoch 7340/10000, Train Loss: 0.6106, Train Acc: 66.18%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 7341/10000, Train Loss: 0.6150, Train Acc: 64.74%, Test Loss: 0.5503, Test Acc: 72.41%\n",
            "Epoch 7342/10000, Train Loss: 0.5950, Train Acc: 65.61%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 7343/10000, Train Loss: 0.6101, Train Acc: 66.47%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7344/10000, Train Loss: 0.6129, Train Acc: 65.61%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 7345/10000, Train Loss: 0.5965, Train Acc: 64.74%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 7346/10000, Train Loss: 0.6017, Train Acc: 66.18%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 7347/10000, Train Loss: 0.6105, Train Acc: 64.16%, Test Loss: 0.5568, Test Acc: 70.69%\n",
            "Epoch 7348/10000, Train Loss: 0.6019, Train Acc: 65.32%, Test Loss: 0.5589, Test Acc: 72.41%\n",
            "Epoch 7349/10000, Train Loss: 0.6218, Train Acc: 64.45%, Test Loss: 0.5586, Test Acc: 68.97%\n",
            "Epoch 7350/10000, Train Loss: 0.6076, Train Acc: 65.61%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7351/10000, Train Loss: 0.6227, Train Acc: 64.16%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 7352/10000, Train Loss: 0.6089, Train Acc: 65.90%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 7353/10000, Train Loss: 0.6055, Train Acc: 66.18%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 7354/10000, Train Loss: 0.6212, Train Acc: 67.05%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 7355/10000, Train Loss: 0.6087, Train Acc: 64.16%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 7356/10000, Train Loss: 0.6330, Train Acc: 64.45%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 7357/10000, Train Loss: 0.5817, Train Acc: 68.79%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 7358/10000, Train Loss: 0.5867, Train Acc: 66.18%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 7359/10000, Train Loss: 0.6215, Train Acc: 62.43%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 7360/10000, Train Loss: 0.6153, Train Acc: 64.74%, Test Loss: 0.5542, Test Acc: 74.14%\n",
            "Epoch 7361/10000, Train Loss: 0.6094, Train Acc: 62.72%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 7362/10000, Train Loss: 0.6238, Train Acc: 67.05%, Test Loss: 0.5506, Test Acc: 68.97%\n",
            "Epoch 7363/10000, Train Loss: 0.6099, Train Acc: 67.63%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 7364/10000, Train Loss: 0.6165, Train Acc: 67.05%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 7365/10000, Train Loss: 0.5908, Train Acc: 68.50%, Test Loss: 0.5623, Test Acc: 70.69%\n",
            "Epoch 7366/10000, Train Loss: 0.6057, Train Acc: 67.92%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 7367/10000, Train Loss: 0.6066, Train Acc: 64.45%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 7368/10000, Train Loss: 0.6011, Train Acc: 65.61%, Test Loss: 0.5552, Test Acc: 74.14%\n",
            "Epoch 7369/10000, Train Loss: 0.5857, Train Acc: 69.65%, Test Loss: 0.5506, Test Acc: 70.69%\n",
            "Epoch 7370/10000, Train Loss: 0.6070, Train Acc: 62.43%, Test Loss: 0.5495, Test Acc: 70.69%\n",
            "Epoch 7371/10000, Train Loss: 0.6484, Train Acc: 64.16%, Test Loss: 0.5484, Test Acc: 68.97%\n",
            "Epoch 7372/10000, Train Loss: 0.6224, Train Acc: 64.74%, Test Loss: 0.5551, Test Acc: 70.69%\n",
            "Epoch 7373/10000, Train Loss: 0.6266, Train Acc: 67.05%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 7374/10000, Train Loss: 0.6158, Train Acc: 66.18%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7375/10000, Train Loss: 0.6443, Train Acc: 65.61%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 7376/10000, Train Loss: 0.6139, Train Acc: 64.45%, Test Loss: 0.5505, Test Acc: 72.41%\n",
            "Epoch 7377/10000, Train Loss: 0.6195, Train Acc: 64.45%, Test Loss: 0.5496, Test Acc: 72.41%\n",
            "Epoch 7378/10000, Train Loss: 0.6208, Train Acc: 62.72%, Test Loss: 0.5490, Test Acc: 72.41%\n",
            "Epoch 7379/10000, Train Loss: 0.6284, Train Acc: 64.74%, Test Loss: 0.5464, Test Acc: 72.41%\n",
            "Epoch 7380/10000, Train Loss: 0.6147, Train Acc: 65.61%, Test Loss: 0.5467, Test Acc: 68.97%\n",
            "Epoch 7381/10000, Train Loss: 0.6153, Train Acc: 66.47%, Test Loss: 0.5473, Test Acc: 68.97%\n",
            "Epoch 7382/10000, Train Loss: 0.6293, Train Acc: 65.90%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 7383/10000, Train Loss: 0.6077, Train Acc: 67.63%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 7384/10000, Train Loss: 0.6410, Train Acc: 63.01%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 7385/10000, Train Loss: 0.6368, Train Acc: 61.85%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 7386/10000, Train Loss: 0.6158, Train Acc: 65.61%, Test Loss: 0.5512, Test Acc: 70.69%\n",
            "Epoch 7387/10000, Train Loss: 0.5970, Train Acc: 66.47%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7388/10000, Train Loss: 0.5989, Train Acc: 66.18%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 7389/10000, Train Loss: 0.6174, Train Acc: 64.45%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 7390/10000, Train Loss: 0.6160, Train Acc: 63.87%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 7391/10000, Train Loss: 0.5886, Train Acc: 64.45%, Test Loss: 0.5498, Test Acc: 68.97%\n",
            "Epoch 7392/10000, Train Loss: 0.6223, Train Acc: 63.87%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 7393/10000, Train Loss: 0.6330, Train Acc: 63.29%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 7394/10000, Train Loss: 0.6069, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 7395/10000, Train Loss: 0.5997, Train Acc: 67.05%, Test Loss: 0.5578, Test Acc: 70.69%\n",
            "Epoch 7396/10000, Train Loss: 0.5902, Train Acc: 66.76%, Test Loss: 0.5602, Test Acc: 70.69%\n",
            "Epoch 7397/10000, Train Loss: 0.6298, Train Acc: 64.16%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 7398/10000, Train Loss: 0.6174, Train Acc: 65.03%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 7399/10000, Train Loss: 0.6081, Train Acc: 65.03%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7400/10000, Train Loss: 0.6368, Train Acc: 62.14%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 7401/10000, Train Loss: 0.6296, Train Acc: 63.87%, Test Loss: 0.5541, Test Acc: 74.14%\n",
            "Epoch 7402/10000, Train Loss: 0.6061, Train Acc: 64.45%, Test Loss: 0.5520, Test Acc: 70.69%\n",
            "Epoch 7403/10000, Train Loss: 0.6041, Train Acc: 67.05%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 7404/10000, Train Loss: 0.5999, Train Acc: 64.74%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 7405/10000, Train Loss: 0.6097, Train Acc: 69.65%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7406/10000, Train Loss: 0.6235, Train Acc: 63.87%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 7407/10000, Train Loss: 0.6300, Train Acc: 62.14%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 7408/10000, Train Loss: 0.6164, Train Acc: 65.32%, Test Loss: 0.5554, Test Acc: 72.41%\n",
            "Epoch 7409/10000, Train Loss: 0.6146, Train Acc: 64.45%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 7410/10000, Train Loss: 0.6162, Train Acc: 63.58%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 7411/10000, Train Loss: 0.6147, Train Acc: 66.76%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 7412/10000, Train Loss: 0.6146, Train Acc: 63.01%, Test Loss: 0.5485, Test Acc: 72.41%\n",
            "Epoch 7413/10000, Train Loss: 0.6098, Train Acc: 65.61%, Test Loss: 0.5504, Test Acc: 68.97%\n",
            "Epoch 7414/10000, Train Loss: 0.6063, Train Acc: 67.34%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 7415/10000, Train Loss: 0.6370, Train Acc: 62.14%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 7416/10000, Train Loss: 0.6507, Train Acc: 65.03%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 7417/10000, Train Loss: 0.6043, Train Acc: 65.32%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 7418/10000, Train Loss: 0.6032, Train Acc: 65.03%, Test Loss: 0.5595, Test Acc: 70.69%\n",
            "Epoch 7419/10000, Train Loss: 0.6120, Train Acc: 66.18%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 7420/10000, Train Loss: 0.6203, Train Acc: 62.43%, Test Loss: 0.5632, Test Acc: 68.97%\n",
            "Epoch 7421/10000, Train Loss: 0.6163, Train Acc: 64.74%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 7422/10000, Train Loss: 0.6245, Train Acc: 67.05%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 7423/10000, Train Loss: 0.6145, Train Acc: 63.58%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 7424/10000, Train Loss: 0.6119, Train Acc: 66.18%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 7425/10000, Train Loss: 0.6333, Train Acc: 62.14%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 7426/10000, Train Loss: 0.6371, Train Acc: 59.83%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 7427/10000, Train Loss: 0.6001, Train Acc: 65.61%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 7428/10000, Train Loss: 0.6324, Train Acc: 64.45%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 7429/10000, Train Loss: 0.6045, Train Acc: 61.27%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 7430/10000, Train Loss: 0.6136, Train Acc: 60.12%, Test Loss: 0.5556, Test Acc: 74.14%\n",
            "Epoch 7431/10000, Train Loss: 0.6274, Train Acc: 65.03%, Test Loss: 0.5579, Test Acc: 72.41%\n",
            "Epoch 7432/10000, Train Loss: 0.6089, Train Acc: 67.63%, Test Loss: 0.5572, Test Acc: 72.41%\n",
            "Epoch 7433/10000, Train Loss: 0.6196, Train Acc: 64.16%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 7434/10000, Train Loss: 0.6218, Train Acc: 66.18%, Test Loss: 0.5546, Test Acc: 74.14%\n",
            "Epoch 7435/10000, Train Loss: 0.6276, Train Acc: 64.45%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 7436/10000, Train Loss: 0.6076, Train Acc: 65.03%, Test Loss: 0.5503, Test Acc: 72.41%\n",
            "Epoch 7437/10000, Train Loss: 0.6315, Train Acc: 62.72%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 7438/10000, Train Loss: 0.6048, Train Acc: 65.90%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7439/10000, Train Loss: 0.6414, Train Acc: 60.98%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 7440/10000, Train Loss: 0.6019, Train Acc: 63.58%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 7441/10000, Train Loss: 0.5908, Train Acc: 63.58%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7442/10000, Train Loss: 0.6239, Train Acc: 65.32%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 7443/10000, Train Loss: 0.6030, Train Acc: 66.18%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7444/10000, Train Loss: 0.6375, Train Acc: 63.01%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 7445/10000, Train Loss: 0.6097, Train Acc: 66.18%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7446/10000, Train Loss: 0.6216, Train Acc: 66.76%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 7447/10000, Train Loss: 0.6027, Train Acc: 68.21%, Test Loss: 0.5596, Test Acc: 70.69%\n",
            "Epoch 7448/10000, Train Loss: 0.6407, Train Acc: 64.16%, Test Loss: 0.5620, Test Acc: 68.97%\n",
            "Epoch 7449/10000, Train Loss: 0.6144, Train Acc: 65.32%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 7450/10000, Train Loss: 0.6134, Train Acc: 62.72%, Test Loss: 0.5611, Test Acc: 70.69%\n",
            "Epoch 7451/10000, Train Loss: 0.6279, Train Acc: 63.29%, Test Loss: 0.5591, Test Acc: 74.14%\n",
            "Epoch 7452/10000, Train Loss: 0.6086, Train Acc: 65.32%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 7453/10000, Train Loss: 0.6291, Train Acc: 66.47%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 7454/10000, Train Loss: 0.5979, Train Acc: 65.03%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 7455/10000, Train Loss: 0.6048, Train Acc: 65.61%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 7456/10000, Train Loss: 0.6012, Train Acc: 65.32%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 7457/10000, Train Loss: 0.5893, Train Acc: 70.23%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 7458/10000, Train Loss: 0.6005, Train Acc: 68.50%, Test Loss: 0.5599, Test Acc: 68.97%\n",
            "Epoch 7459/10000, Train Loss: 0.6123, Train Acc: 61.85%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 7460/10000, Train Loss: 0.6156, Train Acc: 65.03%, Test Loss: 0.5641, Test Acc: 70.69%\n",
            "Epoch 7461/10000, Train Loss: 0.6257, Train Acc: 66.47%, Test Loss: 0.5646, Test Acc: 68.97%\n",
            "Epoch 7462/10000, Train Loss: 0.6206, Train Acc: 61.85%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 7463/10000, Train Loss: 0.6115, Train Acc: 65.03%, Test Loss: 0.5584, Test Acc: 74.14%\n",
            "Epoch 7464/10000, Train Loss: 0.6146, Train Acc: 62.14%, Test Loss: 0.5612, Test Acc: 72.41%\n",
            "Epoch 7465/10000, Train Loss: 0.6317, Train Acc: 65.61%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 7466/10000, Train Loss: 0.6279, Train Acc: 63.58%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 7467/10000, Train Loss: 0.6361, Train Acc: 60.69%, Test Loss: 0.5545, Test Acc: 74.14%\n",
            "Epoch 7468/10000, Train Loss: 0.6006, Train Acc: 67.63%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 7469/10000, Train Loss: 0.5979, Train Acc: 65.03%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 7470/10000, Train Loss: 0.5828, Train Acc: 64.16%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 7471/10000, Train Loss: 0.6279, Train Acc: 64.74%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7472/10000, Train Loss: 0.6082, Train Acc: 64.74%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 7473/10000, Train Loss: 0.6303, Train Acc: 63.58%, Test Loss: 0.5600, Test Acc: 70.69%\n",
            "Epoch 7474/10000, Train Loss: 0.6143, Train Acc: 67.05%, Test Loss: 0.5631, Test Acc: 72.41%\n",
            "Epoch 7475/10000, Train Loss: 0.6192, Train Acc: 61.85%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 7476/10000, Train Loss: 0.5905, Train Acc: 65.32%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 7477/10000, Train Loss: 0.5935, Train Acc: 66.18%, Test Loss: 0.5557, Test Acc: 74.14%\n",
            "Epoch 7478/10000, Train Loss: 0.6250, Train Acc: 65.90%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 7479/10000, Train Loss: 0.6031, Train Acc: 63.58%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 7480/10000, Train Loss: 0.6197, Train Acc: 63.29%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 7481/10000, Train Loss: 0.6024, Train Acc: 65.90%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 7482/10000, Train Loss: 0.6201, Train Acc: 63.01%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 7483/10000, Train Loss: 0.6125, Train Acc: 67.34%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 7484/10000, Train Loss: 0.6339, Train Acc: 63.87%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 7485/10000, Train Loss: 0.6106, Train Acc: 63.01%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 7486/10000, Train Loss: 0.6090, Train Acc: 65.90%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 7487/10000, Train Loss: 0.6054, Train Acc: 63.58%, Test Loss: 0.5623, Test Acc: 70.69%\n",
            "Epoch 7488/10000, Train Loss: 0.5932, Train Acc: 68.21%, Test Loss: 0.5634, Test Acc: 68.97%\n",
            "Epoch 7489/10000, Train Loss: 0.5927, Train Acc: 64.16%, Test Loss: 0.5683, Test Acc: 68.97%\n",
            "Epoch 7490/10000, Train Loss: 0.6304, Train Acc: 64.74%, Test Loss: 0.5619, Test Acc: 68.97%\n",
            "Epoch 7491/10000, Train Loss: 0.6264, Train Acc: 65.03%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 7492/10000, Train Loss: 0.6244, Train Acc: 63.87%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 7493/10000, Train Loss: 0.5961, Train Acc: 66.47%, Test Loss: 0.5580, Test Acc: 72.41%\n",
            "Epoch 7494/10000, Train Loss: 0.6091, Train Acc: 64.74%, Test Loss: 0.5565, Test Acc: 72.41%\n",
            "Epoch 7495/10000, Train Loss: 0.6097, Train Acc: 66.47%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 7496/10000, Train Loss: 0.5888, Train Acc: 66.47%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 7497/10000, Train Loss: 0.6169, Train Acc: 64.74%, Test Loss: 0.5602, Test Acc: 74.14%\n",
            "Epoch 7498/10000, Train Loss: 0.6310, Train Acc: 64.45%, Test Loss: 0.5551, Test Acc: 74.14%\n",
            "Epoch 7499/10000, Train Loss: 0.6072, Train Acc: 63.01%, Test Loss: 0.5514, Test Acc: 72.41%\n",
            "Epoch 7500/10000, Train Loss: 0.6070, Train Acc: 65.03%, Test Loss: 0.5489, Test Acc: 68.97%\n",
            "Epoch 7501/10000, Train Loss: 0.6031, Train Acc: 63.87%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7502/10000, Train Loss: 0.6221, Train Acc: 62.72%, Test Loss: 0.5632, Test Acc: 68.97%\n",
            "Epoch 7503/10000, Train Loss: 0.6178, Train Acc: 65.90%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 7504/10000, Train Loss: 0.6090, Train Acc: 61.85%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 7505/10000, Train Loss: 0.6220, Train Acc: 62.72%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 7506/10000, Train Loss: 0.6283, Train Acc: 63.01%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 7507/10000, Train Loss: 0.6376, Train Acc: 61.27%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 7508/10000, Train Loss: 0.6074, Train Acc: 66.47%, Test Loss: 0.5494, Test Acc: 70.69%\n",
            "Epoch 7509/10000, Train Loss: 0.5913, Train Acc: 64.45%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 7510/10000, Train Loss: 0.6319, Train Acc: 64.74%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7511/10000, Train Loss: 0.6172, Train Acc: 64.74%, Test Loss: 0.5582, Test Acc: 70.69%\n",
            "Epoch 7512/10000, Train Loss: 0.6008, Train Acc: 64.16%, Test Loss: 0.5611, Test Acc: 70.69%\n",
            "Epoch 7513/10000, Train Loss: 0.6007, Train Acc: 67.05%, Test Loss: 0.5616, Test Acc: 70.69%\n",
            "Epoch 7514/10000, Train Loss: 0.6007, Train Acc: 63.58%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 7515/10000, Train Loss: 0.6121, Train Acc: 65.03%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 7516/10000, Train Loss: 0.6057, Train Acc: 65.90%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 7517/10000, Train Loss: 0.6130, Train Acc: 66.18%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 7518/10000, Train Loss: 0.6387, Train Acc: 64.45%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 7519/10000, Train Loss: 0.6291, Train Acc: 60.40%, Test Loss: 0.5566, Test Acc: 72.41%\n",
            "Epoch 7520/10000, Train Loss: 0.6133, Train Acc: 64.16%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 7521/10000, Train Loss: 0.5921, Train Acc: 66.76%, Test Loss: 0.5519, Test Acc: 70.69%\n",
            "Epoch 7522/10000, Train Loss: 0.6089, Train Acc: 63.29%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 7523/10000, Train Loss: 0.6236, Train Acc: 61.56%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 7524/10000, Train Loss: 0.6062, Train Acc: 69.08%, Test Loss: 0.5509, Test Acc: 70.69%\n",
            "Epoch 7525/10000, Train Loss: 0.6073, Train Acc: 67.92%, Test Loss: 0.5502, Test Acc: 67.24%\n",
            "Epoch 7526/10000, Train Loss: 0.6006, Train Acc: 65.32%, Test Loss: 0.5485, Test Acc: 68.97%\n",
            "Epoch 7527/10000, Train Loss: 0.6126, Train Acc: 62.14%, Test Loss: 0.5515, Test Acc: 70.69%\n",
            "Epoch 7528/10000, Train Loss: 0.6251, Train Acc: 65.90%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 7529/10000, Train Loss: 0.6060, Train Acc: 65.90%, Test Loss: 0.5581, Test Acc: 70.69%\n",
            "Epoch 7530/10000, Train Loss: 0.6231, Train Acc: 64.74%, Test Loss: 0.5591, Test Acc: 70.69%\n",
            "Epoch 7531/10000, Train Loss: 0.6254, Train Acc: 63.29%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 7532/10000, Train Loss: 0.6082, Train Acc: 64.16%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 7533/10000, Train Loss: 0.6258, Train Acc: 66.47%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 7534/10000, Train Loss: 0.6216, Train Acc: 62.43%, Test Loss: 0.5564, Test Acc: 74.14%\n",
            "Epoch 7535/10000, Train Loss: 0.6049, Train Acc: 67.34%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 7536/10000, Train Loss: 0.6415, Train Acc: 62.72%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7537/10000, Train Loss: 0.6129, Train Acc: 65.03%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 7538/10000, Train Loss: 0.6076, Train Acc: 65.32%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 7539/10000, Train Loss: 0.6002, Train Acc: 67.05%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 7540/10000, Train Loss: 0.6243, Train Acc: 60.98%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7541/10000, Train Loss: 0.6160, Train Acc: 63.29%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 7542/10000, Train Loss: 0.6038, Train Acc: 65.03%, Test Loss: 0.5484, Test Acc: 70.69%\n",
            "Epoch 7543/10000, Train Loss: 0.5973, Train Acc: 67.05%, Test Loss: 0.5511, Test Acc: 70.69%\n",
            "Epoch 7544/10000, Train Loss: 0.6167, Train Acc: 65.90%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7545/10000, Train Loss: 0.6353, Train Acc: 63.87%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 7546/10000, Train Loss: 0.6224, Train Acc: 62.43%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 7547/10000, Train Loss: 0.6316, Train Acc: 62.72%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7548/10000, Train Loss: 0.6214, Train Acc: 61.85%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7549/10000, Train Loss: 0.6135, Train Acc: 67.05%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 7550/10000, Train Loss: 0.6182, Train Acc: 64.74%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 7551/10000, Train Loss: 0.5842, Train Acc: 68.21%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7552/10000, Train Loss: 0.6108, Train Acc: 64.16%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 7553/10000, Train Loss: 0.6202, Train Acc: 64.45%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7554/10000, Train Loss: 0.6058, Train Acc: 63.01%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 7555/10000, Train Loss: 0.6046, Train Acc: 65.03%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 7556/10000, Train Loss: 0.5898, Train Acc: 66.18%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 7557/10000, Train Loss: 0.6153, Train Acc: 66.18%, Test Loss: 0.5636, Test Acc: 68.97%\n",
            "Epoch 7558/10000, Train Loss: 0.6328, Train Acc: 60.98%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 7559/10000, Train Loss: 0.6211, Train Acc: 65.03%, Test Loss: 0.5552, Test Acc: 74.14%\n",
            "Epoch 7560/10000, Train Loss: 0.6225, Train Acc: 63.01%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 7561/10000, Train Loss: 0.6010, Train Acc: 66.47%, Test Loss: 0.5568, Test Acc: 72.41%\n",
            "Epoch 7562/10000, Train Loss: 0.6279, Train Acc: 66.76%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 7563/10000, Train Loss: 0.6216, Train Acc: 61.85%, Test Loss: 0.5512, Test Acc: 72.41%\n",
            "Epoch 7564/10000, Train Loss: 0.6321, Train Acc: 60.69%, Test Loss: 0.5490, Test Acc: 70.69%\n",
            "Epoch 7565/10000, Train Loss: 0.5994, Train Acc: 66.47%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 7566/10000, Train Loss: 0.6133, Train Acc: 65.61%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7567/10000, Train Loss: 0.6025, Train Acc: 66.18%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 7568/10000, Train Loss: 0.6194, Train Acc: 65.61%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 7569/10000, Train Loss: 0.5897, Train Acc: 66.18%, Test Loss: 0.5495, Test Acc: 68.97%\n",
            "Epoch 7570/10000, Train Loss: 0.6044, Train Acc: 68.79%, Test Loss: 0.5516, Test Acc: 70.69%\n",
            "Epoch 7571/10000, Train Loss: 0.6070, Train Acc: 66.47%, Test Loss: 0.5527, Test Acc: 70.69%\n",
            "Epoch 7572/10000, Train Loss: 0.5999, Train Acc: 65.61%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 7573/10000, Train Loss: 0.6138, Train Acc: 61.85%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 7574/10000, Train Loss: 0.6273, Train Acc: 66.47%, Test Loss: 0.5527, Test Acc: 70.69%\n",
            "Epoch 7575/10000, Train Loss: 0.6354, Train Acc: 65.32%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 7576/10000, Train Loss: 0.6246, Train Acc: 65.32%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7577/10000, Train Loss: 0.5938, Train Acc: 67.05%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 7578/10000, Train Loss: 0.6123, Train Acc: 66.47%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 7579/10000, Train Loss: 0.6115, Train Acc: 63.01%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7580/10000, Train Loss: 0.6142, Train Acc: 61.85%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 7581/10000, Train Loss: 0.6284, Train Acc: 67.05%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 7582/10000, Train Loss: 0.6327, Train Acc: 65.32%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 7583/10000, Train Loss: 0.6296, Train Acc: 63.29%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 7584/10000, Train Loss: 0.6302, Train Acc: 65.32%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 7585/10000, Train Loss: 0.6192, Train Acc: 63.87%, Test Loss: 0.5512, Test Acc: 70.69%\n",
            "Epoch 7586/10000, Train Loss: 0.6120, Train Acc: 68.79%, Test Loss: 0.5473, Test Acc: 72.41%\n",
            "Epoch 7587/10000, Train Loss: 0.6097, Train Acc: 66.76%, Test Loss: 0.5479, Test Acc: 72.41%\n",
            "Epoch 7588/10000, Train Loss: 0.6016, Train Acc: 65.32%, Test Loss: 0.5493, Test Acc: 72.41%\n",
            "Epoch 7589/10000, Train Loss: 0.6157, Train Acc: 63.58%, Test Loss: 0.5480, Test Acc: 68.97%\n",
            "Epoch 7590/10000, Train Loss: 0.6030, Train Acc: 63.01%, Test Loss: 0.5489, Test Acc: 70.69%\n",
            "Epoch 7591/10000, Train Loss: 0.6142, Train Acc: 64.74%, Test Loss: 0.5515, Test Acc: 70.69%\n",
            "Epoch 7592/10000, Train Loss: 0.6440, Train Acc: 61.27%, Test Loss: 0.5556, Test Acc: 74.14%\n",
            "Epoch 7593/10000, Train Loss: 0.6321, Train Acc: 63.01%, Test Loss: 0.5618, Test Acc: 70.69%\n",
            "Epoch 7594/10000, Train Loss: 0.6194, Train Acc: 65.03%, Test Loss: 0.5653, Test Acc: 72.41%\n",
            "Epoch 7595/10000, Train Loss: 0.6015, Train Acc: 67.34%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 7596/10000, Train Loss: 0.6207, Train Acc: 64.45%, Test Loss: 0.5578, Test Acc: 70.69%\n",
            "Epoch 7597/10000, Train Loss: 0.6246, Train Acc: 61.85%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 7598/10000, Train Loss: 0.6297, Train Acc: 61.85%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 7599/10000, Train Loss: 0.6102, Train Acc: 64.45%, Test Loss: 0.5556, Test Acc: 70.69%\n",
            "Epoch 7600/10000, Train Loss: 0.5941, Train Acc: 67.63%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 7601/10000, Train Loss: 0.6141, Train Acc: 65.61%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 7602/10000, Train Loss: 0.5968, Train Acc: 66.47%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 7603/10000, Train Loss: 0.5925, Train Acc: 64.16%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7604/10000, Train Loss: 0.6150, Train Acc: 62.43%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7605/10000, Train Loss: 0.6073, Train Acc: 66.47%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 7606/10000, Train Loss: 0.6228, Train Acc: 63.87%, Test Loss: 0.5532, Test Acc: 70.69%\n",
            "Epoch 7607/10000, Train Loss: 0.6310, Train Acc: 61.85%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 7608/10000, Train Loss: 0.6278, Train Acc: 60.98%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 7609/10000, Train Loss: 0.6513, Train Acc: 65.03%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 7610/10000, Train Loss: 0.6161, Train Acc: 63.01%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 7611/10000, Train Loss: 0.6206, Train Acc: 63.58%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 7612/10000, Train Loss: 0.6233, Train Acc: 63.01%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 7613/10000, Train Loss: 0.6207, Train Acc: 63.01%, Test Loss: 0.5530, Test Acc: 70.69%\n",
            "Epoch 7614/10000, Train Loss: 0.6160, Train Acc: 65.03%, Test Loss: 0.5525, Test Acc: 70.69%\n",
            "Epoch 7615/10000, Train Loss: 0.6182, Train Acc: 63.01%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 7616/10000, Train Loss: 0.6209, Train Acc: 65.90%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 7617/10000, Train Loss: 0.6217, Train Acc: 63.58%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 7618/10000, Train Loss: 0.5998, Train Acc: 66.47%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 7619/10000, Train Loss: 0.6183, Train Acc: 66.76%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 7620/10000, Train Loss: 0.6039, Train Acc: 66.18%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 7621/10000, Train Loss: 0.6075, Train Acc: 67.05%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 7622/10000, Train Loss: 0.6034, Train Acc: 64.45%, Test Loss: 0.5587, Test Acc: 72.41%\n",
            "Epoch 7623/10000, Train Loss: 0.5939, Train Acc: 64.74%, Test Loss: 0.5647, Test Acc: 68.97%\n",
            "Epoch 7624/10000, Train Loss: 0.6004, Train Acc: 68.50%, Test Loss: 0.5627, Test Acc: 70.69%\n",
            "Epoch 7625/10000, Train Loss: 0.5962, Train Acc: 68.21%, Test Loss: 0.5626, Test Acc: 68.97%\n",
            "Epoch 7626/10000, Train Loss: 0.6035, Train Acc: 64.45%, Test Loss: 0.5619, Test Acc: 68.97%\n",
            "Epoch 7627/10000, Train Loss: 0.6041, Train Acc: 62.72%, Test Loss: 0.5601, Test Acc: 70.69%\n",
            "Epoch 7628/10000, Train Loss: 0.6306, Train Acc: 65.61%, Test Loss: 0.5583, Test Acc: 74.14%\n",
            "Epoch 7629/10000, Train Loss: 0.5945, Train Acc: 66.47%, Test Loss: 0.5575, Test Acc: 74.14%\n",
            "Epoch 7630/10000, Train Loss: 0.6222, Train Acc: 64.16%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 7631/10000, Train Loss: 0.5976, Train Acc: 67.63%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 7632/10000, Train Loss: 0.5934, Train Acc: 65.32%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 7633/10000, Train Loss: 0.5994, Train Acc: 63.58%, Test Loss: 0.5558, Test Acc: 74.14%\n",
            "Epoch 7634/10000, Train Loss: 0.5865, Train Acc: 68.79%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 7635/10000, Train Loss: 0.5895, Train Acc: 67.92%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 7636/10000, Train Loss: 0.6069, Train Acc: 61.27%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 7637/10000, Train Loss: 0.6347, Train Acc: 65.32%, Test Loss: 0.5584, Test Acc: 72.41%\n",
            "Epoch 7638/10000, Train Loss: 0.6101, Train Acc: 63.29%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 7639/10000, Train Loss: 0.6119, Train Acc: 67.92%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 7640/10000, Train Loss: 0.6159, Train Acc: 66.18%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 7641/10000, Train Loss: 0.6215, Train Acc: 65.90%, Test Loss: 0.5536, Test Acc: 74.14%\n",
            "Epoch 7642/10000, Train Loss: 0.6136, Train Acc: 64.16%, Test Loss: 0.5545, Test Acc: 75.86%\n",
            "Epoch 7643/10000, Train Loss: 0.6252, Train Acc: 64.74%, Test Loss: 0.5516, Test Acc: 74.14%\n",
            "Epoch 7644/10000, Train Loss: 0.5903, Train Acc: 65.90%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 7645/10000, Train Loss: 0.6158, Train Acc: 62.72%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 7646/10000, Train Loss: 0.6383, Train Acc: 63.29%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 7647/10000, Train Loss: 0.6014, Train Acc: 65.90%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 7648/10000, Train Loss: 0.6099, Train Acc: 65.61%, Test Loss: 0.5634, Test Acc: 68.97%\n",
            "Epoch 7649/10000, Train Loss: 0.6204, Train Acc: 62.43%, Test Loss: 0.5606, Test Acc: 70.69%\n",
            "Epoch 7650/10000, Train Loss: 0.6452, Train Acc: 64.16%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 7651/10000, Train Loss: 0.6308, Train Acc: 65.61%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 7652/10000, Train Loss: 0.6027, Train Acc: 65.32%, Test Loss: 0.5510, Test Acc: 74.14%\n",
            "Epoch 7653/10000, Train Loss: 0.6325, Train Acc: 64.45%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 7654/10000, Train Loss: 0.6072, Train Acc: 66.47%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 7655/10000, Train Loss: 0.6226, Train Acc: 64.45%, Test Loss: 0.5515, Test Acc: 70.69%\n",
            "Epoch 7656/10000, Train Loss: 0.6165, Train Acc: 65.32%, Test Loss: 0.5505, Test Acc: 72.41%\n",
            "Epoch 7657/10000, Train Loss: 0.6124, Train Acc: 65.90%, Test Loss: 0.5491, Test Acc: 70.69%\n",
            "Epoch 7658/10000, Train Loss: 0.6033, Train Acc: 63.01%, Test Loss: 0.5477, Test Acc: 70.69%\n",
            "Epoch 7659/10000, Train Loss: 0.6129, Train Acc: 62.43%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 7660/10000, Train Loss: 0.6105, Train Acc: 65.90%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 7661/10000, Train Loss: 0.6129, Train Acc: 63.29%, Test Loss: 0.5608, Test Acc: 70.69%\n",
            "Epoch 7662/10000, Train Loss: 0.6291, Train Acc: 65.03%, Test Loss: 0.5644, Test Acc: 70.69%\n",
            "Epoch 7663/10000, Train Loss: 0.6103, Train Acc: 67.34%, Test Loss: 0.5631, Test Acc: 72.41%\n",
            "Epoch 7664/10000, Train Loss: 0.6119, Train Acc: 65.32%, Test Loss: 0.5603, Test Acc: 72.41%\n",
            "Epoch 7665/10000, Train Loss: 0.6179, Train Acc: 64.16%, Test Loss: 0.5620, Test Acc: 70.69%\n",
            "Epoch 7666/10000, Train Loss: 0.5870, Train Acc: 67.63%, Test Loss: 0.5637, Test Acc: 70.69%\n",
            "Epoch 7667/10000, Train Loss: 0.6311, Train Acc: 63.58%, Test Loss: 0.5642, Test Acc: 68.97%\n",
            "Epoch 7668/10000, Train Loss: 0.6055, Train Acc: 66.76%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7669/10000, Train Loss: 0.6182, Train Acc: 66.47%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 7670/10000, Train Loss: 0.6146, Train Acc: 67.05%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 7671/10000, Train Loss: 0.5924, Train Acc: 67.05%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 7672/10000, Train Loss: 0.6177, Train Acc: 65.03%, Test Loss: 0.5542, Test Acc: 74.14%\n",
            "Epoch 7673/10000, Train Loss: 0.6197, Train Acc: 66.18%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 7674/10000, Train Loss: 0.6302, Train Acc: 68.79%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 7675/10000, Train Loss: 0.6195, Train Acc: 64.74%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 7676/10000, Train Loss: 0.6035, Train Acc: 68.50%, Test Loss: 0.5602, Test Acc: 70.69%\n",
            "Epoch 7677/10000, Train Loss: 0.5981, Train Acc: 69.36%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 7678/10000, Train Loss: 0.5982, Train Acc: 67.63%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7679/10000, Train Loss: 0.6115, Train Acc: 63.58%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 7680/10000, Train Loss: 0.6084, Train Acc: 64.16%, Test Loss: 0.5506, Test Acc: 72.41%\n",
            "Epoch 7681/10000, Train Loss: 0.6186, Train Acc: 63.01%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 7682/10000, Train Loss: 0.6233, Train Acc: 65.03%, Test Loss: 0.5493, Test Acc: 70.69%\n",
            "Epoch 7683/10000, Train Loss: 0.6103, Train Acc: 65.90%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 7684/10000, Train Loss: 0.6216, Train Acc: 61.85%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 7685/10000, Train Loss: 0.6145, Train Acc: 64.74%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 7686/10000, Train Loss: 0.6398, Train Acc: 63.87%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 7687/10000, Train Loss: 0.6156, Train Acc: 65.32%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 7688/10000, Train Loss: 0.6199, Train Acc: 67.05%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 7689/10000, Train Loss: 0.5887, Train Acc: 68.50%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 7690/10000, Train Loss: 0.6031, Train Acc: 66.47%, Test Loss: 0.5503, Test Acc: 72.41%\n",
            "Epoch 7691/10000, Train Loss: 0.6167, Train Acc: 65.03%, Test Loss: 0.5506, Test Acc: 70.69%\n",
            "Epoch 7692/10000, Train Loss: 0.6098, Train Acc: 66.18%, Test Loss: 0.5551, Test Acc: 70.69%\n",
            "Epoch 7693/10000, Train Loss: 0.6032, Train Acc: 65.32%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 7694/10000, Train Loss: 0.6263, Train Acc: 64.16%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 7695/10000, Train Loss: 0.6182, Train Acc: 63.87%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 7696/10000, Train Loss: 0.6169, Train Acc: 66.76%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 7697/10000, Train Loss: 0.6072, Train Acc: 64.45%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 7698/10000, Train Loss: 0.6122, Train Acc: 63.58%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 7699/10000, Train Loss: 0.6058, Train Acc: 64.74%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 7700/10000, Train Loss: 0.6262, Train Acc: 64.16%, Test Loss: 0.5610, Test Acc: 68.97%\n",
            "Epoch 7701/10000, Train Loss: 0.5825, Train Acc: 67.63%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 7702/10000, Train Loss: 0.6139, Train Acc: 64.74%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7703/10000, Train Loss: 0.6273, Train Acc: 65.61%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 7704/10000, Train Loss: 0.6173, Train Acc: 66.47%, Test Loss: 0.5526, Test Acc: 70.69%\n",
            "Epoch 7705/10000, Train Loss: 0.6258, Train Acc: 65.03%, Test Loss: 0.5518, Test Acc: 74.14%\n",
            "Epoch 7706/10000, Train Loss: 0.6157, Train Acc: 63.29%, Test Loss: 0.5511, Test Acc: 72.41%\n",
            "Epoch 7707/10000, Train Loss: 0.5974, Train Acc: 63.58%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 7708/10000, Train Loss: 0.5903, Train Acc: 69.36%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 7709/10000, Train Loss: 0.6059, Train Acc: 64.45%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 7710/10000, Train Loss: 0.6062, Train Acc: 64.16%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 7711/10000, Train Loss: 0.6144, Train Acc: 65.61%, Test Loss: 0.5526, Test Acc: 70.69%\n",
            "Epoch 7712/10000, Train Loss: 0.6158, Train Acc: 65.03%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 7713/10000, Train Loss: 0.6213, Train Acc: 64.45%, Test Loss: 0.5525, Test Acc: 70.69%\n",
            "Epoch 7714/10000, Train Loss: 0.6032, Train Acc: 66.47%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 7715/10000, Train Loss: 0.6196, Train Acc: 64.45%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 7716/10000, Train Loss: 0.6121, Train Acc: 61.85%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 7717/10000, Train Loss: 0.6155, Train Acc: 63.01%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 7718/10000, Train Loss: 0.6311, Train Acc: 60.69%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 7719/10000, Train Loss: 0.6192, Train Acc: 66.47%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 7720/10000, Train Loss: 0.5982, Train Acc: 65.90%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 7721/10000, Train Loss: 0.5926, Train Acc: 66.47%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7722/10000, Train Loss: 0.6096, Train Acc: 64.16%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7723/10000, Train Loss: 0.6071, Train Acc: 64.74%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 7724/10000, Train Loss: 0.5999, Train Acc: 63.58%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7725/10000, Train Loss: 0.6250, Train Acc: 65.61%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7726/10000, Train Loss: 0.5997, Train Acc: 67.34%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 7727/10000, Train Loss: 0.6327, Train Acc: 64.16%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 7728/10000, Train Loss: 0.6384, Train Acc: 61.85%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 7729/10000, Train Loss: 0.5996, Train Acc: 67.63%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 7730/10000, Train Loss: 0.6098, Train Acc: 62.14%, Test Loss: 0.5524, Test Acc: 74.14%\n",
            "Epoch 7731/10000, Train Loss: 0.6454, Train Acc: 64.74%, Test Loss: 0.5473, Test Acc: 70.69%\n",
            "Epoch 7732/10000, Train Loss: 0.5989, Train Acc: 65.03%, Test Loss: 0.5444, Test Acc: 68.97%\n",
            "Epoch 7733/10000, Train Loss: 0.6125, Train Acc: 65.90%, Test Loss: 0.5476, Test Acc: 70.69%\n",
            "Epoch 7734/10000, Train Loss: 0.6166, Train Acc: 66.76%, Test Loss: 0.5502, Test Acc: 70.69%\n",
            "Epoch 7735/10000, Train Loss: 0.6326, Train Acc: 61.85%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 7736/10000, Train Loss: 0.6325, Train Acc: 63.87%, Test Loss: 0.5583, Test Acc: 70.69%\n",
            "Epoch 7737/10000, Train Loss: 0.6324, Train Acc: 62.14%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 7738/10000, Train Loss: 0.5991, Train Acc: 65.61%, Test Loss: 0.5633, Test Acc: 70.69%\n",
            "Epoch 7739/10000, Train Loss: 0.5906, Train Acc: 68.50%, Test Loss: 0.5646, Test Acc: 68.97%\n",
            "Epoch 7740/10000, Train Loss: 0.6003, Train Acc: 63.58%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 7741/10000, Train Loss: 0.6119, Train Acc: 64.16%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 7742/10000, Train Loss: 0.6268, Train Acc: 61.56%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 7743/10000, Train Loss: 0.6243, Train Acc: 63.87%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 7744/10000, Train Loss: 0.6129, Train Acc: 66.18%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 7745/10000, Train Loss: 0.6093, Train Acc: 64.45%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 7746/10000, Train Loss: 0.6233, Train Acc: 67.05%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 7747/10000, Train Loss: 0.6097, Train Acc: 65.90%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 7748/10000, Train Loss: 0.6031, Train Acc: 64.74%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 7749/10000, Train Loss: 0.6352, Train Acc: 62.14%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 7750/10000, Train Loss: 0.6138, Train Acc: 63.29%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7751/10000, Train Loss: 0.6151, Train Acc: 67.34%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 7752/10000, Train Loss: 0.6047, Train Acc: 64.16%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 7753/10000, Train Loss: 0.6127, Train Acc: 62.14%, Test Loss: 0.5510, Test Acc: 70.69%\n",
            "Epoch 7754/10000, Train Loss: 0.6200, Train Acc: 63.29%, Test Loss: 0.5495, Test Acc: 68.97%\n",
            "Epoch 7755/10000, Train Loss: 0.6082, Train Acc: 63.58%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 7756/10000, Train Loss: 0.6155, Train Acc: 65.90%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 7757/10000, Train Loss: 0.6048, Train Acc: 67.63%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7758/10000, Train Loss: 0.6150, Train Acc: 66.18%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 7759/10000, Train Loss: 0.6133, Train Acc: 61.56%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 7760/10000, Train Loss: 0.6468, Train Acc: 62.14%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 7761/10000, Train Loss: 0.6115, Train Acc: 65.90%, Test Loss: 0.5496, Test Acc: 72.41%\n",
            "Epoch 7762/10000, Train Loss: 0.6224, Train Acc: 62.72%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 7763/10000, Train Loss: 0.6285, Train Acc: 64.45%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 7764/10000, Train Loss: 0.6217, Train Acc: 64.45%, Test Loss: 0.5601, Test Acc: 72.41%\n",
            "Epoch 7765/10000, Train Loss: 0.6160, Train Acc: 65.61%, Test Loss: 0.5626, Test Acc: 68.97%\n",
            "Epoch 7766/10000, Train Loss: 0.6376, Train Acc: 64.74%, Test Loss: 0.5646, Test Acc: 68.97%\n",
            "Epoch 7767/10000, Train Loss: 0.6165, Train Acc: 63.87%, Test Loss: 0.5635, Test Acc: 68.97%\n",
            "Epoch 7768/10000, Train Loss: 0.6220, Train Acc: 66.18%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 7769/10000, Train Loss: 0.5937, Train Acc: 65.61%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 7770/10000, Train Loss: 0.5950, Train Acc: 66.76%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 7771/10000, Train Loss: 0.6034, Train Acc: 66.18%, Test Loss: 0.5521, Test Acc: 74.14%\n",
            "Epoch 7772/10000, Train Loss: 0.6225, Train Acc: 66.47%, Test Loss: 0.5522, Test Acc: 74.14%\n",
            "Epoch 7773/10000, Train Loss: 0.5808, Train Acc: 67.05%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 7774/10000, Train Loss: 0.6031, Train Acc: 65.03%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 7775/10000, Train Loss: 0.6142, Train Acc: 65.03%, Test Loss: 0.5587, Test Acc: 70.69%\n",
            "Epoch 7776/10000, Train Loss: 0.6008, Train Acc: 67.34%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 7777/10000, Train Loss: 0.6053, Train Acc: 65.90%, Test Loss: 0.5628, Test Acc: 68.97%\n",
            "Epoch 7778/10000, Train Loss: 0.6188, Train Acc: 66.47%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 7779/10000, Train Loss: 0.6060, Train Acc: 66.18%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 7780/10000, Train Loss: 0.6075, Train Acc: 68.21%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 7781/10000, Train Loss: 0.6145, Train Acc: 62.43%, Test Loss: 0.5563, Test Acc: 74.14%\n",
            "Epoch 7782/10000, Train Loss: 0.6041, Train Acc: 65.61%, Test Loss: 0.5551, Test Acc: 74.14%\n",
            "Epoch 7783/10000, Train Loss: 0.6284, Train Acc: 62.72%, Test Loss: 0.5557, Test Acc: 70.69%\n",
            "Epoch 7784/10000, Train Loss: 0.6262, Train Acc: 61.27%, Test Loss: 0.5517, Test Acc: 74.14%\n",
            "Epoch 7785/10000, Train Loss: 0.6145, Train Acc: 65.61%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 7786/10000, Train Loss: 0.6176, Train Acc: 63.29%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 7787/10000, Train Loss: 0.6333, Train Acc: 65.03%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 7788/10000, Train Loss: 0.6485, Train Acc: 61.56%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7789/10000, Train Loss: 0.6241, Train Acc: 65.61%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7790/10000, Train Loss: 0.6165, Train Acc: 64.74%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 7791/10000, Train Loss: 0.6080, Train Acc: 64.16%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 7792/10000, Train Loss: 0.6017, Train Acc: 65.61%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 7793/10000, Train Loss: 0.6212, Train Acc: 66.18%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 7794/10000, Train Loss: 0.6323, Train Acc: 63.58%, Test Loss: 0.5604, Test Acc: 72.41%\n",
            "Epoch 7795/10000, Train Loss: 0.6206, Train Acc: 63.87%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 7796/10000, Train Loss: 0.6047, Train Acc: 64.45%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 7797/10000, Train Loss: 0.5952, Train Acc: 66.18%, Test Loss: 0.5561, Test Acc: 70.69%\n",
            "Epoch 7798/10000, Train Loss: 0.6085, Train Acc: 66.18%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 7799/10000, Train Loss: 0.5984, Train Acc: 66.76%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 7800/10000, Train Loss: 0.6076, Train Acc: 65.03%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 7801/10000, Train Loss: 0.6081, Train Acc: 61.56%, Test Loss: 0.5576, Test Acc: 74.14%\n",
            "Epoch 7802/10000, Train Loss: 0.6080, Train Acc: 64.74%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 7803/10000, Train Loss: 0.6122, Train Acc: 66.76%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 7804/10000, Train Loss: 0.6358, Train Acc: 63.58%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 7805/10000, Train Loss: 0.5970, Train Acc: 64.45%, Test Loss: 0.5586, Test Acc: 68.97%\n",
            "Epoch 7806/10000, Train Loss: 0.6034, Train Acc: 68.79%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 7807/10000, Train Loss: 0.6111, Train Acc: 65.03%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 7808/10000, Train Loss: 0.6186, Train Acc: 63.87%, Test Loss: 0.5546, Test Acc: 74.14%\n",
            "Epoch 7809/10000, Train Loss: 0.6149, Train Acc: 63.58%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 7810/10000, Train Loss: 0.6278, Train Acc: 64.74%, Test Loss: 0.5575, Test Acc: 74.14%\n",
            "Epoch 7811/10000, Train Loss: 0.6256, Train Acc: 63.58%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 7812/10000, Train Loss: 0.6113, Train Acc: 67.34%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7813/10000, Train Loss: 0.6268, Train Acc: 63.01%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 7814/10000, Train Loss: 0.6340, Train Acc: 63.01%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 7815/10000, Train Loss: 0.5969, Train Acc: 67.34%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 7816/10000, Train Loss: 0.5911, Train Acc: 69.36%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 7817/10000, Train Loss: 0.6142, Train Acc: 65.03%, Test Loss: 0.5519, Test Acc: 74.14%\n",
            "Epoch 7818/10000, Train Loss: 0.6006, Train Acc: 65.90%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7819/10000, Train Loss: 0.6146, Train Acc: 65.03%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 7820/10000, Train Loss: 0.6250, Train Acc: 65.61%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 7821/10000, Train Loss: 0.6125, Train Acc: 63.58%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 7822/10000, Train Loss: 0.5976, Train Acc: 66.76%, Test Loss: 0.5516, Test Acc: 74.14%\n",
            "Epoch 7823/10000, Train Loss: 0.6117, Train Acc: 60.98%, Test Loss: 0.5502, Test Acc: 70.69%\n",
            "Epoch 7824/10000, Train Loss: 0.6124, Train Acc: 64.74%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 7825/10000, Train Loss: 0.6055, Train Acc: 65.90%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 7826/10000, Train Loss: 0.6002, Train Acc: 67.34%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 7827/10000, Train Loss: 0.6041, Train Acc: 64.16%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 7828/10000, Train Loss: 0.6051, Train Acc: 66.47%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 7829/10000, Train Loss: 0.6088, Train Acc: 63.58%, Test Loss: 0.5588, Test Acc: 70.69%\n",
            "Epoch 7830/10000, Train Loss: 0.6118, Train Acc: 64.16%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 7831/10000, Train Loss: 0.6009, Train Acc: 69.65%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 7832/10000, Train Loss: 0.6146, Train Acc: 65.32%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 7833/10000, Train Loss: 0.6010, Train Acc: 66.47%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 7834/10000, Train Loss: 0.5993, Train Acc: 66.76%, Test Loss: 0.5533, Test Acc: 74.14%\n",
            "Epoch 7835/10000, Train Loss: 0.6129, Train Acc: 65.61%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 7836/10000, Train Loss: 0.6352, Train Acc: 66.76%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 7837/10000, Train Loss: 0.6142, Train Acc: 65.90%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 7838/10000, Train Loss: 0.6234, Train Acc: 65.32%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 7839/10000, Train Loss: 0.6175, Train Acc: 64.16%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 7840/10000, Train Loss: 0.6313, Train Acc: 62.43%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 7841/10000, Train Loss: 0.6043, Train Acc: 65.61%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 7842/10000, Train Loss: 0.6093, Train Acc: 67.34%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 7843/10000, Train Loss: 0.6053, Train Acc: 65.90%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 7844/10000, Train Loss: 0.6157, Train Acc: 63.87%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 7845/10000, Train Loss: 0.6165, Train Acc: 65.61%, Test Loss: 0.5534, Test Acc: 74.14%\n",
            "Epoch 7846/10000, Train Loss: 0.6178, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 7847/10000, Train Loss: 0.6124, Train Acc: 65.90%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 7848/10000, Train Loss: 0.6244, Train Acc: 61.85%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 7849/10000, Train Loss: 0.6132, Train Acc: 64.45%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 7850/10000, Train Loss: 0.6047, Train Acc: 67.63%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 7851/10000, Train Loss: 0.5918, Train Acc: 66.47%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 7852/10000, Train Loss: 0.6349, Train Acc: 65.03%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 7853/10000, Train Loss: 0.6108, Train Acc: 66.47%, Test Loss: 0.5498, Test Acc: 72.41%\n",
            "Epoch 7854/10000, Train Loss: 0.6003, Train Acc: 66.76%, Test Loss: 0.5502, Test Acc: 72.41%\n",
            "Epoch 7855/10000, Train Loss: 0.6022, Train Acc: 66.47%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7856/10000, Train Loss: 0.6214, Train Acc: 62.72%, Test Loss: 0.5618, Test Acc: 68.97%\n",
            "Epoch 7857/10000, Train Loss: 0.5919, Train Acc: 65.61%, Test Loss: 0.5638, Test Acc: 70.69%\n",
            "Epoch 7858/10000, Train Loss: 0.6217, Train Acc: 62.72%, Test Loss: 0.5607, Test Acc: 68.97%\n",
            "Epoch 7859/10000, Train Loss: 0.6265, Train Acc: 63.87%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 7860/10000, Train Loss: 0.6146, Train Acc: 66.76%, Test Loss: 0.5490, Test Acc: 72.41%\n",
            "Epoch 7861/10000, Train Loss: 0.6168, Train Acc: 65.03%, Test Loss: 0.5521, Test Acc: 74.14%\n",
            "Epoch 7862/10000, Train Loss: 0.6068, Train Acc: 65.03%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 7863/10000, Train Loss: 0.6142, Train Acc: 65.32%, Test Loss: 0.5519, Test Acc: 74.14%\n",
            "Epoch 7864/10000, Train Loss: 0.6184, Train Acc: 63.01%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 7865/10000, Train Loss: 0.5987, Train Acc: 66.47%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 7866/10000, Train Loss: 0.5882, Train Acc: 67.63%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 7867/10000, Train Loss: 0.5909, Train Acc: 67.92%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 7868/10000, Train Loss: 0.5750, Train Acc: 67.34%, Test Loss: 0.5601, Test Acc: 70.69%\n",
            "Epoch 7869/10000, Train Loss: 0.6007, Train Acc: 69.65%, Test Loss: 0.5636, Test Acc: 68.97%\n",
            "Epoch 7870/10000, Train Loss: 0.6412, Train Acc: 60.98%, Test Loss: 0.5612, Test Acc: 68.97%\n",
            "Epoch 7871/10000, Train Loss: 0.6157, Train Acc: 62.43%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 7872/10000, Train Loss: 0.6057, Train Acc: 68.21%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 7873/10000, Train Loss: 0.5776, Train Acc: 70.81%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 7874/10000, Train Loss: 0.5917, Train Acc: 65.61%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 7875/10000, Train Loss: 0.6145, Train Acc: 61.27%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 7876/10000, Train Loss: 0.6272, Train Acc: 65.03%, Test Loss: 0.5532, Test Acc: 74.14%\n",
            "Epoch 7877/10000, Train Loss: 0.5864, Train Acc: 66.76%, Test Loss: 0.5497, Test Acc: 68.97%\n",
            "Epoch 7878/10000, Train Loss: 0.6090, Train Acc: 66.18%, Test Loss: 0.5486, Test Acc: 68.97%\n",
            "Epoch 7879/10000, Train Loss: 0.6122, Train Acc: 67.92%, Test Loss: 0.5521, Test Acc: 68.97%\n",
            "Epoch 7880/10000, Train Loss: 0.6272, Train Acc: 63.01%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 7881/10000, Train Loss: 0.5952, Train Acc: 69.65%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7882/10000, Train Loss: 0.6044, Train Acc: 65.03%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 7883/10000, Train Loss: 0.5987, Train Acc: 66.76%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 7884/10000, Train Loss: 0.5949, Train Acc: 65.61%, Test Loss: 0.5502, Test Acc: 72.41%\n",
            "Epoch 7885/10000, Train Loss: 0.6148, Train Acc: 65.90%, Test Loss: 0.5488, Test Acc: 68.97%\n",
            "Epoch 7886/10000, Train Loss: 0.5994, Train Acc: 65.32%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 7887/10000, Train Loss: 0.6307, Train Acc: 62.72%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 7888/10000, Train Loss: 0.6230, Train Acc: 64.16%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7889/10000, Train Loss: 0.6386, Train Acc: 62.14%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 7890/10000, Train Loss: 0.5971, Train Acc: 62.72%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 7891/10000, Train Loss: 0.5941, Train Acc: 66.76%, Test Loss: 0.5507, Test Acc: 72.41%\n",
            "Epoch 7892/10000, Train Loss: 0.6192, Train Acc: 66.18%, Test Loss: 0.5499, Test Acc: 70.69%\n",
            "Epoch 7893/10000, Train Loss: 0.6103, Train Acc: 64.45%, Test Loss: 0.5506, Test Acc: 68.97%\n",
            "Epoch 7894/10000, Train Loss: 0.6164, Train Acc: 62.43%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 7895/10000, Train Loss: 0.6167, Train Acc: 65.90%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 7896/10000, Train Loss: 0.6371, Train Acc: 63.87%, Test Loss: 0.5495, Test Acc: 72.41%\n",
            "Epoch 7897/10000, Train Loss: 0.6266, Train Acc: 65.90%, Test Loss: 0.5502, Test Acc: 70.69%\n",
            "Epoch 7898/10000, Train Loss: 0.5956, Train Acc: 64.45%, Test Loss: 0.5571, Test Acc: 70.69%\n",
            "Epoch 7899/10000, Train Loss: 0.6182, Train Acc: 66.18%, Test Loss: 0.5591, Test Acc: 70.69%\n",
            "Epoch 7900/10000, Train Loss: 0.5942, Train Acc: 67.05%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 7901/10000, Train Loss: 0.6004, Train Acc: 65.90%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 7902/10000, Train Loss: 0.5937, Train Acc: 64.74%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 7903/10000, Train Loss: 0.6002, Train Acc: 69.08%, Test Loss: 0.5552, Test Acc: 70.69%\n",
            "Epoch 7904/10000, Train Loss: 0.6181, Train Acc: 64.45%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 7905/10000, Train Loss: 0.6100, Train Acc: 65.61%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 7906/10000, Train Loss: 0.6251, Train Acc: 64.16%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 7907/10000, Train Loss: 0.6037, Train Acc: 65.61%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 7908/10000, Train Loss: 0.6197, Train Acc: 64.45%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 7909/10000, Train Loss: 0.6085, Train Acc: 65.90%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 7910/10000, Train Loss: 0.6040, Train Acc: 65.32%, Test Loss: 0.5556, Test Acc: 72.41%\n",
            "Epoch 7911/10000, Train Loss: 0.5991, Train Acc: 65.32%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 7912/10000, Train Loss: 0.6274, Train Acc: 65.90%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 7913/10000, Train Loss: 0.6219, Train Acc: 59.54%, Test Loss: 0.5496, Test Acc: 74.14%\n",
            "Epoch 7914/10000, Train Loss: 0.6201, Train Acc: 65.03%, Test Loss: 0.5487, Test Acc: 74.14%\n",
            "Epoch 7915/10000, Train Loss: 0.6048, Train Acc: 64.45%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 7916/10000, Train Loss: 0.6481, Train Acc: 63.01%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 7917/10000, Train Loss: 0.6155, Train Acc: 64.74%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 7918/10000, Train Loss: 0.6309, Train Acc: 65.61%, Test Loss: 0.5511, Test Acc: 68.97%\n",
            "Epoch 7919/10000, Train Loss: 0.6119, Train Acc: 65.90%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 7920/10000, Train Loss: 0.6148, Train Acc: 63.01%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 7921/10000, Train Loss: 0.6004, Train Acc: 66.76%, Test Loss: 0.5530, Test Acc: 70.69%\n",
            "Epoch 7922/10000, Train Loss: 0.6090, Train Acc: 64.45%, Test Loss: 0.5515, Test Acc: 72.41%\n",
            "Epoch 7923/10000, Train Loss: 0.6066, Train Acc: 66.76%, Test Loss: 0.5540, Test Acc: 74.14%\n",
            "Epoch 7924/10000, Train Loss: 0.6144, Train Acc: 64.16%, Test Loss: 0.5506, Test Acc: 72.41%\n",
            "Epoch 7925/10000, Train Loss: 0.6038, Train Acc: 65.90%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 7926/10000, Train Loss: 0.6233, Train Acc: 62.72%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 7927/10000, Train Loss: 0.6272, Train Acc: 63.58%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 7928/10000, Train Loss: 0.6284, Train Acc: 62.43%, Test Loss: 0.5532, Test Acc: 70.69%\n",
            "Epoch 7929/10000, Train Loss: 0.5954, Train Acc: 63.58%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 7930/10000, Train Loss: 0.6190, Train Acc: 63.29%, Test Loss: 0.5514, Test Acc: 74.14%\n",
            "Epoch 7931/10000, Train Loss: 0.5936, Train Acc: 68.21%, Test Loss: 0.5470, Test Acc: 72.41%\n",
            "Epoch 7932/10000, Train Loss: 0.6245, Train Acc: 62.43%, Test Loss: 0.5482, Test Acc: 68.97%\n",
            "Epoch 7933/10000, Train Loss: 0.6018, Train Acc: 67.63%, Test Loss: 0.5484, Test Acc: 68.97%\n",
            "Epoch 7934/10000, Train Loss: 0.6220, Train Acc: 64.74%, Test Loss: 0.5504, Test Acc: 68.97%\n",
            "Epoch 7935/10000, Train Loss: 0.6366, Train Acc: 66.18%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 7936/10000, Train Loss: 0.5939, Train Acc: 65.03%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 7937/10000, Train Loss: 0.6609, Train Acc: 62.43%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 7938/10000, Train Loss: 0.6245, Train Acc: 64.45%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 7939/10000, Train Loss: 0.6174, Train Acc: 65.61%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 7940/10000, Train Loss: 0.6121, Train Acc: 65.32%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 7941/10000, Train Loss: 0.6132, Train Acc: 62.72%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 7942/10000, Train Loss: 0.6140, Train Acc: 67.63%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 7943/10000, Train Loss: 0.6224, Train Acc: 65.90%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 7944/10000, Train Loss: 0.6345, Train Acc: 65.61%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 7945/10000, Train Loss: 0.6252, Train Acc: 64.16%, Test Loss: 0.5498, Test Acc: 75.86%\n",
            "Epoch 7946/10000, Train Loss: 0.6113, Train Acc: 65.32%, Test Loss: 0.5481, Test Acc: 72.41%\n",
            "Epoch 7947/10000, Train Loss: 0.6030, Train Acc: 63.58%, Test Loss: 0.5498, Test Acc: 72.41%\n",
            "Epoch 7948/10000, Train Loss: 0.6232, Train Acc: 63.29%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7949/10000, Train Loss: 0.6062, Train Acc: 67.63%, Test Loss: 0.5573, Test Acc: 72.41%\n",
            "Epoch 7950/10000, Train Loss: 0.6407, Train Acc: 62.72%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 7951/10000, Train Loss: 0.6022, Train Acc: 67.05%, Test Loss: 0.5590, Test Acc: 70.69%\n",
            "Epoch 7952/10000, Train Loss: 0.6051, Train Acc: 64.74%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 7953/10000, Train Loss: 0.6274, Train Acc: 62.72%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 7954/10000, Train Loss: 0.6182, Train Acc: 63.01%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 7955/10000, Train Loss: 0.6005, Train Acc: 64.16%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 7956/10000, Train Loss: 0.6140, Train Acc: 63.87%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 7957/10000, Train Loss: 0.6094, Train Acc: 64.74%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 7958/10000, Train Loss: 0.6130, Train Acc: 64.45%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 7959/10000, Train Loss: 0.6471, Train Acc: 62.43%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 7960/10000, Train Loss: 0.5838, Train Acc: 66.76%, Test Loss: 0.5512, Test Acc: 74.14%\n",
            "Epoch 7961/10000, Train Loss: 0.5963, Train Acc: 70.81%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 7962/10000, Train Loss: 0.6127, Train Acc: 65.61%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 7963/10000, Train Loss: 0.6289, Train Acc: 62.72%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7964/10000, Train Loss: 0.6387, Train Acc: 65.61%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 7965/10000, Train Loss: 0.6045, Train Acc: 64.74%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 7966/10000, Train Loss: 0.5992, Train Acc: 64.16%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 7967/10000, Train Loss: 0.6072, Train Acc: 65.90%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 7968/10000, Train Loss: 0.6401, Train Acc: 63.87%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 7969/10000, Train Loss: 0.6100, Train Acc: 65.61%, Test Loss: 0.5512, Test Acc: 72.41%\n",
            "Epoch 7970/10000, Train Loss: 0.5806, Train Acc: 67.63%, Test Loss: 0.5517, Test Acc: 74.14%\n",
            "Epoch 7971/10000, Train Loss: 0.6171, Train Acc: 61.85%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 7972/10000, Train Loss: 0.6272, Train Acc: 62.14%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 7973/10000, Train Loss: 0.5953, Train Acc: 65.61%, Test Loss: 0.5490, Test Acc: 74.14%\n",
            "Epoch 7974/10000, Train Loss: 0.5917, Train Acc: 68.50%, Test Loss: 0.5489, Test Acc: 72.41%\n",
            "Epoch 7975/10000, Train Loss: 0.6249, Train Acc: 64.16%, Test Loss: 0.5480, Test Acc: 68.97%\n",
            "Epoch 7976/10000, Train Loss: 0.6021, Train Acc: 66.18%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 7977/10000, Train Loss: 0.6140, Train Acc: 64.45%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 7978/10000, Train Loss: 0.6036, Train Acc: 64.45%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 7979/10000, Train Loss: 0.6264, Train Acc: 63.29%, Test Loss: 0.5510, Test Acc: 68.97%\n",
            "Epoch 7980/10000, Train Loss: 0.6330, Train Acc: 62.72%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 7981/10000, Train Loss: 0.6029, Train Acc: 67.05%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 7982/10000, Train Loss: 0.6105, Train Acc: 65.03%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 7983/10000, Train Loss: 0.6060, Train Acc: 66.18%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 7984/10000, Train Loss: 0.6107, Train Acc: 67.05%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 7985/10000, Train Loss: 0.6054, Train Acc: 67.92%, Test Loss: 0.5587, Test Acc: 72.41%\n",
            "Epoch 7986/10000, Train Loss: 0.5997, Train Acc: 67.34%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 7987/10000, Train Loss: 0.6201, Train Acc: 63.01%, Test Loss: 0.5537, Test Acc: 74.14%\n",
            "Epoch 7988/10000, Train Loss: 0.6326, Train Acc: 63.58%, Test Loss: 0.5494, Test Acc: 74.14%\n",
            "Epoch 7989/10000, Train Loss: 0.6108, Train Acc: 65.32%, Test Loss: 0.5492, Test Acc: 74.14%\n",
            "Epoch 7990/10000, Train Loss: 0.6081, Train Acc: 65.90%, Test Loss: 0.5486, Test Acc: 74.14%\n",
            "Epoch 7991/10000, Train Loss: 0.6012, Train Acc: 65.90%, Test Loss: 0.5504, Test Acc: 72.41%\n",
            "Epoch 7992/10000, Train Loss: 0.6100, Train Acc: 64.16%, Test Loss: 0.5505, Test Acc: 70.69%\n",
            "Epoch 7993/10000, Train Loss: 0.6352, Train Acc: 62.72%, Test Loss: 0.5487, Test Acc: 68.97%\n",
            "Epoch 7994/10000, Train Loss: 0.6307, Train Acc: 63.87%, Test Loss: 0.5459, Test Acc: 70.69%\n",
            "Epoch 7995/10000, Train Loss: 0.6041, Train Acc: 63.87%, Test Loss: 0.5508, Test Acc: 70.69%\n",
            "Epoch 7996/10000, Train Loss: 0.5939, Train Acc: 62.72%, Test Loss: 0.5630, Test Acc: 68.97%\n",
            "Epoch 7997/10000, Train Loss: 0.6280, Train Acc: 61.85%, Test Loss: 0.5691, Test Acc: 68.97%\n",
            "Epoch 7998/10000, Train Loss: 0.6023, Train Acc: 67.34%, Test Loss: 0.5651, Test Acc: 68.97%\n",
            "Epoch 7999/10000, Train Loss: 0.6189, Train Acc: 66.18%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 8000/10000, Train Loss: 0.6056, Train Acc: 63.58%, Test Loss: 0.5521, Test Acc: 74.14%\n",
            "Epoch 8001/10000, Train Loss: 0.6168, Train Acc: 65.61%, Test Loss: 0.5542, Test Acc: 74.14%\n",
            "Epoch 8002/10000, Train Loss: 0.6079, Train Acc: 67.05%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 8003/10000, Train Loss: 0.6289, Train Acc: 62.72%, Test Loss: 0.5528, Test Acc: 74.14%\n",
            "Epoch 8004/10000, Train Loss: 0.6226, Train Acc: 65.32%, Test Loss: 0.5537, Test Acc: 74.14%\n",
            "Epoch 8005/10000, Train Loss: 0.6071, Train Acc: 66.18%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 8006/10000, Train Loss: 0.6285, Train Acc: 62.14%, Test Loss: 0.5510, Test Acc: 70.69%\n",
            "Epoch 8007/10000, Train Loss: 0.6170, Train Acc: 64.74%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 8008/10000, Train Loss: 0.6071, Train Acc: 68.21%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 8009/10000, Train Loss: 0.6129, Train Acc: 63.87%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 8010/10000, Train Loss: 0.5893, Train Acc: 67.05%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 8011/10000, Train Loss: 0.6253, Train Acc: 65.61%, Test Loss: 0.5528, Test Acc: 70.69%\n",
            "Epoch 8012/10000, Train Loss: 0.6349, Train Acc: 65.61%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 8013/10000, Train Loss: 0.6271, Train Acc: 63.58%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 8014/10000, Train Loss: 0.6186, Train Acc: 63.58%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 8015/10000, Train Loss: 0.6117, Train Acc: 65.03%, Test Loss: 0.5622, Test Acc: 68.97%\n",
            "Epoch 8016/10000, Train Loss: 0.6095, Train Acc: 65.61%, Test Loss: 0.5602, Test Acc: 72.41%\n",
            "Epoch 8017/10000, Train Loss: 0.5998, Train Acc: 63.87%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 8018/10000, Train Loss: 0.6173, Train Acc: 65.90%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 8019/10000, Train Loss: 0.6031, Train Acc: 64.45%, Test Loss: 0.5582, Test Acc: 74.14%\n",
            "Epoch 8020/10000, Train Loss: 0.6275, Train Acc: 67.63%, Test Loss: 0.5551, Test Acc: 74.14%\n",
            "Epoch 8021/10000, Train Loss: 0.6379, Train Acc: 67.34%, Test Loss: 0.5550, Test Acc: 74.14%\n",
            "Epoch 8022/10000, Train Loss: 0.6005, Train Acc: 64.16%, Test Loss: 0.5561, Test Acc: 70.69%\n",
            "Epoch 8023/10000, Train Loss: 0.6091, Train Acc: 66.18%, Test Loss: 0.5561, Test Acc: 70.69%\n",
            "Epoch 8024/10000, Train Loss: 0.6046, Train Acc: 63.87%, Test Loss: 0.5580, Test Acc: 70.69%\n",
            "Epoch 8025/10000, Train Loss: 0.6299, Train Acc: 65.32%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 8026/10000, Train Loss: 0.5931, Train Acc: 66.76%, Test Loss: 0.5544, Test Acc: 74.14%\n",
            "Epoch 8027/10000, Train Loss: 0.6083, Train Acc: 65.32%, Test Loss: 0.5523, Test Acc: 72.41%\n",
            "Epoch 8028/10000, Train Loss: 0.6043, Train Acc: 65.90%, Test Loss: 0.5524, Test Acc: 74.14%\n",
            "Epoch 8029/10000, Train Loss: 0.6144, Train Acc: 67.34%, Test Loss: 0.5542, Test Acc: 74.14%\n",
            "Epoch 8030/10000, Train Loss: 0.6143, Train Acc: 65.61%, Test Loss: 0.5524, Test Acc: 74.14%\n",
            "Epoch 8031/10000, Train Loss: 0.5994, Train Acc: 65.32%, Test Loss: 0.5522, Test Acc: 74.14%\n",
            "Epoch 8032/10000, Train Loss: 0.6093, Train Acc: 64.74%, Test Loss: 0.5532, Test Acc: 74.14%\n",
            "Epoch 8033/10000, Train Loss: 0.6515, Train Acc: 59.54%, Test Loss: 0.5519, Test Acc: 74.14%\n",
            "Epoch 8034/10000, Train Loss: 0.6373, Train Acc: 64.74%, Test Loss: 0.5497, Test Acc: 75.86%\n",
            "Epoch 8035/10000, Train Loss: 0.6178, Train Acc: 63.58%, Test Loss: 0.5521, Test Acc: 72.41%\n",
            "Epoch 8036/10000, Train Loss: 0.6295, Train Acc: 61.85%, Test Loss: 0.5498, Test Acc: 68.97%\n",
            "Epoch 8037/10000, Train Loss: 0.6098, Train Acc: 67.92%, Test Loss: 0.5496, Test Acc: 68.97%\n",
            "Epoch 8038/10000, Train Loss: 0.6018, Train Acc: 67.05%, Test Loss: 0.5511, Test Acc: 68.97%\n",
            "Epoch 8039/10000, Train Loss: 0.5945, Train Acc: 64.74%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 8040/10000, Train Loss: 0.6125, Train Acc: 63.01%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 8041/10000, Train Loss: 0.6189, Train Acc: 59.25%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 8042/10000, Train Loss: 0.5966, Train Acc: 67.05%, Test Loss: 0.5519, Test Acc: 70.69%\n",
            "Epoch 8043/10000, Train Loss: 0.5983, Train Acc: 63.01%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 8044/10000, Train Loss: 0.6063, Train Acc: 67.63%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 8045/10000, Train Loss: 0.6121, Train Acc: 63.87%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 8046/10000, Train Loss: 0.6126, Train Acc: 61.85%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 8047/10000, Train Loss: 0.6085, Train Acc: 67.34%, Test Loss: 0.5579, Test Acc: 72.41%\n",
            "Epoch 8048/10000, Train Loss: 0.6198, Train Acc: 64.45%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8049/10000, Train Loss: 0.6173, Train Acc: 65.03%, Test Loss: 0.5551, Test Acc: 70.69%\n",
            "Epoch 8050/10000, Train Loss: 0.5935, Train Acc: 63.87%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 8051/10000, Train Loss: 0.6005, Train Acc: 67.05%, Test Loss: 0.5587, Test Acc: 72.41%\n",
            "Epoch 8052/10000, Train Loss: 0.6348, Train Acc: 64.45%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 8053/10000, Train Loss: 0.6182, Train Acc: 65.03%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 8054/10000, Train Loss: 0.6236, Train Acc: 61.85%, Test Loss: 0.5541, Test Acc: 74.14%\n",
            "Epoch 8055/10000, Train Loss: 0.6273, Train Acc: 65.32%, Test Loss: 0.5496, Test Acc: 74.14%\n",
            "Epoch 8056/10000, Train Loss: 0.6206, Train Acc: 64.74%, Test Loss: 0.5505, Test Acc: 74.14%\n",
            "Epoch 8057/10000, Train Loss: 0.6032, Train Acc: 65.61%, Test Loss: 0.5490, Test Acc: 74.14%\n",
            "Epoch 8058/10000, Train Loss: 0.6085, Train Acc: 64.16%, Test Loss: 0.5478, Test Acc: 72.41%\n",
            "Epoch 8059/10000, Train Loss: 0.6208, Train Acc: 61.85%, Test Loss: 0.5473, Test Acc: 70.69%\n",
            "Epoch 8060/10000, Train Loss: 0.5906, Train Acc: 70.23%, Test Loss: 0.5492, Test Acc: 70.69%\n",
            "Epoch 8061/10000, Train Loss: 0.6205, Train Acc: 66.18%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 8062/10000, Train Loss: 0.6042, Train Acc: 63.01%, Test Loss: 0.5510, Test Acc: 72.41%\n",
            "Epoch 8063/10000, Train Loss: 0.6193, Train Acc: 64.16%, Test Loss: 0.5487, Test Acc: 72.41%\n",
            "Epoch 8064/10000, Train Loss: 0.6026, Train Acc: 66.18%, Test Loss: 0.5463, Test Acc: 70.69%\n",
            "Epoch 8065/10000, Train Loss: 0.6059, Train Acc: 66.76%, Test Loss: 0.5488, Test Acc: 72.41%\n",
            "Epoch 8066/10000, Train Loss: 0.6253, Train Acc: 65.32%, Test Loss: 0.5478, Test Acc: 68.97%\n",
            "Epoch 8067/10000, Train Loss: 0.6101, Train Acc: 65.03%, Test Loss: 0.5494, Test Acc: 68.97%\n",
            "Epoch 8068/10000, Train Loss: 0.6262, Train Acc: 64.45%, Test Loss: 0.5506, Test Acc: 68.97%\n",
            "Epoch 8069/10000, Train Loss: 0.6000, Train Acc: 64.74%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 8070/10000, Train Loss: 0.6283, Train Acc: 63.29%, Test Loss: 0.5495, Test Acc: 72.41%\n",
            "Epoch 8071/10000, Train Loss: 0.5965, Train Acc: 67.34%, Test Loss: 0.5491, Test Acc: 72.41%\n",
            "Epoch 8072/10000, Train Loss: 0.6097, Train Acc: 67.63%, Test Loss: 0.5496, Test Acc: 70.69%\n",
            "Epoch 8073/10000, Train Loss: 0.6346, Train Acc: 61.85%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 8074/10000, Train Loss: 0.6054, Train Acc: 65.32%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 8075/10000, Train Loss: 0.5979, Train Acc: 66.18%, Test Loss: 0.5529, Test Acc: 74.14%\n",
            "Epoch 8076/10000, Train Loss: 0.6287, Train Acc: 62.72%, Test Loss: 0.5489, Test Acc: 72.41%\n",
            "Epoch 8077/10000, Train Loss: 0.6147, Train Acc: 65.61%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 8078/10000, Train Loss: 0.6322, Train Acc: 63.58%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 8079/10000, Train Loss: 0.6079, Train Acc: 66.18%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 8080/10000, Train Loss: 0.6147, Train Acc: 66.47%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 8081/10000, Train Loss: 0.6071, Train Acc: 64.16%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 8082/10000, Train Loss: 0.6079, Train Acc: 62.72%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 8083/10000, Train Loss: 0.6241, Train Acc: 65.90%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 8084/10000, Train Loss: 0.6071, Train Acc: 67.34%, Test Loss: 0.5552, Test Acc: 70.69%\n",
            "Epoch 8085/10000, Train Loss: 0.6156, Train Acc: 65.03%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 8086/10000, Train Loss: 0.6031, Train Acc: 64.16%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 8087/10000, Train Loss: 0.5915, Train Acc: 66.18%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 8088/10000, Train Loss: 0.6135, Train Acc: 62.72%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 8089/10000, Train Loss: 0.6309, Train Acc: 65.61%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 8090/10000, Train Loss: 0.6283, Train Acc: 64.16%, Test Loss: 0.5537, Test Acc: 74.14%\n",
            "Epoch 8091/10000, Train Loss: 0.6153, Train Acc: 63.87%, Test Loss: 0.5534, Test Acc: 74.14%\n",
            "Epoch 8092/10000, Train Loss: 0.6179, Train Acc: 61.27%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 8093/10000, Train Loss: 0.6125, Train Acc: 62.14%, Test Loss: 0.5521, Test Acc: 68.97%\n",
            "Epoch 8094/10000, Train Loss: 0.5957, Train Acc: 66.76%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 8095/10000, Train Loss: 0.6080, Train Acc: 65.03%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 8096/10000, Train Loss: 0.6059, Train Acc: 67.05%, Test Loss: 0.5556, Test Acc: 70.69%\n",
            "Epoch 8097/10000, Train Loss: 0.6168, Train Acc: 63.29%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 8098/10000, Train Loss: 0.6211, Train Acc: 64.74%, Test Loss: 0.5528, Test Acc: 70.69%\n",
            "Epoch 8099/10000, Train Loss: 0.6101, Train Acc: 63.87%, Test Loss: 0.5566, Test Acc: 70.69%\n",
            "Epoch 8100/10000, Train Loss: 0.6031, Train Acc: 65.90%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 8101/10000, Train Loss: 0.6062, Train Acc: 67.92%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 8102/10000, Train Loss: 0.6175, Train Acc: 65.61%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 8103/10000, Train Loss: 0.6100, Train Acc: 65.32%, Test Loss: 0.5514, Test Acc: 72.41%\n",
            "Epoch 8104/10000, Train Loss: 0.6113, Train Acc: 67.05%, Test Loss: 0.5514, Test Acc: 74.14%\n",
            "Epoch 8105/10000, Train Loss: 0.6132, Train Acc: 64.74%, Test Loss: 0.5502, Test Acc: 72.41%\n",
            "Epoch 8106/10000, Train Loss: 0.6074, Train Acc: 64.16%, Test Loss: 0.5485, Test Acc: 68.97%\n",
            "Epoch 8107/10000, Train Loss: 0.6230, Train Acc: 66.47%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 8108/10000, Train Loss: 0.6215, Train Acc: 65.61%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 8109/10000, Train Loss: 0.6086, Train Acc: 64.45%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 8110/10000, Train Loss: 0.6322, Train Acc: 65.03%, Test Loss: 0.5600, Test Acc: 70.69%\n",
            "Epoch 8111/10000, Train Loss: 0.6036, Train Acc: 67.63%, Test Loss: 0.5666, Test Acc: 68.97%\n",
            "Epoch 8112/10000, Train Loss: 0.6029, Train Acc: 67.63%, Test Loss: 0.5637, Test Acc: 68.97%\n",
            "Epoch 8113/10000, Train Loss: 0.5980, Train Acc: 64.74%, Test Loss: 0.5619, Test Acc: 70.69%\n",
            "Epoch 8114/10000, Train Loss: 0.6101, Train Acc: 65.90%, Test Loss: 0.5580, Test Acc: 70.69%\n",
            "Epoch 8115/10000, Train Loss: 0.5989, Train Acc: 68.50%, Test Loss: 0.5586, Test Acc: 70.69%\n",
            "Epoch 8116/10000, Train Loss: 0.6111, Train Acc: 62.72%, Test Loss: 0.5517, Test Acc: 74.14%\n",
            "Epoch 8117/10000, Train Loss: 0.6129, Train Acc: 69.08%, Test Loss: 0.5558, Test Acc: 74.14%\n",
            "Epoch 8118/10000, Train Loss: 0.5999, Train Acc: 64.74%, Test Loss: 0.5590, Test Acc: 74.14%\n",
            "Epoch 8119/10000, Train Loss: 0.5931, Train Acc: 66.76%, Test Loss: 0.5561, Test Acc: 75.86%\n",
            "Epoch 8120/10000, Train Loss: 0.6020, Train Acc: 68.79%, Test Loss: 0.5531, Test Acc: 75.86%\n",
            "Epoch 8121/10000, Train Loss: 0.6168, Train Acc: 62.72%, Test Loss: 0.5485, Test Acc: 72.41%\n",
            "Epoch 8122/10000, Train Loss: 0.6359, Train Acc: 61.85%, Test Loss: 0.5494, Test Acc: 68.97%\n",
            "Epoch 8123/10000, Train Loss: 0.6153, Train Acc: 62.72%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 8124/10000, Train Loss: 0.6195, Train Acc: 65.03%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 8125/10000, Train Loss: 0.6185, Train Acc: 64.45%, Test Loss: 0.5512, Test Acc: 70.69%\n",
            "Epoch 8126/10000, Train Loss: 0.6048, Train Acc: 63.58%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 8127/10000, Train Loss: 0.6085, Train Acc: 63.87%, Test Loss: 0.5640, Test Acc: 68.97%\n",
            "Epoch 8128/10000, Train Loss: 0.6009, Train Acc: 64.16%, Test Loss: 0.5697, Test Acc: 70.69%\n",
            "Epoch 8129/10000, Train Loss: 0.6565, Train Acc: 65.03%, Test Loss: 0.5725, Test Acc: 67.24%\n",
            "Epoch 8130/10000, Train Loss: 0.6088, Train Acc: 65.90%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 8131/10000, Train Loss: 0.6108, Train Acc: 65.32%, Test Loss: 0.5531, Test Acc: 74.14%\n",
            "Epoch 8132/10000, Train Loss: 0.6242, Train Acc: 61.85%, Test Loss: 0.5506, Test Acc: 72.41%\n",
            "Epoch 8133/10000, Train Loss: 0.6106, Train Acc: 67.63%, Test Loss: 0.5471, Test Acc: 74.14%\n",
            "Epoch 8134/10000, Train Loss: 0.5969, Train Acc: 64.74%, Test Loss: 0.5470, Test Acc: 72.41%\n",
            "Epoch 8135/10000, Train Loss: 0.6354, Train Acc: 62.72%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 8136/10000, Train Loss: 0.6432, Train Acc: 65.61%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 8137/10000, Train Loss: 0.5938, Train Acc: 67.34%, Test Loss: 0.5509, Test Acc: 70.69%\n",
            "Epoch 8138/10000, Train Loss: 0.6084, Train Acc: 65.90%, Test Loss: 0.5502, Test Acc: 70.69%\n",
            "Epoch 8139/10000, Train Loss: 0.6374, Train Acc: 64.16%, Test Loss: 0.5514, Test Acc: 70.69%\n",
            "Epoch 8140/10000, Train Loss: 0.6267, Train Acc: 64.16%, Test Loss: 0.5600, Test Acc: 68.97%\n",
            "Epoch 8141/10000, Train Loss: 0.6263, Train Acc: 65.61%, Test Loss: 0.5581, Test Acc: 70.69%\n",
            "Epoch 8142/10000, Train Loss: 0.6061, Train Acc: 66.76%, Test Loss: 0.5519, Test Acc: 70.69%\n",
            "Epoch 8143/10000, Train Loss: 0.5921, Train Acc: 65.03%, Test Loss: 0.5484, Test Acc: 72.41%\n",
            "Epoch 8144/10000, Train Loss: 0.5867, Train Acc: 67.05%, Test Loss: 0.5491, Test Acc: 72.41%\n",
            "Epoch 8145/10000, Train Loss: 0.6340, Train Acc: 63.58%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 8146/10000, Train Loss: 0.6013, Train Acc: 69.08%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 8147/10000, Train Loss: 0.6018, Train Acc: 69.65%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 8148/10000, Train Loss: 0.6039, Train Acc: 61.85%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 8149/10000, Train Loss: 0.5847, Train Acc: 67.34%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 8150/10000, Train Loss: 0.6174, Train Acc: 67.34%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 8151/10000, Train Loss: 0.6086, Train Acc: 67.63%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8152/10000, Train Loss: 0.6209, Train Acc: 62.72%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 8153/10000, Train Loss: 0.6074, Train Acc: 67.05%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 8154/10000, Train Loss: 0.6160, Train Acc: 64.45%, Test Loss: 0.5491, Test Acc: 72.41%\n",
            "Epoch 8155/10000, Train Loss: 0.6382, Train Acc: 64.16%, Test Loss: 0.5472, Test Acc: 72.41%\n",
            "Epoch 8156/10000, Train Loss: 0.6012, Train Acc: 66.47%, Test Loss: 0.5496, Test Acc: 68.97%\n",
            "Epoch 8157/10000, Train Loss: 0.6012, Train Acc: 67.34%, Test Loss: 0.5512, Test Acc: 72.41%\n",
            "Epoch 8158/10000, Train Loss: 0.6285, Train Acc: 63.29%, Test Loss: 0.5492, Test Acc: 72.41%\n",
            "Epoch 8159/10000, Train Loss: 0.5983, Train Acc: 65.03%, Test Loss: 0.5491, Test Acc: 72.41%\n",
            "Epoch 8160/10000, Train Loss: 0.6090, Train Acc: 67.05%, Test Loss: 0.5453, Test Acc: 72.41%\n",
            "Epoch 8161/10000, Train Loss: 0.6097, Train Acc: 65.32%, Test Loss: 0.5461, Test Acc: 72.41%\n",
            "Epoch 8162/10000, Train Loss: 0.6240, Train Acc: 63.58%, Test Loss: 0.5473, Test Acc: 72.41%\n",
            "Epoch 8163/10000, Train Loss: 0.6125, Train Acc: 64.16%, Test Loss: 0.5504, Test Acc: 68.97%\n",
            "Epoch 8164/10000, Train Loss: 0.6186, Train Acc: 64.16%, Test Loss: 0.5525, Test Acc: 70.69%\n",
            "Epoch 8165/10000, Train Loss: 0.6208, Train Acc: 66.18%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 8166/10000, Train Loss: 0.6162, Train Acc: 64.74%, Test Loss: 0.5526, Test Acc: 70.69%\n",
            "Epoch 8167/10000, Train Loss: 0.5915, Train Acc: 67.34%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 8168/10000, Train Loss: 0.6153, Train Acc: 67.05%, Test Loss: 0.5542, Test Acc: 70.69%\n",
            "Epoch 8169/10000, Train Loss: 0.5922, Train Acc: 65.03%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 8170/10000, Train Loss: 0.6133, Train Acc: 66.76%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 8171/10000, Train Loss: 0.5906, Train Acc: 67.05%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 8172/10000, Train Loss: 0.6300, Train Acc: 61.27%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 8173/10000, Train Loss: 0.6003, Train Acc: 63.58%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 8174/10000, Train Loss: 0.6051, Train Acc: 65.61%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 8175/10000, Train Loss: 0.6204, Train Acc: 61.85%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 8176/10000, Train Loss: 0.6103, Train Acc: 66.18%, Test Loss: 0.5489, Test Acc: 70.69%\n",
            "Epoch 8177/10000, Train Loss: 0.6087, Train Acc: 65.90%, Test Loss: 0.5487, Test Acc: 68.97%\n",
            "Epoch 8178/10000, Train Loss: 0.6107, Train Acc: 63.58%, Test Loss: 0.5520, Test Acc: 70.69%\n",
            "Epoch 8179/10000, Train Loss: 0.6064, Train Acc: 65.61%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 8180/10000, Train Loss: 0.6186, Train Acc: 63.87%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 8181/10000, Train Loss: 0.6021, Train Acc: 66.76%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 8182/10000, Train Loss: 0.5901, Train Acc: 67.34%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 8183/10000, Train Loss: 0.6404, Train Acc: 66.47%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 8184/10000, Train Loss: 0.6232, Train Acc: 67.05%, Test Loss: 0.5548, Test Acc: 74.14%\n",
            "Epoch 8185/10000, Train Loss: 0.6020, Train Acc: 65.61%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 8186/10000, Train Loss: 0.5962, Train Acc: 67.34%, Test Loss: 0.5502, Test Acc: 74.14%\n",
            "Epoch 8187/10000, Train Loss: 0.6177, Train Acc: 65.61%, Test Loss: 0.5497, Test Acc: 74.14%\n",
            "Epoch 8188/10000, Train Loss: 0.6101, Train Acc: 64.45%, Test Loss: 0.5513, Test Acc: 72.41%\n",
            "Epoch 8189/10000, Train Loss: 0.6245, Train Acc: 65.90%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 8190/10000, Train Loss: 0.6075, Train Acc: 62.14%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 8191/10000, Train Loss: 0.6361, Train Acc: 61.27%, Test Loss: 0.5500, Test Acc: 70.69%\n",
            "Epoch 8192/10000, Train Loss: 0.6277, Train Acc: 67.34%, Test Loss: 0.5504, Test Acc: 68.97%\n",
            "Epoch 8193/10000, Train Loss: 0.6154, Train Acc: 65.03%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 8194/10000, Train Loss: 0.6284, Train Acc: 63.01%, Test Loss: 0.5603, Test Acc: 70.69%\n",
            "Epoch 8195/10000, Train Loss: 0.6111, Train Acc: 64.16%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 8196/10000, Train Loss: 0.6063, Train Acc: 63.87%, Test Loss: 0.5510, Test Acc: 72.41%\n",
            "Epoch 8197/10000, Train Loss: 0.6460, Train Acc: 64.74%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 8198/10000, Train Loss: 0.6275, Train Acc: 64.16%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 8199/10000, Train Loss: 0.6198, Train Acc: 65.03%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8200/10000, Train Loss: 0.5954, Train Acc: 66.18%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8201/10000, Train Loss: 0.5830, Train Acc: 65.90%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 8202/10000, Train Loss: 0.6153, Train Acc: 63.01%, Test Loss: 0.5560, Test Acc: 70.69%\n",
            "Epoch 8203/10000, Train Loss: 0.6145, Train Acc: 63.87%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 8204/10000, Train Loss: 0.6087, Train Acc: 62.72%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 8205/10000, Train Loss: 0.5920, Train Acc: 65.03%, Test Loss: 0.5532, Test Acc: 70.69%\n",
            "Epoch 8206/10000, Train Loss: 0.5960, Train Acc: 66.47%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 8207/10000, Train Loss: 0.6095, Train Acc: 65.32%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 8208/10000, Train Loss: 0.6321, Train Acc: 66.18%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 8209/10000, Train Loss: 0.6270, Train Acc: 63.58%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 8210/10000, Train Loss: 0.5989, Train Acc: 66.76%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 8211/10000, Train Loss: 0.6124, Train Acc: 63.58%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 8212/10000, Train Loss: 0.6075, Train Acc: 64.16%, Test Loss: 0.5598, Test Acc: 70.69%\n",
            "Epoch 8213/10000, Train Loss: 0.5815, Train Acc: 65.90%, Test Loss: 0.5548, Test Acc: 74.14%\n",
            "Epoch 8214/10000, Train Loss: 0.6021, Train Acc: 65.03%, Test Loss: 0.5513, Test Acc: 72.41%\n",
            "Epoch 8215/10000, Train Loss: 0.6229, Train Acc: 63.58%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 8216/10000, Train Loss: 0.6092, Train Acc: 68.21%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 8217/10000, Train Loss: 0.6208, Train Acc: 65.03%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 8218/10000, Train Loss: 0.6488, Train Acc: 62.14%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 8219/10000, Train Loss: 0.5860, Train Acc: 64.74%, Test Loss: 0.5521, Test Acc: 72.41%\n",
            "Epoch 8220/10000, Train Loss: 0.6121, Train Acc: 63.29%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 8221/10000, Train Loss: 0.6198, Train Acc: 64.16%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 8222/10000, Train Loss: 0.6004, Train Acc: 67.63%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 8223/10000, Train Loss: 0.6276, Train Acc: 63.58%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 8224/10000, Train Loss: 0.6264, Train Acc: 63.58%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 8225/10000, Train Loss: 0.6030, Train Acc: 63.87%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 8226/10000, Train Loss: 0.5964, Train Acc: 65.32%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 8227/10000, Train Loss: 0.6046, Train Acc: 64.16%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 8228/10000, Train Loss: 0.6119, Train Acc: 61.27%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 8229/10000, Train Loss: 0.5992, Train Acc: 65.03%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 8230/10000, Train Loss: 0.6069, Train Acc: 66.47%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 8231/10000, Train Loss: 0.6209, Train Acc: 64.16%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 8232/10000, Train Loss: 0.5945, Train Acc: 67.92%, Test Loss: 0.5587, Test Acc: 70.69%\n",
            "Epoch 8233/10000, Train Loss: 0.5884, Train Acc: 65.61%, Test Loss: 0.5585, Test Acc: 70.69%\n",
            "Epoch 8234/10000, Train Loss: 0.5938, Train Acc: 69.94%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 8235/10000, Train Loss: 0.6108, Train Acc: 64.16%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 8236/10000, Train Loss: 0.5967, Train Acc: 67.34%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 8237/10000, Train Loss: 0.5965, Train Acc: 65.90%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 8238/10000, Train Loss: 0.6143, Train Acc: 65.03%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 8239/10000, Train Loss: 0.6150, Train Acc: 64.74%, Test Loss: 0.5617, Test Acc: 70.69%\n",
            "Epoch 8240/10000, Train Loss: 0.6169, Train Acc: 60.98%, Test Loss: 0.5656, Test Acc: 68.97%\n",
            "Epoch 8241/10000, Train Loss: 0.6124, Train Acc: 63.58%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 8242/10000, Train Loss: 0.6126, Train Acc: 62.72%, Test Loss: 0.5520, Test Acc: 74.14%\n",
            "Epoch 8243/10000, Train Loss: 0.6273, Train Acc: 59.54%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 8244/10000, Train Loss: 0.6070, Train Acc: 64.45%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 8245/10000, Train Loss: 0.6066, Train Acc: 63.29%, Test Loss: 0.5523, Test Acc: 74.14%\n",
            "Epoch 8246/10000, Train Loss: 0.6136, Train Acc: 65.32%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 8247/10000, Train Loss: 0.5991, Train Acc: 65.03%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 8248/10000, Train Loss: 0.6042, Train Acc: 63.87%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 8249/10000, Train Loss: 0.6232, Train Acc: 62.43%, Test Loss: 0.5494, Test Acc: 72.41%\n",
            "Epoch 8250/10000, Train Loss: 0.6001, Train Acc: 65.03%, Test Loss: 0.5475, Test Acc: 72.41%\n",
            "Epoch 8251/10000, Train Loss: 0.6075, Train Acc: 67.05%, Test Loss: 0.5462, Test Acc: 70.69%\n",
            "Epoch 8252/10000, Train Loss: 0.6088, Train Acc: 65.32%, Test Loss: 0.5508, Test Acc: 70.69%\n",
            "Epoch 8253/10000, Train Loss: 0.6096, Train Acc: 67.92%, Test Loss: 0.5510, Test Acc: 68.97%\n",
            "Epoch 8254/10000, Train Loss: 0.6231, Train Acc: 62.72%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 8255/10000, Train Loss: 0.6122, Train Acc: 65.32%, Test Loss: 0.5512, Test Acc: 70.69%\n",
            "Epoch 8256/10000, Train Loss: 0.6324, Train Acc: 65.61%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 8257/10000, Train Loss: 0.6166, Train Acc: 62.43%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 8258/10000, Train Loss: 0.5979, Train Acc: 66.47%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 8259/10000, Train Loss: 0.6154, Train Acc: 62.14%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 8260/10000, Train Loss: 0.6102, Train Acc: 65.32%, Test Loss: 0.5523, Test Acc: 68.97%\n",
            "Epoch 8261/10000, Train Loss: 0.6105, Train Acc: 63.58%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 8262/10000, Train Loss: 0.6119, Train Acc: 66.47%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 8263/10000, Train Loss: 0.6045, Train Acc: 65.61%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 8264/10000, Train Loss: 0.5970, Train Acc: 66.18%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 8265/10000, Train Loss: 0.5990, Train Acc: 63.87%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 8266/10000, Train Loss: 0.6219, Train Acc: 63.58%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 8267/10000, Train Loss: 0.6098, Train Acc: 64.16%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 8268/10000, Train Loss: 0.6196, Train Acc: 65.03%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 8269/10000, Train Loss: 0.5892, Train Acc: 65.61%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 8270/10000, Train Loss: 0.6279, Train Acc: 62.72%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 8271/10000, Train Loss: 0.6183, Train Acc: 65.61%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8272/10000, Train Loss: 0.6198, Train Acc: 65.03%, Test Loss: 0.5523, Test Acc: 72.41%\n",
            "Epoch 8273/10000, Train Loss: 0.6051, Train Acc: 67.34%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 8274/10000, Train Loss: 0.6304, Train Acc: 63.29%, Test Loss: 0.5514, Test Acc: 74.14%\n",
            "Epoch 8275/10000, Train Loss: 0.5895, Train Acc: 66.18%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 8276/10000, Train Loss: 0.6298, Train Acc: 64.45%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 8277/10000, Train Loss: 0.6416, Train Acc: 66.47%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 8278/10000, Train Loss: 0.6082, Train Acc: 63.58%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 8279/10000, Train Loss: 0.6237, Train Acc: 65.03%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 8280/10000, Train Loss: 0.5990, Train Acc: 63.01%, Test Loss: 0.5513, Test Acc: 72.41%\n",
            "Epoch 8281/10000, Train Loss: 0.6124, Train Acc: 64.74%, Test Loss: 0.5511, Test Acc: 72.41%\n",
            "Epoch 8282/10000, Train Loss: 0.6050, Train Acc: 66.76%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 8283/10000, Train Loss: 0.5891, Train Acc: 63.58%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 8284/10000, Train Loss: 0.6080, Train Acc: 66.18%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 8285/10000, Train Loss: 0.6154, Train Acc: 65.32%, Test Loss: 0.5556, Test Acc: 70.69%\n",
            "Epoch 8286/10000, Train Loss: 0.6209, Train Acc: 66.76%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 8287/10000, Train Loss: 0.6230, Train Acc: 62.72%, Test Loss: 0.5526, Test Acc: 74.14%\n",
            "Epoch 8288/10000, Train Loss: 0.6334, Train Acc: 66.76%, Test Loss: 0.5534, Test Acc: 75.86%\n",
            "Epoch 8289/10000, Train Loss: 0.6277, Train Acc: 63.29%, Test Loss: 0.5506, Test Acc: 75.86%\n",
            "Epoch 8290/10000, Train Loss: 0.6066, Train Acc: 63.29%, Test Loss: 0.5437, Test Acc: 70.69%\n",
            "Epoch 8291/10000, Train Loss: 0.6316, Train Acc: 65.03%, Test Loss: 0.5443, Test Acc: 70.69%\n",
            "Epoch 8292/10000, Train Loss: 0.6180, Train Acc: 64.45%, Test Loss: 0.5513, Test Acc: 70.69%\n",
            "Epoch 8293/10000, Train Loss: 0.6275, Train Acc: 65.03%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 8294/10000, Train Loss: 0.6112, Train Acc: 62.43%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 8295/10000, Train Loss: 0.6069, Train Acc: 64.16%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 8296/10000, Train Loss: 0.6133, Train Acc: 67.05%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 8297/10000, Train Loss: 0.6010, Train Acc: 64.45%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 8298/10000, Train Loss: 0.5926, Train Acc: 66.18%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 8299/10000, Train Loss: 0.6096, Train Acc: 65.90%, Test Loss: 0.5521, Test Acc: 68.97%\n",
            "Epoch 8300/10000, Train Loss: 0.6068, Train Acc: 63.87%, Test Loss: 0.5484, Test Acc: 68.97%\n",
            "Epoch 8301/10000, Train Loss: 0.6339, Train Acc: 65.32%, Test Loss: 0.5511, Test Acc: 70.69%\n",
            "Epoch 8302/10000, Train Loss: 0.6037, Train Acc: 65.61%, Test Loss: 0.5586, Test Acc: 68.97%\n",
            "Epoch 8303/10000, Train Loss: 0.6116, Train Acc: 64.16%, Test Loss: 0.5612, Test Acc: 68.97%\n",
            "Epoch 8304/10000, Train Loss: 0.6048, Train Acc: 69.08%, Test Loss: 0.5590, Test Acc: 68.97%\n",
            "Epoch 8305/10000, Train Loss: 0.6218, Train Acc: 63.87%, Test Loss: 0.5622, Test Acc: 70.69%\n",
            "Epoch 8306/10000, Train Loss: 0.6263, Train Acc: 65.90%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 8307/10000, Train Loss: 0.6199, Train Acc: 62.72%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 8308/10000, Train Loss: 0.6179, Train Acc: 67.34%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 8309/10000, Train Loss: 0.6219, Train Acc: 63.01%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 8310/10000, Train Loss: 0.6007, Train Acc: 62.43%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 8311/10000, Train Loss: 0.6248, Train Acc: 60.69%, Test Loss: 0.5526, Test Acc: 74.14%\n",
            "Epoch 8312/10000, Train Loss: 0.6218, Train Acc: 66.47%, Test Loss: 0.5518, Test Acc: 75.86%\n",
            "Epoch 8313/10000, Train Loss: 0.6371, Train Acc: 61.85%, Test Loss: 0.5483, Test Acc: 75.86%\n",
            "Epoch 8314/10000, Train Loss: 0.6183, Train Acc: 65.03%, Test Loss: 0.5467, Test Acc: 74.14%\n",
            "Epoch 8315/10000, Train Loss: 0.5993, Train Acc: 64.16%, Test Loss: 0.5494, Test Acc: 70.69%\n",
            "Epoch 8316/10000, Train Loss: 0.6278, Train Acc: 65.32%, Test Loss: 0.5508, Test Acc: 68.97%\n",
            "Epoch 8317/10000, Train Loss: 0.6260, Train Acc: 64.74%, Test Loss: 0.5509, Test Acc: 70.69%\n",
            "Epoch 8318/10000, Train Loss: 0.6215, Train Acc: 63.29%, Test Loss: 0.5510, Test Acc: 70.69%\n",
            "Epoch 8319/10000, Train Loss: 0.5899, Train Acc: 69.08%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 8320/10000, Train Loss: 0.6247, Train Acc: 64.16%, Test Loss: 0.5532, Test Acc: 70.69%\n",
            "Epoch 8321/10000, Train Loss: 0.5984, Train Acc: 66.18%, Test Loss: 0.5528, Test Acc: 70.69%\n",
            "Epoch 8322/10000, Train Loss: 0.5956, Train Acc: 64.16%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 8323/10000, Train Loss: 0.6159, Train Acc: 68.21%, Test Loss: 0.5492, Test Acc: 68.97%\n",
            "Epoch 8324/10000, Train Loss: 0.6148, Train Acc: 63.58%, Test Loss: 0.5496, Test Acc: 70.69%\n",
            "Epoch 8325/10000, Train Loss: 0.6216, Train Acc: 63.01%, Test Loss: 0.5497, Test Acc: 68.97%\n",
            "Epoch 8326/10000, Train Loss: 0.6246, Train Acc: 65.32%, Test Loss: 0.5461, Test Acc: 68.97%\n",
            "Epoch 8327/10000, Train Loss: 0.6114, Train Acc: 67.63%, Test Loss: 0.5452, Test Acc: 70.69%\n",
            "Epoch 8328/10000, Train Loss: 0.6253, Train Acc: 65.32%, Test Loss: 0.5472, Test Acc: 68.97%\n",
            "Epoch 8329/10000, Train Loss: 0.5948, Train Acc: 65.61%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 8330/10000, Train Loss: 0.5878, Train Acc: 64.16%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 8331/10000, Train Loss: 0.5979, Train Acc: 66.18%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 8332/10000, Train Loss: 0.5975, Train Acc: 66.18%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 8333/10000, Train Loss: 0.6102, Train Acc: 62.43%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 8334/10000, Train Loss: 0.6048, Train Acc: 69.65%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 8335/10000, Train Loss: 0.6055, Train Acc: 66.76%, Test Loss: 0.5483, Test Acc: 68.97%\n",
            "Epoch 8336/10000, Train Loss: 0.6026, Train Acc: 64.45%, Test Loss: 0.5499, Test Acc: 68.97%\n",
            "Epoch 8337/10000, Train Loss: 0.5890, Train Acc: 64.16%, Test Loss: 0.5502, Test Acc: 70.69%\n",
            "Epoch 8338/10000, Train Loss: 0.6032, Train Acc: 65.03%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 8339/10000, Train Loss: 0.6089, Train Acc: 63.87%, Test Loss: 0.5570, Test Acc: 70.69%\n",
            "Epoch 8340/10000, Train Loss: 0.6333, Train Acc: 65.61%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 8341/10000, Train Loss: 0.6239, Train Acc: 64.16%, Test Loss: 0.5494, Test Acc: 68.97%\n",
            "Epoch 8342/10000, Train Loss: 0.6165, Train Acc: 67.63%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 8343/10000, Train Loss: 0.6135, Train Acc: 64.74%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 8344/10000, Train Loss: 0.6179, Train Acc: 65.61%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 8345/10000, Train Loss: 0.6279, Train Acc: 64.16%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 8346/10000, Train Loss: 0.6055, Train Acc: 64.16%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 8347/10000, Train Loss: 0.6004, Train Acc: 63.87%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 8348/10000, Train Loss: 0.5805, Train Acc: 67.34%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 8349/10000, Train Loss: 0.6085, Train Acc: 62.14%, Test Loss: 0.5508, Test Acc: 70.69%\n",
            "Epoch 8350/10000, Train Loss: 0.5948, Train Acc: 67.34%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 8351/10000, Train Loss: 0.5964, Train Acc: 66.18%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 8352/10000, Train Loss: 0.6024, Train Acc: 62.14%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 8353/10000, Train Loss: 0.5912, Train Acc: 65.32%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 8354/10000, Train Loss: 0.5851, Train Acc: 65.61%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 8355/10000, Train Loss: 0.5979, Train Acc: 69.36%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 8356/10000, Train Loss: 0.6147, Train Acc: 66.47%, Test Loss: 0.5523, Test Acc: 74.14%\n",
            "Epoch 8357/10000, Train Loss: 0.5964, Train Acc: 64.16%, Test Loss: 0.5538, Test Acc: 74.14%\n",
            "Epoch 8358/10000, Train Loss: 0.5963, Train Acc: 66.18%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 8359/10000, Train Loss: 0.6341, Train Acc: 63.58%, Test Loss: 0.5465, Test Acc: 70.69%\n",
            "Epoch 8360/10000, Train Loss: 0.6550, Train Acc: 64.45%, Test Loss: 0.5449, Test Acc: 68.97%\n",
            "Epoch 8361/10000, Train Loss: 0.6025, Train Acc: 67.34%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 8362/10000, Train Loss: 0.6116, Train Acc: 63.01%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 8363/10000, Train Loss: 0.6230, Train Acc: 65.32%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 8364/10000, Train Loss: 0.5996, Train Acc: 65.03%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 8365/10000, Train Loss: 0.6284, Train Acc: 63.58%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 8366/10000, Train Loss: 0.6107, Train Acc: 67.92%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 8367/10000, Train Loss: 0.6117, Train Acc: 64.45%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 8368/10000, Train Loss: 0.6042, Train Acc: 66.18%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 8369/10000, Train Loss: 0.6212, Train Acc: 64.74%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 8370/10000, Train Loss: 0.6042, Train Acc: 67.05%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 8371/10000, Train Loss: 0.6306, Train Acc: 64.45%, Test Loss: 0.5526, Test Acc: 70.69%\n",
            "Epoch 8372/10000, Train Loss: 0.6137, Train Acc: 65.32%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 8373/10000, Train Loss: 0.6060, Train Acc: 65.32%, Test Loss: 0.5552, Test Acc: 75.86%\n",
            "Epoch 8374/10000, Train Loss: 0.6058, Train Acc: 63.29%, Test Loss: 0.5486, Test Acc: 75.86%\n",
            "Epoch 8375/10000, Train Loss: 0.6063, Train Acc: 65.32%, Test Loss: 0.5458, Test Acc: 72.41%\n",
            "Epoch 8376/10000, Train Loss: 0.6187, Train Acc: 63.58%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 8377/10000, Train Loss: 0.6183, Train Acc: 64.16%, Test Loss: 0.5466, Test Acc: 70.69%\n",
            "Epoch 8378/10000, Train Loss: 0.5982, Train Acc: 61.85%, Test Loss: 0.5453, Test Acc: 68.97%\n",
            "Epoch 8379/10000, Train Loss: 0.6155, Train Acc: 68.50%, Test Loss: 0.5436, Test Acc: 74.14%\n",
            "Epoch 8380/10000, Train Loss: 0.6090, Train Acc: 62.14%, Test Loss: 0.5464, Test Acc: 68.97%\n",
            "Epoch 8381/10000, Train Loss: 0.6133, Train Acc: 64.74%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 8382/10000, Train Loss: 0.6233, Train Acc: 63.87%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 8383/10000, Train Loss: 0.6079, Train Acc: 68.50%, Test Loss: 0.5586, Test Acc: 72.41%\n",
            "Epoch 8384/10000, Train Loss: 0.6303, Train Acc: 66.47%, Test Loss: 0.5601, Test Acc: 72.41%\n",
            "Epoch 8385/10000, Train Loss: 0.6380, Train Acc: 62.14%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 8386/10000, Train Loss: 0.6233, Train Acc: 67.34%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 8387/10000, Train Loss: 0.6049, Train Acc: 62.43%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 8388/10000, Train Loss: 0.6320, Train Acc: 65.32%, Test Loss: 0.5532, Test Acc: 70.69%\n",
            "Epoch 8389/10000, Train Loss: 0.6378, Train Acc: 67.92%, Test Loss: 0.5493, Test Acc: 72.41%\n",
            "Epoch 8390/10000, Train Loss: 0.6252, Train Acc: 65.03%, Test Loss: 0.5480, Test Acc: 70.69%\n",
            "Epoch 8391/10000, Train Loss: 0.6130, Train Acc: 64.74%, Test Loss: 0.5489, Test Acc: 72.41%\n",
            "Epoch 8392/10000, Train Loss: 0.6169, Train Acc: 67.05%, Test Loss: 0.5483, Test Acc: 70.69%\n",
            "Epoch 8393/10000, Train Loss: 0.6186, Train Acc: 65.03%, Test Loss: 0.5494, Test Acc: 68.97%\n",
            "Epoch 8394/10000, Train Loss: 0.6110, Train Acc: 65.03%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 8395/10000, Train Loss: 0.6489, Train Acc: 61.85%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 8396/10000, Train Loss: 0.5948, Train Acc: 65.90%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 8397/10000, Train Loss: 0.6079, Train Acc: 64.45%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 8398/10000, Train Loss: 0.6016, Train Acc: 65.90%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 8399/10000, Train Loss: 0.6115, Train Acc: 63.01%, Test Loss: 0.5588, Test Acc: 70.69%\n",
            "Epoch 8400/10000, Train Loss: 0.6141, Train Acc: 66.18%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 8401/10000, Train Loss: 0.6136, Train Acc: 65.61%, Test Loss: 0.5499, Test Acc: 68.97%\n",
            "Epoch 8402/10000, Train Loss: 0.6084, Train Acc: 64.74%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 8403/10000, Train Loss: 0.6524, Train Acc: 65.32%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 8404/10000, Train Loss: 0.6381, Train Acc: 62.43%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 8405/10000, Train Loss: 0.6234, Train Acc: 65.32%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 8406/10000, Train Loss: 0.6181, Train Acc: 62.72%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 8407/10000, Train Loss: 0.6075, Train Acc: 65.03%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 8408/10000, Train Loss: 0.6047, Train Acc: 62.43%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 8409/10000, Train Loss: 0.6123, Train Acc: 64.74%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 8410/10000, Train Loss: 0.5914, Train Acc: 63.29%, Test Loss: 0.5515, Test Acc: 72.41%\n",
            "Epoch 8411/10000, Train Loss: 0.6237, Train Acc: 62.72%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 8412/10000, Train Loss: 0.6000, Train Acc: 66.76%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 8413/10000, Train Loss: 0.6266, Train Acc: 65.32%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 8414/10000, Train Loss: 0.6557, Train Acc: 61.56%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 8415/10000, Train Loss: 0.6347, Train Acc: 65.90%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 8416/10000, Train Loss: 0.6107, Train Acc: 64.16%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 8417/10000, Train Loss: 0.6108, Train Acc: 63.87%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 8418/10000, Train Loss: 0.6315, Train Acc: 65.03%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 8419/10000, Train Loss: 0.6097, Train Acc: 65.32%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 8420/10000, Train Loss: 0.6455, Train Acc: 64.74%, Test Loss: 0.5587, Test Acc: 74.14%\n",
            "Epoch 8421/10000, Train Loss: 0.6066, Train Acc: 66.76%, Test Loss: 0.5532, Test Acc: 70.69%\n",
            "Epoch 8422/10000, Train Loss: 0.6091, Train Acc: 65.90%, Test Loss: 0.5513, Test Acc: 70.69%\n",
            "Epoch 8423/10000, Train Loss: 0.5878, Train Acc: 64.45%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 8424/10000, Train Loss: 0.6036, Train Acc: 65.32%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 8425/10000, Train Loss: 0.6190, Train Acc: 63.58%, Test Loss: 0.5599, Test Acc: 68.97%\n",
            "Epoch 8426/10000, Train Loss: 0.5974, Train Acc: 64.45%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 8427/10000, Train Loss: 0.6113, Train Acc: 68.79%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 8428/10000, Train Loss: 0.5980, Train Acc: 65.90%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 8429/10000, Train Loss: 0.6167, Train Acc: 66.18%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 8430/10000, Train Loss: 0.6335, Train Acc: 67.05%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 8431/10000, Train Loss: 0.6162, Train Acc: 65.32%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 8432/10000, Train Loss: 0.6167, Train Acc: 65.90%, Test Loss: 0.5515, Test Acc: 72.41%\n",
            "Epoch 8433/10000, Train Loss: 0.5863, Train Acc: 68.50%, Test Loss: 0.5529, Test Acc: 74.14%\n",
            "Epoch 8434/10000, Train Loss: 0.6245, Train Acc: 64.16%, Test Loss: 0.5564, Test Acc: 74.14%\n",
            "Epoch 8435/10000, Train Loss: 0.5993, Train Acc: 63.29%, Test Loss: 0.5595, Test Acc: 74.14%\n",
            "Epoch 8436/10000, Train Loss: 0.6144, Train Acc: 64.16%, Test Loss: 0.5592, Test Acc: 70.69%\n",
            "Epoch 8437/10000, Train Loss: 0.6074, Train Acc: 65.90%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 8438/10000, Train Loss: 0.6130, Train Acc: 65.90%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 8439/10000, Train Loss: 0.5997, Train Acc: 67.34%, Test Loss: 0.5566, Test Acc: 72.41%\n",
            "Epoch 8440/10000, Train Loss: 0.6108, Train Acc: 68.21%, Test Loss: 0.5554, Test Acc: 72.41%\n",
            "Epoch 8441/10000, Train Loss: 0.6045, Train Acc: 64.74%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 8442/10000, Train Loss: 0.6225, Train Acc: 64.45%, Test Loss: 0.5517, Test Acc: 74.14%\n",
            "Epoch 8443/10000, Train Loss: 0.6203, Train Acc: 62.72%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 8444/10000, Train Loss: 0.6036, Train Acc: 65.61%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 8445/10000, Train Loss: 0.6196, Train Acc: 63.58%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 8446/10000, Train Loss: 0.6214, Train Acc: 65.61%, Test Loss: 0.5502, Test Acc: 70.69%\n",
            "Epoch 8447/10000, Train Loss: 0.6154, Train Acc: 66.47%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 8448/10000, Train Loss: 0.6280, Train Acc: 61.85%, Test Loss: 0.5512, Test Acc: 70.69%\n",
            "Epoch 8449/10000, Train Loss: 0.6345, Train Acc: 65.03%, Test Loss: 0.5480, Test Acc: 70.69%\n",
            "Epoch 8450/10000, Train Loss: 0.6469, Train Acc: 63.29%, Test Loss: 0.5472, Test Acc: 68.97%\n",
            "Epoch 8451/10000, Train Loss: 0.6079, Train Acc: 65.32%, Test Loss: 0.5510, Test Acc: 68.97%\n",
            "Epoch 8452/10000, Train Loss: 0.6079, Train Acc: 64.45%, Test Loss: 0.5496, Test Acc: 68.97%\n",
            "Epoch 8453/10000, Train Loss: 0.6028, Train Acc: 65.32%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 8454/10000, Train Loss: 0.6137, Train Acc: 62.72%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 8455/10000, Train Loss: 0.6147, Train Acc: 65.32%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 8456/10000, Train Loss: 0.6069, Train Acc: 65.90%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 8457/10000, Train Loss: 0.6034, Train Acc: 66.18%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 8458/10000, Train Loss: 0.6130, Train Acc: 67.92%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 8459/10000, Train Loss: 0.6090, Train Acc: 65.32%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 8460/10000, Train Loss: 0.5890, Train Acc: 65.90%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 8461/10000, Train Loss: 0.6195, Train Acc: 69.36%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 8462/10000, Train Loss: 0.5926, Train Acc: 66.47%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 8463/10000, Train Loss: 0.6201, Train Acc: 65.32%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 8464/10000, Train Loss: 0.6042, Train Acc: 65.32%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 8465/10000, Train Loss: 0.6212, Train Acc: 64.16%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 8466/10000, Train Loss: 0.6382, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 8467/10000, Train Loss: 0.6227, Train Acc: 61.85%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 8468/10000, Train Loss: 0.6370, Train Acc: 61.56%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 8469/10000, Train Loss: 0.6168, Train Acc: 66.47%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 8470/10000, Train Loss: 0.6281, Train Acc: 64.16%, Test Loss: 0.5542, Test Acc: 70.69%\n",
            "Epoch 8471/10000, Train Loss: 0.6356, Train Acc: 63.58%, Test Loss: 0.5503, Test Acc: 72.41%\n",
            "Epoch 8472/10000, Train Loss: 0.6197, Train Acc: 66.18%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 8473/10000, Train Loss: 0.5872, Train Acc: 68.79%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 8474/10000, Train Loss: 0.6169, Train Acc: 62.14%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 8475/10000, Train Loss: 0.5791, Train Acc: 67.63%, Test Loss: 0.5606, Test Acc: 70.69%\n",
            "Epoch 8476/10000, Train Loss: 0.6141, Train Acc: 62.43%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 8477/10000, Train Loss: 0.6236, Train Acc: 67.34%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 8478/10000, Train Loss: 0.6207, Train Acc: 63.29%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 8479/10000, Train Loss: 0.6003, Train Acc: 66.47%, Test Loss: 0.5521, Test Acc: 68.97%\n",
            "Epoch 8480/10000, Train Loss: 0.6364, Train Acc: 64.45%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 8481/10000, Train Loss: 0.6067, Train Acc: 66.76%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 8482/10000, Train Loss: 0.6031, Train Acc: 65.03%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 8483/10000, Train Loss: 0.6101, Train Acc: 64.74%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 8484/10000, Train Loss: 0.5968, Train Acc: 64.16%, Test Loss: 0.5599, Test Acc: 68.97%\n",
            "Epoch 8485/10000, Train Loss: 0.6184, Train Acc: 65.03%, Test Loss: 0.5630, Test Acc: 70.69%\n",
            "Epoch 8486/10000, Train Loss: 0.6195, Train Acc: 63.87%, Test Loss: 0.5637, Test Acc: 70.69%\n",
            "Epoch 8487/10000, Train Loss: 0.6059, Train Acc: 65.61%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 8488/10000, Train Loss: 0.6119, Train Acc: 63.01%, Test Loss: 0.5531, Test Acc: 74.14%\n",
            "Epoch 8489/10000, Train Loss: 0.5866, Train Acc: 66.18%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 8490/10000, Train Loss: 0.5944, Train Acc: 65.90%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 8491/10000, Train Loss: 0.6037, Train Acc: 67.92%, Test Loss: 0.5512, Test Acc: 72.41%\n",
            "Epoch 8492/10000, Train Loss: 0.5844, Train Acc: 68.21%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 8493/10000, Train Loss: 0.6119, Train Acc: 63.58%, Test Loss: 0.5578, Test Acc: 72.41%\n",
            "Epoch 8494/10000, Train Loss: 0.6196, Train Acc: 64.16%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 8495/10000, Train Loss: 0.6047, Train Acc: 63.29%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 8496/10000, Train Loss: 0.5984, Train Acc: 64.45%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 8497/10000, Train Loss: 0.5945, Train Acc: 64.45%, Test Loss: 0.5606, Test Acc: 68.97%\n",
            "Epoch 8498/10000, Train Loss: 0.6232, Train Acc: 65.61%, Test Loss: 0.5615, Test Acc: 68.97%\n",
            "Epoch 8499/10000, Train Loss: 0.6010, Train Acc: 65.61%, Test Loss: 0.5572, Test Acc: 72.41%\n",
            "Epoch 8500/10000, Train Loss: 0.6174, Train Acc: 63.58%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 8501/10000, Train Loss: 0.6141, Train Acc: 64.45%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 8502/10000, Train Loss: 0.6114, Train Acc: 66.18%, Test Loss: 0.5583, Test Acc: 75.86%\n",
            "Epoch 8503/10000, Train Loss: 0.6274, Train Acc: 66.76%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 8504/10000, Train Loss: 0.6267, Train Acc: 65.32%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 8505/10000, Train Loss: 0.6245, Train Acc: 65.61%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 8506/10000, Train Loss: 0.6047, Train Acc: 63.58%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 8507/10000, Train Loss: 0.6069, Train Acc: 65.32%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 8508/10000, Train Loss: 0.6432, Train Acc: 64.16%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 8509/10000, Train Loss: 0.6103, Train Acc: 64.16%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 8510/10000, Train Loss: 0.6056, Train Acc: 63.87%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 8511/10000, Train Loss: 0.6305, Train Acc: 62.72%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 8512/10000, Train Loss: 0.5901, Train Acc: 66.76%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 8513/10000, Train Loss: 0.6225, Train Acc: 65.03%, Test Loss: 0.5557, Test Acc: 70.69%\n",
            "Epoch 8514/10000, Train Loss: 0.6391, Train Acc: 65.90%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 8515/10000, Train Loss: 0.6165, Train Acc: 65.32%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 8516/10000, Train Loss: 0.6240, Train Acc: 65.32%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 8517/10000, Train Loss: 0.6152, Train Acc: 67.92%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 8518/10000, Train Loss: 0.6070, Train Acc: 63.58%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 8519/10000, Train Loss: 0.6207, Train Acc: 63.87%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 8520/10000, Train Loss: 0.6069, Train Acc: 63.58%, Test Loss: 0.5613, Test Acc: 68.97%\n",
            "Epoch 8521/10000, Train Loss: 0.6024, Train Acc: 67.34%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 8522/10000, Train Loss: 0.5844, Train Acc: 67.05%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 8523/10000, Train Loss: 0.6025, Train Acc: 66.47%, Test Loss: 0.5527, Test Acc: 70.69%\n",
            "Epoch 8524/10000, Train Loss: 0.6121, Train Acc: 62.72%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 8525/10000, Train Loss: 0.6012, Train Acc: 67.92%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 8526/10000, Train Loss: 0.6356, Train Acc: 61.27%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 8527/10000, Train Loss: 0.6166, Train Acc: 63.01%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 8528/10000, Train Loss: 0.6008, Train Acc: 65.32%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 8529/10000, Train Loss: 0.6095, Train Acc: 67.05%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 8530/10000, Train Loss: 0.5932, Train Acc: 67.05%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 8531/10000, Train Loss: 0.5891, Train Acc: 65.03%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 8532/10000, Train Loss: 0.5959, Train Acc: 64.45%, Test Loss: 0.5628, Test Acc: 70.69%\n",
            "Epoch 8533/10000, Train Loss: 0.6035, Train Acc: 65.61%, Test Loss: 0.5653, Test Acc: 70.69%\n",
            "Epoch 8534/10000, Train Loss: 0.6069, Train Acc: 67.63%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 8535/10000, Train Loss: 0.6043, Train Acc: 66.18%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 8536/10000, Train Loss: 0.6000, Train Acc: 66.47%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 8537/10000, Train Loss: 0.6128, Train Acc: 64.45%, Test Loss: 0.5571, Test Acc: 74.14%\n",
            "Epoch 8538/10000, Train Loss: 0.5937, Train Acc: 67.92%, Test Loss: 0.5565, Test Acc: 74.14%\n",
            "Epoch 8539/10000, Train Loss: 0.6061, Train Acc: 65.03%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 8540/10000, Train Loss: 0.6385, Train Acc: 61.85%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8541/10000, Train Loss: 0.6213, Train Acc: 64.74%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 8542/10000, Train Loss: 0.5991, Train Acc: 67.92%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 8543/10000, Train Loss: 0.6433, Train Acc: 61.85%, Test Loss: 0.5570, Test Acc: 74.14%\n",
            "Epoch 8544/10000, Train Loss: 0.6218, Train Acc: 64.74%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 8545/10000, Train Loss: 0.6319, Train Acc: 62.14%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 8546/10000, Train Loss: 0.6150, Train Acc: 62.14%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 8547/10000, Train Loss: 0.6279, Train Acc: 64.16%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 8548/10000, Train Loss: 0.6046, Train Acc: 67.63%, Test Loss: 0.5608, Test Acc: 68.97%\n",
            "Epoch 8549/10000, Train Loss: 0.5911, Train Acc: 65.03%, Test Loss: 0.5655, Test Acc: 68.97%\n",
            "Epoch 8550/10000, Train Loss: 0.5889, Train Acc: 65.61%, Test Loss: 0.5667, Test Acc: 68.97%\n",
            "Epoch 8551/10000, Train Loss: 0.6028, Train Acc: 67.34%, Test Loss: 0.5685, Test Acc: 68.97%\n",
            "Epoch 8552/10000, Train Loss: 0.6020, Train Acc: 66.47%, Test Loss: 0.5657, Test Acc: 68.97%\n",
            "Epoch 8553/10000, Train Loss: 0.6269, Train Acc: 63.29%, Test Loss: 0.5619, Test Acc: 74.14%\n",
            "Epoch 8554/10000, Train Loss: 0.6452, Train Acc: 60.69%, Test Loss: 0.5601, Test Acc: 72.41%\n",
            "Epoch 8555/10000, Train Loss: 0.6265, Train Acc: 63.58%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 8556/10000, Train Loss: 0.6184, Train Acc: 67.34%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 8557/10000, Train Loss: 0.6014, Train Acc: 64.74%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 8558/10000, Train Loss: 0.5999, Train Acc: 66.76%, Test Loss: 0.5581, Test Acc: 74.14%\n",
            "Epoch 8559/10000, Train Loss: 0.5966, Train Acc: 63.87%, Test Loss: 0.5587, Test Acc: 72.41%\n",
            "Epoch 8560/10000, Train Loss: 0.6098, Train Acc: 64.74%, Test Loss: 0.5568, Test Acc: 70.69%\n",
            "Epoch 8561/10000, Train Loss: 0.6072, Train Acc: 65.90%, Test Loss: 0.5555, Test Acc: 74.14%\n",
            "Epoch 8562/10000, Train Loss: 0.6094, Train Acc: 63.87%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 8563/10000, Train Loss: 0.6103, Train Acc: 68.21%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 8564/10000, Train Loss: 0.6169, Train Acc: 65.61%, Test Loss: 0.5591, Test Acc: 72.41%\n",
            "Epoch 8565/10000, Train Loss: 0.6152, Train Acc: 63.29%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 8566/10000, Train Loss: 0.6201, Train Acc: 62.72%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 8567/10000, Train Loss: 0.5932, Train Acc: 64.45%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 8568/10000, Train Loss: 0.6102, Train Acc: 65.90%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 8569/10000, Train Loss: 0.6274, Train Acc: 66.18%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 8570/10000, Train Loss: 0.6103, Train Acc: 65.03%, Test Loss: 0.5557, Test Acc: 70.69%\n",
            "Epoch 8571/10000, Train Loss: 0.6163, Train Acc: 64.45%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 8572/10000, Train Loss: 0.6556, Train Acc: 62.43%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 8573/10000, Train Loss: 0.6034, Train Acc: 65.03%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 8574/10000, Train Loss: 0.6327, Train Acc: 64.16%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 8575/10000, Train Loss: 0.6239, Train Acc: 61.85%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 8576/10000, Train Loss: 0.6435, Train Acc: 63.58%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 8577/10000, Train Loss: 0.6222, Train Acc: 64.74%, Test Loss: 0.5628, Test Acc: 68.97%\n",
            "Epoch 8578/10000, Train Loss: 0.6193, Train Acc: 63.29%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 8579/10000, Train Loss: 0.6160, Train Acc: 67.34%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 8580/10000, Train Loss: 0.6110, Train Acc: 64.16%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 8581/10000, Train Loss: 0.6227, Train Acc: 66.47%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 8582/10000, Train Loss: 0.5838, Train Acc: 67.92%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 8583/10000, Train Loss: 0.6042, Train Acc: 68.50%, Test Loss: 0.5590, Test Acc: 68.97%\n",
            "Epoch 8584/10000, Train Loss: 0.6208, Train Acc: 64.16%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 8585/10000, Train Loss: 0.5884, Train Acc: 65.90%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 8586/10000, Train Loss: 0.6074, Train Acc: 67.05%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 8587/10000, Train Loss: 0.6066, Train Acc: 65.61%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 8588/10000, Train Loss: 0.6223, Train Acc: 63.87%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 8589/10000, Train Loss: 0.6229, Train Acc: 63.87%, Test Loss: 0.5515, Test Acc: 70.69%\n",
            "Epoch 8590/10000, Train Loss: 0.5973, Train Acc: 66.18%, Test Loss: 0.5513, Test Acc: 72.41%\n",
            "Epoch 8591/10000, Train Loss: 0.6176, Train Acc: 64.16%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 8592/10000, Train Loss: 0.6353, Train Acc: 62.72%, Test Loss: 0.5507, Test Acc: 75.86%\n",
            "Epoch 8593/10000, Train Loss: 0.6055, Train Acc: 64.74%, Test Loss: 0.5512, Test Acc: 75.86%\n",
            "Epoch 8594/10000, Train Loss: 0.6171, Train Acc: 64.74%, Test Loss: 0.5487, Test Acc: 75.86%\n",
            "Epoch 8595/10000, Train Loss: 0.6313, Train Acc: 63.01%, Test Loss: 0.5426, Test Acc: 70.69%\n",
            "Epoch 8596/10000, Train Loss: 0.5897, Train Acc: 65.32%, Test Loss: 0.5444, Test Acc: 70.69%\n",
            "Epoch 8597/10000, Train Loss: 0.5978, Train Acc: 66.76%, Test Loss: 0.5502, Test Acc: 70.69%\n",
            "Epoch 8598/10000, Train Loss: 0.6241, Train Acc: 63.58%, Test Loss: 0.5521, Test Acc: 70.69%\n",
            "Epoch 8599/10000, Train Loss: 0.6093, Train Acc: 65.32%, Test Loss: 0.5526, Test Acc: 70.69%\n",
            "Epoch 8600/10000, Train Loss: 0.6148, Train Acc: 65.03%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 8601/10000, Train Loss: 0.6075, Train Acc: 64.16%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 8602/10000, Train Loss: 0.6274, Train Acc: 63.87%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 8603/10000, Train Loss: 0.5959, Train Acc: 66.18%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 8604/10000, Train Loss: 0.6186, Train Acc: 63.01%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 8605/10000, Train Loss: 0.6285, Train Acc: 62.14%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 8606/10000, Train Loss: 0.6290, Train Acc: 63.87%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 8607/10000, Train Loss: 0.6282, Train Acc: 63.01%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 8608/10000, Train Loss: 0.6205, Train Acc: 66.18%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 8609/10000, Train Loss: 0.6011, Train Acc: 65.61%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 8610/10000, Train Loss: 0.6165, Train Acc: 65.90%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 8611/10000, Train Loss: 0.6300, Train Acc: 66.47%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 8612/10000, Train Loss: 0.6290, Train Acc: 65.32%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 8613/10000, Train Loss: 0.6221, Train Acc: 67.05%, Test Loss: 0.5548, Test Acc: 70.69%\n",
            "Epoch 8614/10000, Train Loss: 0.6145, Train Acc: 64.16%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 8615/10000, Train Loss: 0.6101, Train Acc: 63.58%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 8616/10000, Train Loss: 0.5952, Train Acc: 66.18%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 8617/10000, Train Loss: 0.6576, Train Acc: 60.98%, Test Loss: 0.5596, Test Acc: 74.14%\n",
            "Epoch 8618/10000, Train Loss: 0.5901, Train Acc: 67.63%, Test Loss: 0.5674, Test Acc: 72.41%\n",
            "Epoch 8619/10000, Train Loss: 0.6035, Train Acc: 67.63%, Test Loss: 0.5694, Test Acc: 70.69%\n",
            "Epoch 8620/10000, Train Loss: 0.6141, Train Acc: 64.16%, Test Loss: 0.5641, Test Acc: 68.97%\n",
            "Epoch 8621/10000, Train Loss: 0.6093, Train Acc: 65.03%, Test Loss: 0.5620, Test Acc: 72.41%\n",
            "Epoch 8622/10000, Train Loss: 0.6081, Train Acc: 65.90%, Test Loss: 0.5600, Test Acc: 74.14%\n",
            "Epoch 8623/10000, Train Loss: 0.6247, Train Acc: 61.85%, Test Loss: 0.5616, Test Acc: 72.41%\n",
            "Epoch 8624/10000, Train Loss: 0.6107, Train Acc: 63.58%, Test Loss: 0.5579, Test Acc: 72.41%\n",
            "Epoch 8625/10000, Train Loss: 0.5954, Train Acc: 62.72%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 8626/10000, Train Loss: 0.5918, Train Acc: 65.32%, Test Loss: 0.5570, Test Acc: 72.41%\n",
            "Epoch 8627/10000, Train Loss: 0.5915, Train Acc: 66.76%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 8628/10000, Train Loss: 0.6017, Train Acc: 68.21%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 8629/10000, Train Loss: 0.6283, Train Acc: 61.56%, Test Loss: 0.5578, Test Acc: 70.69%\n",
            "Epoch 8630/10000, Train Loss: 0.6054, Train Acc: 64.16%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 8631/10000, Train Loss: 0.6028, Train Acc: 64.45%, Test Loss: 0.5547, Test Acc: 70.69%\n",
            "Epoch 8632/10000, Train Loss: 0.6036, Train Acc: 66.76%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 8633/10000, Train Loss: 0.6188, Train Acc: 62.14%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 8634/10000, Train Loss: 0.6271, Train Acc: 64.16%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 8635/10000, Train Loss: 0.6258, Train Acc: 64.45%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 8636/10000, Train Loss: 0.6109, Train Acc: 62.14%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 8637/10000, Train Loss: 0.6185, Train Acc: 62.43%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 8638/10000, Train Loss: 0.5852, Train Acc: 65.90%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 8639/10000, Train Loss: 0.6290, Train Acc: 63.87%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 8640/10000, Train Loss: 0.6104, Train Acc: 63.87%, Test Loss: 0.5560, Test Acc: 70.69%\n",
            "Epoch 8641/10000, Train Loss: 0.5944, Train Acc: 65.61%, Test Loss: 0.5583, Test Acc: 70.69%\n",
            "Epoch 8642/10000, Train Loss: 0.6158, Train Acc: 66.47%, Test Loss: 0.5573, Test Acc: 74.14%\n",
            "Epoch 8643/10000, Train Loss: 0.6259, Train Acc: 63.87%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 8644/10000, Train Loss: 0.6330, Train Acc: 65.32%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8645/10000, Train Loss: 0.6070, Train Acc: 64.74%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 8646/10000, Train Loss: 0.6253, Train Acc: 65.03%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 8647/10000, Train Loss: 0.6169, Train Acc: 62.43%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 8648/10000, Train Loss: 0.6354, Train Acc: 65.90%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 8649/10000, Train Loss: 0.6006, Train Acc: 67.34%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 8650/10000, Train Loss: 0.6232, Train Acc: 65.32%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 8651/10000, Train Loss: 0.6263, Train Acc: 63.01%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 8652/10000, Train Loss: 0.6132, Train Acc: 64.74%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 8653/10000, Train Loss: 0.6356, Train Acc: 63.29%, Test Loss: 0.5593, Test Acc: 74.14%\n",
            "Epoch 8654/10000, Train Loss: 0.6311, Train Acc: 63.29%, Test Loss: 0.5625, Test Acc: 68.97%\n",
            "Epoch 8655/10000, Train Loss: 0.6173, Train Acc: 63.29%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 8656/10000, Train Loss: 0.5994, Train Acc: 68.79%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 8657/10000, Train Loss: 0.6188, Train Acc: 63.58%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 8658/10000, Train Loss: 0.6370, Train Acc: 63.58%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 8659/10000, Train Loss: 0.6008, Train Acc: 68.79%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 8660/10000, Train Loss: 0.6062, Train Acc: 68.50%, Test Loss: 0.5660, Test Acc: 70.69%\n",
            "Epoch 8661/10000, Train Loss: 0.6091, Train Acc: 67.63%, Test Loss: 0.5617, Test Acc: 68.97%\n",
            "Epoch 8662/10000, Train Loss: 0.6148, Train Acc: 62.72%, Test Loss: 0.5598, Test Acc: 72.41%\n",
            "Epoch 8663/10000, Train Loss: 0.6012, Train Acc: 67.34%, Test Loss: 0.5599, Test Acc: 74.14%\n",
            "Epoch 8664/10000, Train Loss: 0.6122, Train Acc: 66.18%, Test Loss: 0.5557, Test Acc: 74.14%\n",
            "Epoch 8665/10000, Train Loss: 0.5987, Train Acc: 63.29%, Test Loss: 0.5543, Test Acc: 75.86%\n",
            "Epoch 8666/10000, Train Loss: 0.6071, Train Acc: 66.18%, Test Loss: 0.5553, Test Acc: 75.86%\n",
            "Epoch 8667/10000, Train Loss: 0.6205, Train Acc: 65.61%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 8668/10000, Train Loss: 0.6098, Train Acc: 65.32%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 8669/10000, Train Loss: 0.6041, Train Acc: 65.03%, Test Loss: 0.5457, Test Acc: 70.69%\n",
            "Epoch 8670/10000, Train Loss: 0.6136, Train Acc: 66.18%, Test Loss: 0.5472, Test Acc: 70.69%\n",
            "Epoch 8671/10000, Train Loss: 0.6292, Train Acc: 65.61%, Test Loss: 0.5503, Test Acc: 70.69%\n",
            "Epoch 8672/10000, Train Loss: 0.6233, Train Acc: 62.43%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 8673/10000, Train Loss: 0.6217, Train Acc: 65.32%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 8674/10000, Train Loss: 0.6331, Train Acc: 62.72%, Test Loss: 0.5657, Test Acc: 68.97%\n",
            "Epoch 8675/10000, Train Loss: 0.6174, Train Acc: 63.58%, Test Loss: 0.5688, Test Acc: 72.41%\n",
            "Epoch 8676/10000, Train Loss: 0.6101, Train Acc: 63.87%, Test Loss: 0.5683, Test Acc: 68.97%\n",
            "Epoch 8677/10000, Train Loss: 0.6272, Train Acc: 66.18%, Test Loss: 0.5656, Test Acc: 68.97%\n",
            "Epoch 8678/10000, Train Loss: 0.6110, Train Acc: 65.61%, Test Loss: 0.5640, Test Acc: 68.97%\n",
            "Epoch 8679/10000, Train Loss: 0.6075, Train Acc: 66.47%, Test Loss: 0.5606, Test Acc: 68.97%\n",
            "Epoch 8680/10000, Train Loss: 0.6035, Train Acc: 67.92%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 8681/10000, Train Loss: 0.6145, Train Acc: 63.01%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 8682/10000, Train Loss: 0.6105, Train Acc: 61.85%, Test Loss: 0.5601, Test Acc: 74.14%\n",
            "Epoch 8683/10000, Train Loss: 0.6145, Train Acc: 62.72%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 8684/10000, Train Loss: 0.6357, Train Acc: 62.72%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 8685/10000, Train Loss: 0.6222, Train Acc: 64.45%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 8686/10000, Train Loss: 0.6373, Train Acc: 60.69%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 8687/10000, Train Loss: 0.6186, Train Acc: 62.14%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 8688/10000, Train Loss: 0.6151, Train Acc: 64.74%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 8689/10000, Train Loss: 0.6182, Train Acc: 64.45%, Test Loss: 0.5584, Test Acc: 72.41%\n",
            "Epoch 8690/10000, Train Loss: 0.6142, Train Acc: 63.01%, Test Loss: 0.5578, Test Acc: 72.41%\n",
            "Epoch 8691/10000, Train Loss: 0.6295, Train Acc: 65.32%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 8692/10000, Train Loss: 0.6096, Train Acc: 67.05%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 8693/10000, Train Loss: 0.6419, Train Acc: 60.69%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 8694/10000, Train Loss: 0.5964, Train Acc: 67.05%, Test Loss: 0.5574, Test Acc: 72.41%\n",
            "Epoch 8695/10000, Train Loss: 0.6342, Train Acc: 64.74%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 8696/10000, Train Loss: 0.6144, Train Acc: 61.85%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 8697/10000, Train Loss: 0.6016, Train Acc: 68.79%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 8698/10000, Train Loss: 0.6000, Train Acc: 66.47%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 8699/10000, Train Loss: 0.6297, Train Acc: 61.27%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 8700/10000, Train Loss: 0.6250, Train Acc: 61.27%, Test Loss: 0.5568, Test Acc: 70.69%\n",
            "Epoch 8701/10000, Train Loss: 0.6139, Train Acc: 65.03%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 8702/10000, Train Loss: 0.6175, Train Acc: 66.76%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 8703/10000, Train Loss: 0.6189, Train Acc: 65.90%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 8704/10000, Train Loss: 0.6168, Train Acc: 65.32%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 8705/10000, Train Loss: 0.6289, Train Acc: 62.43%, Test Loss: 0.5585, Test Acc: 72.41%\n",
            "Epoch 8706/10000, Train Loss: 0.6092, Train Acc: 67.05%, Test Loss: 0.5606, Test Acc: 68.97%\n",
            "Epoch 8707/10000, Train Loss: 0.6021, Train Acc: 66.47%, Test Loss: 0.5634, Test Acc: 68.97%\n",
            "Epoch 8708/10000, Train Loss: 0.6122, Train Acc: 67.05%, Test Loss: 0.5678, Test Acc: 72.41%\n",
            "Epoch 8709/10000, Train Loss: 0.6167, Train Acc: 61.85%, Test Loss: 0.5673, Test Acc: 68.97%\n",
            "Epoch 8710/10000, Train Loss: 0.6513, Train Acc: 63.01%, Test Loss: 0.5607, Test Acc: 68.97%\n",
            "Epoch 8711/10000, Train Loss: 0.6015, Train Acc: 67.34%, Test Loss: 0.5623, Test Acc: 70.69%\n",
            "Epoch 8712/10000, Train Loss: 0.6094, Train Acc: 66.47%, Test Loss: 0.5630, Test Acc: 72.41%\n",
            "Epoch 8713/10000, Train Loss: 0.6168, Train Acc: 66.18%, Test Loss: 0.5600, Test Acc: 74.14%\n",
            "Epoch 8714/10000, Train Loss: 0.5970, Train Acc: 63.58%, Test Loss: 0.5578, Test Acc: 72.41%\n",
            "Epoch 8715/10000, Train Loss: 0.6114, Train Acc: 63.58%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 8716/10000, Train Loss: 0.6282, Train Acc: 65.90%, Test Loss: 0.5575, Test Acc: 72.41%\n",
            "Epoch 8717/10000, Train Loss: 0.6226, Train Acc: 59.83%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 8718/10000, Train Loss: 0.6528, Train Acc: 60.12%, Test Loss: 0.5558, Test Acc: 74.14%\n",
            "Epoch 8719/10000, Train Loss: 0.6063, Train Acc: 63.87%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 8720/10000, Train Loss: 0.6141, Train Acc: 62.14%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 8721/10000, Train Loss: 0.6338, Train Acc: 65.03%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 8722/10000, Train Loss: 0.5987, Train Acc: 64.74%, Test Loss: 0.5519, Test Acc: 70.69%\n",
            "Epoch 8723/10000, Train Loss: 0.6084, Train Acc: 64.45%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 8724/10000, Train Loss: 0.5794, Train Acc: 68.21%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 8725/10000, Train Loss: 0.6119, Train Acc: 64.16%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 8726/10000, Train Loss: 0.6102, Train Acc: 65.03%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 8727/10000, Train Loss: 0.6226, Train Acc: 63.01%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 8728/10000, Train Loss: 0.6015, Train Acc: 64.16%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 8729/10000, Train Loss: 0.6344, Train Acc: 61.85%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 8730/10000, Train Loss: 0.6389, Train Acc: 60.98%, Test Loss: 0.5509, Test Acc: 70.69%\n",
            "Epoch 8731/10000, Train Loss: 0.6108, Train Acc: 68.79%, Test Loss: 0.5515, Test Acc: 70.69%\n",
            "Epoch 8732/10000, Train Loss: 0.6112, Train Acc: 68.21%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 8733/10000, Train Loss: 0.6304, Train Acc: 64.45%, Test Loss: 0.5557, Test Acc: 70.69%\n",
            "Epoch 8734/10000, Train Loss: 0.6292, Train Acc: 63.01%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 8735/10000, Train Loss: 0.6008, Train Acc: 65.32%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 8736/10000, Train Loss: 0.6269, Train Acc: 63.29%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 8737/10000, Train Loss: 0.6218, Train Acc: 65.61%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 8738/10000, Train Loss: 0.6096, Train Acc: 66.76%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8739/10000, Train Loss: 0.6371, Train Acc: 62.72%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 8740/10000, Train Loss: 0.6376, Train Acc: 65.90%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 8741/10000, Train Loss: 0.6141, Train Acc: 66.18%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 8742/10000, Train Loss: 0.6386, Train Acc: 66.18%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 8743/10000, Train Loss: 0.5853, Train Acc: 67.05%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 8744/10000, Train Loss: 0.6151, Train Acc: 66.18%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 8745/10000, Train Loss: 0.6184, Train Acc: 64.74%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 8746/10000, Train Loss: 0.6053, Train Acc: 67.05%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 8747/10000, Train Loss: 0.6164, Train Acc: 65.03%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 8748/10000, Train Loss: 0.5990, Train Acc: 66.47%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 8749/10000, Train Loss: 0.6113, Train Acc: 65.61%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 8750/10000, Train Loss: 0.6018, Train Acc: 65.90%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 8751/10000, Train Loss: 0.6225, Train Acc: 66.47%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 8752/10000, Train Loss: 0.6252, Train Acc: 64.45%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 8753/10000, Train Loss: 0.6119, Train Acc: 65.61%, Test Loss: 0.5597, Test Acc: 70.69%\n",
            "Epoch 8754/10000, Train Loss: 0.5992, Train Acc: 63.87%, Test Loss: 0.5627, Test Acc: 68.97%\n",
            "Epoch 8755/10000, Train Loss: 0.6295, Train Acc: 63.29%, Test Loss: 0.5590, Test Acc: 68.97%\n",
            "Epoch 8756/10000, Train Loss: 0.6250, Train Acc: 63.01%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 8757/10000, Train Loss: 0.6236, Train Acc: 61.56%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 8758/10000, Train Loss: 0.6098, Train Acc: 64.45%, Test Loss: 0.5573, Test Acc: 72.41%\n",
            "Epoch 8759/10000, Train Loss: 0.6009, Train Acc: 65.32%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 8760/10000, Train Loss: 0.6057, Train Acc: 65.32%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 8761/10000, Train Loss: 0.6236, Train Acc: 63.29%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 8762/10000, Train Loss: 0.6072, Train Acc: 65.61%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 8763/10000, Train Loss: 0.6170, Train Acc: 65.61%, Test Loss: 0.5598, Test Acc: 68.97%\n",
            "Epoch 8764/10000, Train Loss: 0.6013, Train Acc: 67.34%, Test Loss: 0.5570, Test Acc: 72.41%\n",
            "Epoch 8765/10000, Train Loss: 0.6093, Train Acc: 65.61%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 8766/10000, Train Loss: 0.6048, Train Acc: 64.45%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 8767/10000, Train Loss: 0.5925, Train Acc: 66.47%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 8768/10000, Train Loss: 0.6129, Train Acc: 66.76%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 8769/10000, Train Loss: 0.6113, Train Acc: 63.87%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 8770/10000, Train Loss: 0.6108, Train Acc: 63.29%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 8771/10000, Train Loss: 0.6082, Train Acc: 65.32%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 8772/10000, Train Loss: 0.5974, Train Acc: 65.90%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 8773/10000, Train Loss: 0.5996, Train Acc: 65.03%, Test Loss: 0.5652, Test Acc: 70.69%\n",
            "Epoch 8774/10000, Train Loss: 0.5978, Train Acc: 65.90%, Test Loss: 0.5698, Test Acc: 68.97%\n",
            "Epoch 8775/10000, Train Loss: 0.6170, Train Acc: 63.58%, Test Loss: 0.5632, Test Acc: 68.97%\n",
            "Epoch 8776/10000, Train Loss: 0.6406, Train Acc: 63.29%, Test Loss: 0.5612, Test Acc: 70.69%\n",
            "Epoch 8777/10000, Train Loss: 0.6319, Train Acc: 65.03%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 8778/10000, Train Loss: 0.6265, Train Acc: 63.87%, Test Loss: 0.5595, Test Acc: 74.14%\n",
            "Epoch 8779/10000, Train Loss: 0.6203, Train Acc: 65.90%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 8780/10000, Train Loss: 0.6106, Train Acc: 66.18%, Test Loss: 0.5590, Test Acc: 68.97%\n",
            "Epoch 8781/10000, Train Loss: 0.5903, Train Acc: 68.50%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 8782/10000, Train Loss: 0.6111, Train Acc: 69.65%, Test Loss: 0.5613, Test Acc: 68.97%\n",
            "Epoch 8783/10000, Train Loss: 0.6005, Train Acc: 65.90%, Test Loss: 0.5649, Test Acc: 68.97%\n",
            "Epoch 8784/10000, Train Loss: 0.5861, Train Acc: 65.90%, Test Loss: 0.5658, Test Acc: 70.69%\n",
            "Epoch 8785/10000, Train Loss: 0.6254, Train Acc: 64.45%, Test Loss: 0.5622, Test Acc: 70.69%\n",
            "Epoch 8786/10000, Train Loss: 0.5981, Train Acc: 67.05%, Test Loss: 0.5606, Test Acc: 74.14%\n",
            "Epoch 8787/10000, Train Loss: 0.6180, Train Acc: 67.34%, Test Loss: 0.5613, Test Acc: 74.14%\n",
            "Epoch 8788/10000, Train Loss: 0.6195, Train Acc: 63.29%, Test Loss: 0.5609, Test Acc: 72.41%\n",
            "Epoch 8789/10000, Train Loss: 0.6245, Train Acc: 64.16%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 8790/10000, Train Loss: 0.6044, Train Acc: 65.61%, Test Loss: 0.5581, Test Acc: 74.14%\n",
            "Epoch 8791/10000, Train Loss: 0.6213, Train Acc: 68.21%, Test Loss: 0.5583, Test Acc: 72.41%\n",
            "Epoch 8792/10000, Train Loss: 0.6108, Train Acc: 68.21%, Test Loss: 0.5579, Test Acc: 72.41%\n",
            "Epoch 8793/10000, Train Loss: 0.6025, Train Acc: 67.05%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 8794/10000, Train Loss: 0.6195, Train Acc: 66.47%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 8795/10000, Train Loss: 0.6183, Train Acc: 64.74%, Test Loss: 0.5594, Test Acc: 70.69%\n",
            "Epoch 8796/10000, Train Loss: 0.6316, Train Acc: 68.50%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 8797/10000, Train Loss: 0.5972, Train Acc: 68.21%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 8798/10000, Train Loss: 0.6176, Train Acc: 65.32%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 8799/10000, Train Loss: 0.6063, Train Acc: 68.79%, Test Loss: 0.5574, Test Acc: 70.69%\n",
            "Epoch 8800/10000, Train Loss: 0.6176, Train Acc: 65.61%, Test Loss: 0.5611, Test Acc: 70.69%\n",
            "Epoch 8801/10000, Train Loss: 0.6064, Train Acc: 67.63%, Test Loss: 0.5644, Test Acc: 68.97%\n",
            "Epoch 8802/10000, Train Loss: 0.5863, Train Acc: 69.94%, Test Loss: 0.5672, Test Acc: 68.97%\n",
            "Epoch 8803/10000, Train Loss: 0.6192, Train Acc: 60.98%, Test Loss: 0.5640, Test Acc: 74.14%\n",
            "Epoch 8804/10000, Train Loss: 0.6131, Train Acc: 67.05%, Test Loss: 0.5583, Test Acc: 72.41%\n",
            "Epoch 8805/10000, Train Loss: 0.6193, Train Acc: 65.03%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 8806/10000, Train Loss: 0.6327, Train Acc: 62.72%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 8807/10000, Train Loss: 0.5850, Train Acc: 67.92%, Test Loss: 0.5627, Test Acc: 70.69%\n",
            "Epoch 8808/10000, Train Loss: 0.6209, Train Acc: 64.45%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 8809/10000, Train Loss: 0.6095, Train Acc: 65.32%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 8810/10000, Train Loss: 0.5964, Train Acc: 66.47%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 8811/10000, Train Loss: 0.6217, Train Acc: 62.14%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 8812/10000, Train Loss: 0.6225, Train Acc: 64.16%, Test Loss: 0.5583, Test Acc: 72.41%\n",
            "Epoch 8813/10000, Train Loss: 0.6296, Train Acc: 59.54%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 8814/10000, Train Loss: 0.6212, Train Acc: 65.61%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 8815/10000, Train Loss: 0.6073, Train Acc: 67.34%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 8816/10000, Train Loss: 0.6126, Train Acc: 64.74%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 8817/10000, Train Loss: 0.6268, Train Acc: 63.87%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 8818/10000, Train Loss: 0.6022, Train Acc: 68.21%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 8819/10000, Train Loss: 0.6086, Train Acc: 65.90%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 8820/10000, Train Loss: 0.5956, Train Acc: 66.76%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 8821/10000, Train Loss: 0.6160, Train Acc: 66.18%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 8822/10000, Train Loss: 0.6041, Train Acc: 66.76%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 8823/10000, Train Loss: 0.5984, Train Acc: 67.05%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 8824/10000, Train Loss: 0.6272, Train Acc: 64.45%, Test Loss: 0.5520, Test Acc: 70.69%\n",
            "Epoch 8825/10000, Train Loss: 0.6347, Train Acc: 62.43%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 8826/10000, Train Loss: 0.6007, Train Acc: 63.87%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8827/10000, Train Loss: 0.6155, Train Acc: 65.90%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 8828/10000, Train Loss: 0.6185, Train Acc: 64.74%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 8829/10000, Train Loss: 0.6002, Train Acc: 66.47%, Test Loss: 0.5510, Test Acc: 70.69%\n",
            "Epoch 8830/10000, Train Loss: 0.6209, Train Acc: 64.45%, Test Loss: 0.5513, Test Acc: 70.69%\n",
            "Epoch 8831/10000, Train Loss: 0.6158, Train Acc: 65.32%, Test Loss: 0.5509, Test Acc: 70.69%\n",
            "Epoch 8832/10000, Train Loss: 0.6196, Train Acc: 63.29%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 8833/10000, Train Loss: 0.6308, Train Acc: 63.29%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 8834/10000, Train Loss: 0.6059, Train Acc: 64.45%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 8835/10000, Train Loss: 0.6173, Train Acc: 67.92%, Test Loss: 0.5542, Test Acc: 70.69%\n",
            "Epoch 8836/10000, Train Loss: 0.6046, Train Acc: 67.63%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 8837/10000, Train Loss: 0.6069, Train Acc: 64.45%, Test Loss: 0.5583, Test Acc: 70.69%\n",
            "Epoch 8838/10000, Train Loss: 0.6119, Train Acc: 67.92%, Test Loss: 0.5552, Test Acc: 70.69%\n",
            "Epoch 8839/10000, Train Loss: 0.6128, Train Acc: 62.43%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 8840/10000, Train Loss: 0.6077, Train Acc: 69.36%, Test Loss: 0.5525, Test Acc: 70.69%\n",
            "Epoch 8841/10000, Train Loss: 0.6209, Train Acc: 65.90%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 8842/10000, Train Loss: 0.6337, Train Acc: 63.58%, Test Loss: 0.5570, Test Acc: 70.69%\n",
            "Epoch 8843/10000, Train Loss: 0.6632, Train Acc: 66.47%, Test Loss: 0.5580, Test Acc: 70.69%\n",
            "Epoch 8844/10000, Train Loss: 0.6199, Train Acc: 65.03%, Test Loss: 0.5621, Test Acc: 68.97%\n",
            "Epoch 8845/10000, Train Loss: 0.6025, Train Acc: 66.76%, Test Loss: 0.5676, Test Acc: 70.69%\n",
            "Epoch 8846/10000, Train Loss: 0.6007, Train Acc: 65.03%, Test Loss: 0.5675, Test Acc: 68.97%\n",
            "Epoch 8847/10000, Train Loss: 0.6222, Train Acc: 67.05%, Test Loss: 0.5612, Test Acc: 70.69%\n",
            "Epoch 8848/10000, Train Loss: 0.5991, Train Acc: 64.45%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 8849/10000, Train Loss: 0.6061, Train Acc: 63.58%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 8850/10000, Train Loss: 0.6004, Train Acc: 64.45%, Test Loss: 0.5612, Test Acc: 70.69%\n",
            "Epoch 8851/10000, Train Loss: 0.6370, Train Acc: 65.61%, Test Loss: 0.5605, Test Acc: 72.41%\n",
            "Epoch 8852/10000, Train Loss: 0.6032, Train Acc: 63.01%, Test Loss: 0.5588, Test Acc: 72.41%\n",
            "Epoch 8853/10000, Train Loss: 0.6067, Train Acc: 61.85%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 8854/10000, Train Loss: 0.6078, Train Acc: 65.32%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 8855/10000, Train Loss: 0.6149, Train Acc: 64.45%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 8856/10000, Train Loss: 0.5999, Train Acc: 67.92%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 8857/10000, Train Loss: 0.6337, Train Acc: 64.16%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 8858/10000, Train Loss: 0.6182, Train Acc: 62.43%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 8859/10000, Train Loss: 0.6171, Train Acc: 61.85%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 8860/10000, Train Loss: 0.6059, Train Acc: 67.34%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 8861/10000, Train Loss: 0.6302, Train Acc: 60.40%, Test Loss: 0.5510, Test Acc: 70.69%\n",
            "Epoch 8862/10000, Train Loss: 0.6030, Train Acc: 67.34%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 8863/10000, Train Loss: 0.6233, Train Acc: 60.98%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 8864/10000, Train Loss: 0.5951, Train Acc: 65.61%, Test Loss: 0.5608, Test Acc: 70.69%\n",
            "Epoch 8865/10000, Train Loss: 0.6077, Train Acc: 65.32%, Test Loss: 0.5650, Test Acc: 70.69%\n",
            "Epoch 8866/10000, Train Loss: 0.6004, Train Acc: 67.05%, Test Loss: 0.5643, Test Acc: 68.97%\n",
            "Epoch 8867/10000, Train Loss: 0.5932, Train Acc: 64.74%, Test Loss: 0.5621, Test Acc: 70.69%\n",
            "Epoch 8868/10000, Train Loss: 0.6154, Train Acc: 66.18%, Test Loss: 0.5626, Test Acc: 68.97%\n",
            "Epoch 8869/10000, Train Loss: 0.6106, Train Acc: 66.18%, Test Loss: 0.5624, Test Acc: 68.97%\n",
            "Epoch 8870/10000, Train Loss: 0.6042, Train Acc: 64.74%, Test Loss: 0.5631, Test Acc: 68.97%\n",
            "Epoch 8871/10000, Train Loss: 0.6189, Train Acc: 67.34%, Test Loss: 0.5591, Test Acc: 70.69%\n",
            "Epoch 8872/10000, Train Loss: 0.6480, Train Acc: 58.38%, Test Loss: 0.5609, Test Acc: 72.41%\n",
            "Epoch 8873/10000, Train Loss: 0.5916, Train Acc: 66.18%, Test Loss: 0.5631, Test Acc: 74.14%\n",
            "Epoch 8874/10000, Train Loss: 0.6336, Train Acc: 66.18%, Test Loss: 0.5567, Test Acc: 75.86%\n",
            "Epoch 8875/10000, Train Loss: 0.6190, Train Acc: 62.43%, Test Loss: 0.5538, Test Acc: 74.14%\n",
            "Epoch 8876/10000, Train Loss: 0.6153, Train Acc: 62.14%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 8877/10000, Train Loss: 0.6498, Train Acc: 62.43%, Test Loss: 0.5508, Test Acc: 68.97%\n",
            "Epoch 8878/10000, Train Loss: 0.6275, Train Acc: 64.74%, Test Loss: 0.5505, Test Acc: 70.69%\n",
            "Epoch 8879/10000, Train Loss: 0.6071, Train Acc: 64.74%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 8880/10000, Train Loss: 0.6092, Train Acc: 65.32%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 8881/10000, Train Loss: 0.5917, Train Acc: 63.87%, Test Loss: 0.5560, Test Acc: 70.69%\n",
            "Epoch 8882/10000, Train Loss: 0.6085, Train Acc: 64.74%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 8883/10000, Train Loss: 0.6031, Train Acc: 67.92%, Test Loss: 0.5587, Test Acc: 70.69%\n",
            "Epoch 8884/10000, Train Loss: 0.6051, Train Acc: 67.05%, Test Loss: 0.5613, Test Acc: 68.97%\n",
            "Epoch 8885/10000, Train Loss: 0.6127, Train Acc: 65.61%, Test Loss: 0.5652, Test Acc: 67.24%\n",
            "Epoch 8886/10000, Train Loss: 0.6124, Train Acc: 67.05%, Test Loss: 0.5659, Test Acc: 68.97%\n",
            "Epoch 8887/10000, Train Loss: 0.6067, Train Acc: 64.74%, Test Loss: 0.5634, Test Acc: 68.97%\n",
            "Epoch 8888/10000, Train Loss: 0.5920, Train Acc: 65.61%, Test Loss: 0.5607, Test Acc: 68.97%\n",
            "Epoch 8889/10000, Train Loss: 0.6025, Train Acc: 67.05%, Test Loss: 0.5641, Test Acc: 68.97%\n",
            "Epoch 8890/10000, Train Loss: 0.6351, Train Acc: 65.61%, Test Loss: 0.5630, Test Acc: 70.69%\n",
            "Epoch 8891/10000, Train Loss: 0.6111, Train Acc: 66.18%, Test Loss: 0.5614, Test Acc: 74.14%\n",
            "Epoch 8892/10000, Train Loss: 0.6195, Train Acc: 65.32%, Test Loss: 0.5601, Test Acc: 74.14%\n",
            "Epoch 8893/10000, Train Loss: 0.5994, Train Acc: 63.87%, Test Loss: 0.5589, Test Acc: 75.86%\n",
            "Epoch 8894/10000, Train Loss: 0.6092, Train Acc: 62.72%, Test Loss: 0.5572, Test Acc: 75.86%\n",
            "Epoch 8895/10000, Train Loss: 0.5908, Train Acc: 65.61%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 8896/10000, Train Loss: 0.5944, Train Acc: 65.03%, Test Loss: 0.5574, Test Acc: 72.41%\n",
            "Epoch 8897/10000, Train Loss: 0.6192, Train Acc: 65.03%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 8898/10000, Train Loss: 0.6129, Train Acc: 61.27%, Test Loss: 0.5554, Test Acc: 70.69%\n",
            "Epoch 8899/10000, Train Loss: 0.6082, Train Acc: 63.87%, Test Loss: 0.5548, Test Acc: 70.69%\n",
            "Epoch 8900/10000, Train Loss: 0.6047, Train Acc: 65.90%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 8901/10000, Train Loss: 0.6067, Train Acc: 65.32%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 8902/10000, Train Loss: 0.6219, Train Acc: 64.16%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 8903/10000, Train Loss: 0.6159, Train Acc: 63.01%, Test Loss: 0.5606, Test Acc: 70.69%\n",
            "Epoch 8904/10000, Train Loss: 0.6037, Train Acc: 65.03%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 8905/10000, Train Loss: 0.5961, Train Acc: 66.47%, Test Loss: 0.5613, Test Acc: 70.69%\n",
            "Epoch 8906/10000, Train Loss: 0.6104, Train Acc: 64.45%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 8907/10000, Train Loss: 0.6151, Train Acc: 66.18%, Test Loss: 0.5591, Test Acc: 72.41%\n",
            "Epoch 8908/10000, Train Loss: 0.6290, Train Acc: 63.29%, Test Loss: 0.5581, Test Acc: 74.14%\n",
            "Epoch 8909/10000, Train Loss: 0.6187, Train Acc: 63.29%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 8910/10000, Train Loss: 0.6052, Train Acc: 64.45%, Test Loss: 0.5556, Test Acc: 70.69%\n",
            "Epoch 8911/10000, Train Loss: 0.6180, Train Acc: 63.29%, Test Loss: 0.5533, Test Acc: 74.14%\n",
            "Epoch 8912/10000, Train Loss: 0.6076, Train Acc: 65.03%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 8913/10000, Train Loss: 0.6299, Train Acc: 64.16%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 8914/10000, Train Loss: 0.6059, Train Acc: 64.45%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 8915/10000, Train Loss: 0.6262, Train Acc: 64.16%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 8916/10000, Train Loss: 0.6172, Train Acc: 64.16%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 8917/10000, Train Loss: 0.6011, Train Acc: 65.32%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 8918/10000, Train Loss: 0.6285, Train Acc: 65.90%, Test Loss: 0.5591, Test Acc: 70.69%\n",
            "Epoch 8919/10000, Train Loss: 0.6103, Train Acc: 67.05%, Test Loss: 0.5598, Test Acc: 70.69%\n",
            "Epoch 8920/10000, Train Loss: 0.6159, Train Acc: 62.43%, Test Loss: 0.5590, Test Acc: 68.97%\n",
            "Epoch 8921/10000, Train Loss: 0.6168, Train Acc: 65.61%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 8922/10000, Train Loss: 0.6180, Train Acc: 64.74%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 8923/10000, Train Loss: 0.6117, Train Acc: 65.32%, Test Loss: 0.5607, Test Acc: 68.97%\n",
            "Epoch 8924/10000, Train Loss: 0.6185, Train Acc: 66.76%, Test Loss: 0.5630, Test Acc: 68.97%\n",
            "Epoch 8925/10000, Train Loss: 0.6249, Train Acc: 64.45%, Test Loss: 0.5587, Test Acc: 74.14%\n",
            "Epoch 8926/10000, Train Loss: 0.5938, Train Acc: 67.05%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 8927/10000, Train Loss: 0.6164, Train Acc: 64.16%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 8928/10000, Train Loss: 0.6090, Train Acc: 63.29%, Test Loss: 0.5489, Test Acc: 74.14%\n",
            "Epoch 8929/10000, Train Loss: 0.5933, Train Acc: 67.92%, Test Loss: 0.5491, Test Acc: 72.41%\n",
            "Epoch 8930/10000, Train Loss: 0.6200, Train Acc: 65.32%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 8931/10000, Train Loss: 0.6149, Train Acc: 66.76%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 8932/10000, Train Loss: 0.6290, Train Acc: 64.45%, Test Loss: 0.5502, Test Acc: 68.97%\n",
            "Epoch 8933/10000, Train Loss: 0.6136, Train Acc: 62.72%, Test Loss: 0.5484, Test Acc: 70.69%\n",
            "Epoch 8934/10000, Train Loss: 0.5990, Train Acc: 65.32%, Test Loss: 0.5510, Test Acc: 68.97%\n",
            "Epoch 8935/10000, Train Loss: 0.5963, Train Acc: 64.45%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 8936/10000, Train Loss: 0.6273, Train Acc: 63.58%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 8937/10000, Train Loss: 0.6216, Train Acc: 65.03%, Test Loss: 0.5571, Test Acc: 70.69%\n",
            "Epoch 8938/10000, Train Loss: 0.6296, Train Acc: 64.74%, Test Loss: 0.5563, Test Acc: 70.69%\n",
            "Epoch 8939/10000, Train Loss: 0.6136, Train Acc: 63.29%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 8940/10000, Train Loss: 0.6416, Train Acc: 62.72%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 8941/10000, Train Loss: 0.5853, Train Acc: 68.79%, Test Loss: 0.5617, Test Acc: 70.69%\n",
            "Epoch 8942/10000, Train Loss: 0.6192, Train Acc: 62.72%, Test Loss: 0.5724, Test Acc: 68.97%\n",
            "Epoch 8943/10000, Train Loss: 0.6004, Train Acc: 68.79%, Test Loss: 0.5757, Test Acc: 68.97%\n",
            "Epoch 8944/10000, Train Loss: 0.5980, Train Acc: 65.90%, Test Loss: 0.5648, Test Acc: 68.97%\n",
            "Epoch 8945/10000, Train Loss: 0.6066, Train Acc: 64.45%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 8946/10000, Train Loss: 0.6350, Train Acc: 63.87%, Test Loss: 0.5541, Test Acc: 74.14%\n",
            "Epoch 8947/10000, Train Loss: 0.6040, Train Acc: 65.61%, Test Loss: 0.5577, Test Acc: 74.14%\n",
            "Epoch 8948/10000, Train Loss: 0.6214, Train Acc: 66.47%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 8949/10000, Train Loss: 0.6394, Train Acc: 63.87%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 8950/10000, Train Loss: 0.5892, Train Acc: 65.03%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 8951/10000, Train Loss: 0.5876, Train Acc: 65.61%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 8952/10000, Train Loss: 0.6123, Train Acc: 63.29%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 8953/10000, Train Loss: 0.6029, Train Acc: 65.61%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 8954/10000, Train Loss: 0.6085, Train Acc: 67.63%, Test Loss: 0.5565, Test Acc: 72.41%\n",
            "Epoch 8955/10000, Train Loss: 0.6153, Train Acc: 66.47%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 8956/10000, Train Loss: 0.6260, Train Acc: 64.16%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 8957/10000, Train Loss: 0.6131, Train Acc: 64.16%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 8958/10000, Train Loss: 0.5832, Train Acc: 65.61%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 8959/10000, Train Loss: 0.6270, Train Acc: 65.03%, Test Loss: 0.5591, Test Acc: 70.69%\n",
            "Epoch 8960/10000, Train Loss: 0.6170, Train Acc: 65.32%, Test Loss: 0.5614, Test Acc: 70.69%\n",
            "Epoch 8961/10000, Train Loss: 0.6094, Train Acc: 65.03%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 8962/10000, Train Loss: 0.6012, Train Acc: 67.34%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 8963/10000, Train Loss: 0.6060, Train Acc: 63.01%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 8964/10000, Train Loss: 0.5876, Train Acc: 67.05%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 8965/10000, Train Loss: 0.6192, Train Acc: 62.72%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 8966/10000, Train Loss: 0.6188, Train Acc: 63.29%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 8967/10000, Train Loss: 0.6257, Train Acc: 62.72%, Test Loss: 0.5592, Test Acc: 72.41%\n",
            "Epoch 8968/10000, Train Loss: 0.6048, Train Acc: 67.05%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 8969/10000, Train Loss: 0.6196, Train Acc: 67.63%, Test Loss: 0.5568, Test Acc: 72.41%\n",
            "Epoch 8970/10000, Train Loss: 0.5942, Train Acc: 67.63%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 8971/10000, Train Loss: 0.6026, Train Acc: 66.76%, Test Loss: 0.5587, Test Acc: 72.41%\n",
            "Epoch 8972/10000, Train Loss: 0.6109, Train Acc: 64.45%, Test Loss: 0.5535, Test Acc: 74.14%\n",
            "Epoch 8973/10000, Train Loss: 0.6119, Train Acc: 63.01%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 8974/10000, Train Loss: 0.6047, Train Acc: 65.03%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 8975/10000, Train Loss: 0.6519, Train Acc: 65.61%, Test Loss: 0.5573, Test Acc: 72.41%\n",
            "Epoch 8976/10000, Train Loss: 0.6112, Train Acc: 64.16%, Test Loss: 0.5565, Test Acc: 72.41%\n",
            "Epoch 8977/10000, Train Loss: 0.6193, Train Acc: 66.18%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 8978/10000, Train Loss: 0.6109, Train Acc: 66.76%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 8979/10000, Train Loss: 0.6209, Train Acc: 61.56%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 8980/10000, Train Loss: 0.6200, Train Acc: 62.72%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 8981/10000, Train Loss: 0.6241, Train Acc: 65.61%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 8982/10000, Train Loss: 0.5949, Train Acc: 67.63%, Test Loss: 0.5638, Test Acc: 70.69%\n",
            "Epoch 8983/10000, Train Loss: 0.6172, Train Acc: 65.03%, Test Loss: 0.5679, Test Acc: 68.97%\n",
            "Epoch 8984/10000, Train Loss: 0.6167, Train Acc: 67.05%, Test Loss: 0.5683, Test Acc: 68.97%\n",
            "Epoch 8985/10000, Train Loss: 0.6220, Train Acc: 66.76%, Test Loss: 0.5643, Test Acc: 68.97%\n",
            "Epoch 8986/10000, Train Loss: 0.6333, Train Acc: 64.74%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 8987/10000, Train Loss: 0.6113, Train Acc: 64.45%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 8988/10000, Train Loss: 0.6048, Train Acc: 64.16%, Test Loss: 0.5577, Test Acc: 74.14%\n",
            "Epoch 8989/10000, Train Loss: 0.6055, Train Acc: 65.03%, Test Loss: 0.5608, Test Acc: 70.69%\n",
            "Epoch 8990/10000, Train Loss: 0.6088, Train Acc: 67.05%, Test Loss: 0.5639, Test Acc: 74.14%\n",
            "Epoch 8991/10000, Train Loss: 0.6149, Train Acc: 63.01%, Test Loss: 0.5596, Test Acc: 74.14%\n",
            "Epoch 8992/10000, Train Loss: 0.6002, Train Acc: 68.21%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 8993/10000, Train Loss: 0.6111, Train Acc: 64.16%, Test Loss: 0.5582, Test Acc: 70.69%\n",
            "Epoch 8994/10000, Train Loss: 0.5949, Train Acc: 65.32%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 8995/10000, Train Loss: 0.6122, Train Acc: 66.18%, Test Loss: 0.5568, Test Acc: 72.41%\n",
            "Epoch 8996/10000, Train Loss: 0.6296, Train Acc: 61.85%, Test Loss: 0.5572, Test Acc: 72.41%\n",
            "Epoch 8997/10000, Train Loss: 0.5932, Train Acc: 65.90%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 8998/10000, Train Loss: 0.6252, Train Acc: 66.47%, Test Loss: 0.5523, Test Acc: 74.14%\n",
            "Epoch 8999/10000, Train Loss: 0.6114, Train Acc: 66.47%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 9000/10000, Train Loss: 0.6083, Train Acc: 63.58%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 9001/10000, Train Loss: 0.6160, Train Acc: 63.58%, Test Loss: 0.5579, Test Acc: 72.41%\n",
            "Epoch 9002/10000, Train Loss: 0.6181, Train Acc: 65.03%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 9003/10000, Train Loss: 0.6084, Train Acc: 70.23%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 9004/10000, Train Loss: 0.6133, Train Acc: 64.74%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9005/10000, Train Loss: 0.6175, Train Acc: 66.47%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 9006/10000, Train Loss: 0.6252, Train Acc: 65.61%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 9007/10000, Train Loss: 0.6098, Train Acc: 62.43%, Test Loss: 0.5647, Test Acc: 70.69%\n",
            "Epoch 9008/10000, Train Loss: 0.6253, Train Acc: 67.34%, Test Loss: 0.5647, Test Acc: 68.97%\n",
            "Epoch 9009/10000, Train Loss: 0.6191, Train Acc: 66.47%, Test Loss: 0.5643, Test Acc: 67.24%\n",
            "Epoch 9010/10000, Train Loss: 0.6193, Train Acc: 67.34%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 9011/10000, Train Loss: 0.6209, Train Acc: 63.01%, Test Loss: 0.5542, Test Acc: 74.14%\n",
            "Epoch 9012/10000, Train Loss: 0.6141, Train Acc: 66.76%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 9013/10000, Train Loss: 0.6151, Train Acc: 65.32%, Test Loss: 0.5523, Test Acc: 72.41%\n",
            "Epoch 9014/10000, Train Loss: 0.6071, Train Acc: 65.32%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 9015/10000, Train Loss: 0.5978, Train Acc: 64.45%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 9016/10000, Train Loss: 0.6199, Train Acc: 62.43%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 9017/10000, Train Loss: 0.6280, Train Acc: 63.58%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 9018/10000, Train Loss: 0.6112, Train Acc: 63.29%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 9019/10000, Train Loss: 0.5970, Train Acc: 67.05%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 9020/10000, Train Loss: 0.6159, Train Acc: 61.56%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 9021/10000, Train Loss: 0.6100, Train Acc: 65.90%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 9022/10000, Train Loss: 0.6124, Train Acc: 62.72%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 9023/10000, Train Loss: 0.6193, Train Acc: 65.32%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 9024/10000, Train Loss: 0.5844, Train Acc: 66.18%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 9025/10000, Train Loss: 0.6245, Train Acc: 66.76%, Test Loss: 0.5600, Test Acc: 68.97%\n",
            "Epoch 9026/10000, Train Loss: 0.6098, Train Acc: 65.32%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 9027/10000, Train Loss: 0.6157, Train Acc: 66.18%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 9028/10000, Train Loss: 0.6118, Train Acc: 67.34%, Test Loss: 0.5578, Test Acc: 72.41%\n",
            "Epoch 9029/10000, Train Loss: 0.5913, Train Acc: 67.63%, Test Loss: 0.5550, Test Acc: 74.14%\n",
            "Epoch 9030/10000, Train Loss: 0.6096, Train Acc: 60.12%, Test Loss: 0.5554, Test Acc: 74.14%\n",
            "Epoch 9031/10000, Train Loss: 0.6269, Train Acc: 66.18%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 9032/10000, Train Loss: 0.6162, Train Acc: 66.76%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 9033/10000, Train Loss: 0.6040, Train Acc: 68.50%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 9034/10000, Train Loss: 0.6171, Train Acc: 67.34%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 9035/10000, Train Loss: 0.5968, Train Acc: 68.50%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 9036/10000, Train Loss: 0.5919, Train Acc: 62.43%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 9037/10000, Train Loss: 0.6033, Train Acc: 66.76%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 9038/10000, Train Loss: 0.5903, Train Acc: 64.45%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 9039/10000, Train Loss: 0.6146, Train Acc: 62.14%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 9040/10000, Train Loss: 0.6268, Train Acc: 61.85%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 9041/10000, Train Loss: 0.6265, Train Acc: 66.76%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 9042/10000, Train Loss: 0.5997, Train Acc: 66.47%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9043/10000, Train Loss: 0.6110, Train Acc: 64.45%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 9044/10000, Train Loss: 0.6393, Train Acc: 62.72%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 9045/10000, Train Loss: 0.6277, Train Acc: 64.74%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 9046/10000, Train Loss: 0.6048, Train Acc: 65.32%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9047/10000, Train Loss: 0.6119, Train Acc: 63.58%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 9048/10000, Train Loss: 0.5932, Train Acc: 67.34%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 9049/10000, Train Loss: 0.6303, Train Acc: 61.56%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 9050/10000, Train Loss: 0.6056, Train Acc: 62.43%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 9051/10000, Train Loss: 0.6057, Train Acc: 65.61%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 9052/10000, Train Loss: 0.6129, Train Acc: 63.29%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 9053/10000, Train Loss: 0.6006, Train Acc: 64.16%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 9054/10000, Train Loss: 0.6075, Train Acc: 68.21%, Test Loss: 0.5566, Test Acc: 72.41%\n",
            "Epoch 9055/10000, Train Loss: 0.6275, Train Acc: 62.72%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 9056/10000, Train Loss: 0.6052, Train Acc: 66.47%, Test Loss: 0.5507, Test Acc: 70.69%\n",
            "Epoch 9057/10000, Train Loss: 0.6146, Train Acc: 67.05%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 9058/10000, Train Loss: 0.6144, Train Acc: 67.05%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 9059/10000, Train Loss: 0.6127, Train Acc: 66.18%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9060/10000, Train Loss: 0.6117, Train Acc: 67.05%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 9061/10000, Train Loss: 0.6206, Train Acc: 62.43%, Test Loss: 0.5593, Test Acc: 68.97%\n",
            "Epoch 9062/10000, Train Loss: 0.6389, Train Acc: 64.16%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 9063/10000, Train Loss: 0.6040, Train Acc: 67.05%, Test Loss: 0.5503, Test Acc: 70.69%\n",
            "Epoch 9064/10000, Train Loss: 0.5919, Train Acc: 65.61%, Test Loss: 0.5520, Test Acc: 70.69%\n",
            "Epoch 9065/10000, Train Loss: 0.6182, Train Acc: 62.14%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 9066/10000, Train Loss: 0.6084, Train Acc: 66.18%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 9067/10000, Train Loss: 0.6187, Train Acc: 65.03%, Test Loss: 0.5584, Test Acc: 72.41%\n",
            "Epoch 9068/10000, Train Loss: 0.6173, Train Acc: 64.74%, Test Loss: 0.5520, Test Acc: 70.69%\n",
            "Epoch 9069/10000, Train Loss: 0.6205, Train Acc: 65.90%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 9070/10000, Train Loss: 0.6189, Train Acc: 64.74%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 9071/10000, Train Loss: 0.6214, Train Acc: 64.74%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 9072/10000, Train Loss: 0.6086, Train Acc: 64.45%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 9073/10000, Train Loss: 0.5952, Train Acc: 66.18%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 9074/10000, Train Loss: 0.5978, Train Acc: 66.47%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 9075/10000, Train Loss: 0.6072, Train Acc: 67.05%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 9076/10000, Train Loss: 0.6003, Train Acc: 66.18%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 9077/10000, Train Loss: 0.6238, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 9078/10000, Train Loss: 0.6135, Train Acc: 62.72%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9079/10000, Train Loss: 0.6092, Train Acc: 67.34%, Test Loss: 0.5533, Test Acc: 68.97%\n",
            "Epoch 9080/10000, Train Loss: 0.5769, Train Acc: 67.05%, Test Loss: 0.5560, Test Acc: 70.69%\n",
            "Epoch 9081/10000, Train Loss: 0.5986, Train Acc: 66.47%, Test Loss: 0.5586, Test Acc: 70.69%\n",
            "Epoch 9082/10000, Train Loss: 0.6126, Train Acc: 61.27%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 9083/10000, Train Loss: 0.6299, Train Acc: 65.90%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 9084/10000, Train Loss: 0.6256, Train Acc: 64.45%, Test Loss: 0.5550, Test Acc: 75.86%\n",
            "Epoch 9085/10000, Train Loss: 0.5928, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 75.86%\n",
            "Epoch 9086/10000, Train Loss: 0.6063, Train Acc: 64.16%, Test Loss: 0.5516, Test Acc: 75.86%\n",
            "Epoch 9087/10000, Train Loss: 0.5805, Train Acc: 66.18%, Test Loss: 0.5502, Test Acc: 74.14%\n",
            "Epoch 9088/10000, Train Loss: 0.5959, Train Acc: 63.58%, Test Loss: 0.5497, Test Acc: 72.41%\n",
            "Epoch 9089/10000, Train Loss: 0.6040, Train Acc: 63.01%, Test Loss: 0.5495, Test Acc: 70.69%\n",
            "Epoch 9090/10000, Train Loss: 0.6061, Train Acc: 65.90%, Test Loss: 0.5484, Test Acc: 67.24%\n",
            "Epoch 9091/10000, Train Loss: 0.6244, Train Acc: 64.16%, Test Loss: 0.5487, Test Acc: 70.69%\n",
            "Epoch 9092/10000, Train Loss: 0.6283, Train Acc: 62.43%, Test Loss: 0.5513, Test Acc: 70.69%\n",
            "Epoch 9093/10000, Train Loss: 0.6093, Train Acc: 65.90%, Test Loss: 0.5628, Test Acc: 70.69%\n",
            "Epoch 9094/10000, Train Loss: 0.6064, Train Acc: 65.03%, Test Loss: 0.5628, Test Acc: 70.69%\n",
            "Epoch 9095/10000, Train Loss: 0.6333, Train Acc: 60.40%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 9096/10000, Train Loss: 0.5968, Train Acc: 63.58%, Test Loss: 0.5507, Test Acc: 70.69%\n",
            "Epoch 9097/10000, Train Loss: 0.5868, Train Acc: 62.72%, Test Loss: 0.5477, Test Acc: 70.69%\n",
            "Epoch 9098/10000, Train Loss: 0.6239, Train Acc: 64.16%, Test Loss: 0.5495, Test Acc: 70.69%\n",
            "Epoch 9099/10000, Train Loss: 0.6320, Train Acc: 63.58%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 9100/10000, Train Loss: 0.6071, Train Acc: 60.98%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 9101/10000, Train Loss: 0.6248, Train Acc: 65.32%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 9102/10000, Train Loss: 0.6093, Train Acc: 66.76%, Test Loss: 0.5498, Test Acc: 70.69%\n",
            "Epoch 9103/10000, Train Loss: 0.6015, Train Acc: 65.03%, Test Loss: 0.5505, Test Acc: 70.69%\n",
            "Epoch 9104/10000, Train Loss: 0.6069, Train Acc: 67.92%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9105/10000, Train Loss: 0.5905, Train Acc: 67.63%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 9106/10000, Train Loss: 0.6174, Train Acc: 62.43%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9107/10000, Train Loss: 0.5759, Train Acc: 66.47%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9108/10000, Train Loss: 0.6087, Train Acc: 65.61%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 9109/10000, Train Loss: 0.6096, Train Acc: 62.43%, Test Loss: 0.5602, Test Acc: 70.69%\n",
            "Epoch 9110/10000, Train Loss: 0.6267, Train Acc: 63.29%, Test Loss: 0.5618, Test Acc: 72.41%\n",
            "Epoch 9111/10000, Train Loss: 0.6314, Train Acc: 64.74%, Test Loss: 0.5674, Test Acc: 72.41%\n",
            "Epoch 9112/10000, Train Loss: 0.6285, Train Acc: 64.45%, Test Loss: 0.5653, Test Acc: 72.41%\n",
            "Epoch 9113/10000, Train Loss: 0.6209, Train Acc: 60.69%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 9114/10000, Train Loss: 0.6263, Train Acc: 64.74%, Test Loss: 0.5521, Test Acc: 72.41%\n",
            "Epoch 9115/10000, Train Loss: 0.6117, Train Acc: 64.16%, Test Loss: 0.5487, Test Acc: 75.86%\n",
            "Epoch 9116/10000, Train Loss: 0.6179, Train Acc: 64.74%, Test Loss: 0.5475, Test Acc: 75.86%\n",
            "Epoch 9117/10000, Train Loss: 0.6176, Train Acc: 66.47%, Test Loss: 0.5465, Test Acc: 72.41%\n",
            "Epoch 9118/10000, Train Loss: 0.6049, Train Acc: 63.58%, Test Loss: 0.5504, Test Acc: 68.97%\n",
            "Epoch 9119/10000, Train Loss: 0.5973, Train Acc: 67.92%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 9120/10000, Train Loss: 0.6067, Train Acc: 64.74%, Test Loss: 0.5584, Test Acc: 70.69%\n",
            "Epoch 9121/10000, Train Loss: 0.6109, Train Acc: 63.29%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 9122/10000, Train Loss: 0.6043, Train Acc: 63.01%, Test Loss: 0.5619, Test Acc: 70.69%\n",
            "Epoch 9123/10000, Train Loss: 0.5977, Train Acc: 64.45%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 9124/10000, Train Loss: 0.6035, Train Acc: 62.72%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 9125/10000, Train Loss: 0.5909, Train Acc: 65.61%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 9126/10000, Train Loss: 0.6017, Train Acc: 65.61%, Test Loss: 0.5550, Test Acc: 74.14%\n",
            "Epoch 9127/10000, Train Loss: 0.6408, Train Acc: 64.45%, Test Loss: 0.5582, Test Acc: 72.41%\n",
            "Epoch 9128/10000, Train Loss: 0.6006, Train Acc: 67.63%, Test Loss: 0.5515, Test Acc: 72.41%\n",
            "Epoch 9129/10000, Train Loss: 0.6152, Train Acc: 65.61%, Test Loss: 0.5456, Test Acc: 70.69%\n",
            "Epoch 9130/10000, Train Loss: 0.6148, Train Acc: 63.29%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 9131/10000, Train Loss: 0.6210, Train Acc: 65.61%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 9132/10000, Train Loss: 0.6211, Train Acc: 66.47%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 9133/10000, Train Loss: 0.5831, Train Acc: 69.65%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9134/10000, Train Loss: 0.6154, Train Acc: 65.32%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 9135/10000, Train Loss: 0.6048, Train Acc: 65.90%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 9136/10000, Train Loss: 0.6117, Train Acc: 65.32%, Test Loss: 0.5592, Test Acc: 70.69%\n",
            "Epoch 9137/10000, Train Loss: 0.6111, Train Acc: 66.18%, Test Loss: 0.5649, Test Acc: 68.97%\n",
            "Epoch 9138/10000, Train Loss: 0.6028, Train Acc: 67.05%, Test Loss: 0.5631, Test Acc: 70.69%\n",
            "Epoch 9139/10000, Train Loss: 0.6308, Train Acc: 63.58%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 9140/10000, Train Loss: 0.6009, Train Acc: 69.36%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 9141/10000, Train Loss: 0.6002, Train Acc: 67.05%, Test Loss: 0.5535, Test Acc: 72.41%\n",
            "Epoch 9142/10000, Train Loss: 0.6437, Train Acc: 59.54%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 9143/10000, Train Loss: 0.6028, Train Acc: 65.32%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 9144/10000, Train Loss: 0.6201, Train Acc: 63.29%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 9145/10000, Train Loss: 0.5903, Train Acc: 69.08%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 9146/10000, Train Loss: 0.6180, Train Acc: 63.29%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 9147/10000, Train Loss: 0.6119, Train Acc: 65.90%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 9148/10000, Train Loss: 0.6032, Train Acc: 63.58%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 9149/10000, Train Loss: 0.6108, Train Acc: 66.76%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 9150/10000, Train Loss: 0.6078, Train Acc: 66.76%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 9151/10000, Train Loss: 0.6189, Train Acc: 62.14%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 9152/10000, Train Loss: 0.6069, Train Acc: 64.74%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 9153/10000, Train Loss: 0.6208, Train Acc: 62.43%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 9154/10000, Train Loss: 0.6084, Train Acc: 65.03%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 9155/10000, Train Loss: 0.6199, Train Acc: 61.85%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 9156/10000, Train Loss: 0.6030, Train Acc: 65.32%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 9157/10000, Train Loss: 0.5997, Train Acc: 65.61%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 9158/10000, Train Loss: 0.6211, Train Acc: 64.74%, Test Loss: 0.5496, Test Acc: 70.69%\n",
            "Epoch 9159/10000, Train Loss: 0.5898, Train Acc: 65.03%, Test Loss: 0.5509, Test Acc: 68.97%\n",
            "Epoch 9160/10000, Train Loss: 0.6075, Train Acc: 63.87%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9161/10000, Train Loss: 0.6069, Train Acc: 63.87%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 9162/10000, Train Loss: 0.5856, Train Acc: 65.32%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 9163/10000, Train Loss: 0.6161, Train Acc: 66.18%, Test Loss: 0.5511, Test Acc: 68.97%\n",
            "Epoch 9164/10000, Train Loss: 0.6053, Train Acc: 67.05%, Test Loss: 0.5483, Test Acc: 72.41%\n",
            "Epoch 9165/10000, Train Loss: 0.6174, Train Acc: 63.58%, Test Loss: 0.5502, Test Acc: 72.41%\n",
            "Epoch 9166/10000, Train Loss: 0.6288, Train Acc: 63.01%, Test Loss: 0.5510, Test Acc: 72.41%\n",
            "Epoch 9167/10000, Train Loss: 0.6162, Train Acc: 65.03%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 9168/10000, Train Loss: 0.6050, Train Acc: 65.32%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 9169/10000, Train Loss: 0.6338, Train Acc: 63.87%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 9170/10000, Train Loss: 0.6106, Train Acc: 66.47%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 9171/10000, Train Loss: 0.6214, Train Acc: 67.63%, Test Loss: 0.5592, Test Acc: 72.41%\n",
            "Epoch 9172/10000, Train Loss: 0.6093, Train Acc: 67.34%, Test Loss: 0.5566, Test Acc: 70.69%\n",
            "Epoch 9173/10000, Train Loss: 0.5948, Train Acc: 65.03%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 9174/10000, Train Loss: 0.6189, Train Acc: 65.03%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 9175/10000, Train Loss: 0.5918, Train Acc: 63.87%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 9176/10000, Train Loss: 0.6265, Train Acc: 65.61%, Test Loss: 0.5515, Test Acc: 72.41%\n",
            "Epoch 9177/10000, Train Loss: 0.6253, Train Acc: 66.76%, Test Loss: 0.5490, Test Acc: 72.41%\n",
            "Epoch 9178/10000, Train Loss: 0.6102, Train Acc: 66.47%, Test Loss: 0.5507, Test Acc: 72.41%\n",
            "Epoch 9179/10000, Train Loss: 0.6238, Train Acc: 62.72%, Test Loss: 0.5525, Test Acc: 72.41%\n",
            "Epoch 9180/10000, Train Loss: 0.6076, Train Acc: 66.76%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 9181/10000, Train Loss: 0.6148, Train Acc: 66.47%, Test Loss: 0.5507, Test Acc: 72.41%\n",
            "Epoch 9182/10000, Train Loss: 0.6718, Train Acc: 63.58%, Test Loss: 0.5462, Test Acc: 72.41%\n",
            "Epoch 9183/10000, Train Loss: 0.6061, Train Acc: 63.58%, Test Loss: 0.5489, Test Acc: 72.41%\n",
            "Epoch 9184/10000, Train Loss: 0.6196, Train Acc: 64.16%, Test Loss: 0.5527, Test Acc: 70.69%\n",
            "Epoch 9185/10000, Train Loss: 0.6083, Train Acc: 61.56%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 9186/10000, Train Loss: 0.6008, Train Acc: 66.76%, Test Loss: 0.5524, Test Acc: 70.69%\n",
            "Epoch 9187/10000, Train Loss: 0.6183, Train Acc: 66.47%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 9188/10000, Train Loss: 0.5994, Train Acc: 65.03%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 9189/10000, Train Loss: 0.6016, Train Acc: 65.32%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 9190/10000, Train Loss: 0.5992, Train Acc: 61.56%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9191/10000, Train Loss: 0.6060, Train Acc: 66.18%, Test Loss: 0.5521, Test Acc: 72.41%\n",
            "Epoch 9192/10000, Train Loss: 0.6071, Train Acc: 65.32%, Test Loss: 0.5516, Test Acc: 70.69%\n",
            "Epoch 9193/10000, Train Loss: 0.6199, Train Acc: 65.90%, Test Loss: 0.5519, Test Acc: 70.69%\n",
            "Epoch 9194/10000, Train Loss: 0.6071, Train Acc: 64.74%, Test Loss: 0.5515, Test Acc: 70.69%\n",
            "Epoch 9195/10000, Train Loss: 0.6215, Train Acc: 61.27%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9196/10000, Train Loss: 0.6243, Train Acc: 65.32%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 9197/10000, Train Loss: 0.6074, Train Acc: 65.90%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 9198/10000, Train Loss: 0.5892, Train Acc: 65.61%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 9199/10000, Train Loss: 0.6332, Train Acc: 64.16%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 9200/10000, Train Loss: 0.5818, Train Acc: 70.23%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 9201/10000, Train Loss: 0.6263, Train Acc: 63.58%, Test Loss: 0.5600, Test Acc: 68.97%\n",
            "Epoch 9202/10000, Train Loss: 0.6199, Train Acc: 64.16%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 9203/10000, Train Loss: 0.6190, Train Acc: 67.34%, Test Loss: 0.5535, Test Acc: 74.14%\n",
            "Epoch 9204/10000, Train Loss: 0.5918, Train Acc: 66.76%, Test Loss: 0.5536, Test Acc: 74.14%\n",
            "Epoch 9205/10000, Train Loss: 0.6082, Train Acc: 65.61%, Test Loss: 0.5497, Test Acc: 72.41%\n",
            "Epoch 9206/10000, Train Loss: 0.6192, Train Acc: 65.03%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 9207/10000, Train Loss: 0.6207, Train Acc: 63.87%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 9208/10000, Train Loss: 0.6182, Train Acc: 62.43%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 9209/10000, Train Loss: 0.6298, Train Acc: 61.56%, Test Loss: 0.5544, Test Acc: 72.41%\n",
            "Epoch 9210/10000, Train Loss: 0.5866, Train Acc: 67.05%, Test Loss: 0.5540, Test Acc: 70.69%\n",
            "Epoch 9211/10000, Train Loss: 0.6372, Train Acc: 62.14%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 9212/10000, Train Loss: 0.6051, Train Acc: 64.45%, Test Loss: 0.5464, Test Acc: 74.14%\n",
            "Epoch 9213/10000, Train Loss: 0.5973, Train Acc: 66.18%, Test Loss: 0.5418, Test Acc: 68.97%\n",
            "Epoch 9214/10000, Train Loss: 0.6264, Train Acc: 67.63%, Test Loss: 0.5452, Test Acc: 72.41%\n",
            "Epoch 9215/10000, Train Loss: 0.6005, Train Acc: 66.76%, Test Loss: 0.5457, Test Acc: 70.69%\n",
            "Epoch 9216/10000, Train Loss: 0.6290, Train Acc: 65.03%, Test Loss: 0.5521, Test Acc: 70.69%\n",
            "Epoch 9217/10000, Train Loss: 0.6015, Train Acc: 65.90%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 9218/10000, Train Loss: 0.6414, Train Acc: 61.27%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 9219/10000, Train Loss: 0.6316, Train Acc: 64.16%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 9220/10000, Train Loss: 0.5897, Train Acc: 67.34%, Test Loss: 0.5575, Test Acc: 70.69%\n",
            "Epoch 9221/10000, Train Loss: 0.6162, Train Acc: 67.92%, Test Loss: 0.5623, Test Acc: 70.69%\n",
            "Epoch 9222/10000, Train Loss: 0.6199, Train Acc: 65.03%, Test Loss: 0.5604, Test Acc: 70.69%\n",
            "Epoch 9223/10000, Train Loss: 0.6187, Train Acc: 65.90%, Test Loss: 0.5630, Test Acc: 70.69%\n",
            "Epoch 9224/10000, Train Loss: 0.6147, Train Acc: 65.61%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 9225/10000, Train Loss: 0.6020, Train Acc: 64.16%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 9226/10000, Train Loss: 0.5945, Train Acc: 64.16%, Test Loss: 0.5506, Test Acc: 74.14%\n",
            "Epoch 9227/10000, Train Loss: 0.6145, Train Acc: 64.45%, Test Loss: 0.5504, Test Acc: 72.41%\n",
            "Epoch 9228/10000, Train Loss: 0.6138, Train Acc: 59.83%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 9229/10000, Train Loss: 0.5937, Train Acc: 63.29%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 9230/10000, Train Loss: 0.5918, Train Acc: 68.79%, Test Loss: 0.5497, Test Acc: 72.41%\n",
            "Epoch 9231/10000, Train Loss: 0.5945, Train Acc: 63.87%, Test Loss: 0.5493, Test Acc: 70.69%\n",
            "Epoch 9232/10000, Train Loss: 0.5988, Train Acc: 66.47%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 9233/10000, Train Loss: 0.6058, Train Acc: 67.05%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 9234/10000, Train Loss: 0.6257, Train Acc: 64.16%, Test Loss: 0.5521, Test Acc: 70.69%\n",
            "Epoch 9235/10000, Train Loss: 0.5980, Train Acc: 64.74%, Test Loss: 0.5481, Test Acc: 70.69%\n",
            "Epoch 9236/10000, Train Loss: 0.5883, Train Acc: 66.76%, Test Loss: 0.5484, Test Acc: 70.69%\n",
            "Epoch 9237/10000, Train Loss: 0.6213, Train Acc: 64.45%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 9238/10000, Train Loss: 0.6137, Train Acc: 64.16%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 9239/10000, Train Loss: 0.6208, Train Acc: 63.58%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 9240/10000, Train Loss: 0.6143, Train Acc: 63.29%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 9241/10000, Train Loss: 0.6173, Train Acc: 63.29%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 9242/10000, Train Loss: 0.6085, Train Acc: 65.61%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 9243/10000, Train Loss: 0.6366, Train Acc: 65.32%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 9244/10000, Train Loss: 0.6141, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 9245/10000, Train Loss: 0.6417, Train Acc: 66.47%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 9246/10000, Train Loss: 0.6124, Train Acc: 63.87%, Test Loss: 0.5597, Test Acc: 72.41%\n",
            "Epoch 9247/10000, Train Loss: 0.6170, Train Acc: 62.72%, Test Loss: 0.5630, Test Acc: 70.69%\n",
            "Epoch 9248/10000, Train Loss: 0.5880, Train Acc: 67.34%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 9249/10000, Train Loss: 0.6110, Train Acc: 65.61%, Test Loss: 0.5558, Test Acc: 72.41%\n",
            "Epoch 9250/10000, Train Loss: 0.5973, Train Acc: 61.85%, Test Loss: 0.5554, Test Acc: 72.41%\n",
            "Epoch 9251/10000, Train Loss: 0.6070, Train Acc: 66.76%, Test Loss: 0.5609, Test Acc: 72.41%\n",
            "Epoch 9252/10000, Train Loss: 0.6044, Train Acc: 63.29%, Test Loss: 0.5599, Test Acc: 68.97%\n",
            "Epoch 9253/10000, Train Loss: 0.5820, Train Acc: 66.76%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 9254/10000, Train Loss: 0.6154, Train Acc: 63.58%, Test Loss: 0.5581, Test Acc: 70.69%\n",
            "Epoch 9255/10000, Train Loss: 0.6137, Train Acc: 66.18%, Test Loss: 0.5585, Test Acc: 70.69%\n",
            "Epoch 9256/10000, Train Loss: 0.6340, Train Acc: 65.32%, Test Loss: 0.5583, Test Acc: 72.41%\n",
            "Epoch 9257/10000, Train Loss: 0.6211, Train Acc: 64.74%, Test Loss: 0.5542, Test Acc: 74.14%\n",
            "Epoch 9258/10000, Train Loss: 0.6306, Train Acc: 63.58%, Test Loss: 0.5546, Test Acc: 74.14%\n",
            "Epoch 9259/10000, Train Loss: 0.6201, Train Acc: 64.45%, Test Loss: 0.5574, Test Acc: 74.14%\n",
            "Epoch 9260/10000, Train Loss: 0.6279, Train Acc: 60.69%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 9261/10000, Train Loss: 0.6221, Train Acc: 63.58%, Test Loss: 0.5527, Test Acc: 74.14%\n",
            "Epoch 9262/10000, Train Loss: 0.6184, Train Acc: 65.90%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 9263/10000, Train Loss: 0.6169, Train Acc: 64.45%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 9264/10000, Train Loss: 0.6453, Train Acc: 67.63%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 9265/10000, Train Loss: 0.6351, Train Acc: 63.87%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 9266/10000, Train Loss: 0.6145, Train Acc: 66.76%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 9267/10000, Train Loss: 0.5959, Train Acc: 62.72%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 9268/10000, Train Loss: 0.6183, Train Acc: 63.01%, Test Loss: 0.5584, Test Acc: 68.97%\n",
            "Epoch 9269/10000, Train Loss: 0.5958, Train Acc: 66.47%, Test Loss: 0.5569, Test Acc: 72.41%\n",
            "Epoch 9270/10000, Train Loss: 0.6063, Train Acc: 64.16%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 9271/10000, Train Loss: 0.6241, Train Acc: 64.16%, Test Loss: 0.5500, Test Acc: 70.69%\n",
            "Epoch 9272/10000, Train Loss: 0.6062, Train Acc: 64.16%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 9273/10000, Train Loss: 0.6167, Train Acc: 69.36%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 9274/10000, Train Loss: 0.6238, Train Acc: 63.01%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 9275/10000, Train Loss: 0.5983, Train Acc: 66.47%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 9276/10000, Train Loss: 0.6150, Train Acc: 64.74%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 9277/10000, Train Loss: 0.6081, Train Acc: 65.61%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 9278/10000, Train Loss: 0.6093, Train Acc: 69.94%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 9279/10000, Train Loss: 0.6307, Train Acc: 65.32%, Test Loss: 0.5550, Test Acc: 70.69%\n",
            "Epoch 9280/10000, Train Loss: 0.6242, Train Acc: 65.03%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 9281/10000, Train Loss: 0.6119, Train Acc: 64.74%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 9282/10000, Train Loss: 0.6171, Train Acc: 63.01%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9283/10000, Train Loss: 0.6150, Train Acc: 64.74%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 9284/10000, Train Loss: 0.5997, Train Acc: 66.18%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 9285/10000, Train Loss: 0.6110, Train Acc: 68.50%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 9286/10000, Train Loss: 0.6279, Train Acc: 64.74%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 9287/10000, Train Loss: 0.6240, Train Acc: 66.18%, Test Loss: 0.5535, Test Acc: 74.14%\n",
            "Epoch 9288/10000, Train Loss: 0.6177, Train Acc: 64.74%, Test Loss: 0.5554, Test Acc: 72.41%\n",
            "Epoch 9289/10000, Train Loss: 0.6159, Train Acc: 64.74%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 9290/10000, Train Loss: 0.6204, Train Acc: 64.16%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 9291/10000, Train Loss: 0.6331, Train Acc: 63.01%, Test Loss: 0.5516, Test Acc: 70.69%\n",
            "Epoch 9292/10000, Train Loss: 0.6137, Train Acc: 64.16%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 9293/10000, Train Loss: 0.5949, Train Acc: 67.05%, Test Loss: 0.5561, Test Acc: 70.69%\n",
            "Epoch 9294/10000, Train Loss: 0.6261, Train Acc: 62.72%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 9295/10000, Train Loss: 0.6358, Train Acc: 62.14%, Test Loss: 0.5517, Test Acc: 70.69%\n",
            "Epoch 9296/10000, Train Loss: 0.6181, Train Acc: 66.18%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 9297/10000, Train Loss: 0.5895, Train Acc: 65.90%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 9298/10000, Train Loss: 0.6368, Train Acc: 64.16%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 9299/10000, Train Loss: 0.6071, Train Acc: 65.32%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 9300/10000, Train Loss: 0.5988, Train Acc: 68.50%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 9301/10000, Train Loss: 0.6185, Train Acc: 64.45%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 9302/10000, Train Loss: 0.6144, Train Acc: 66.18%, Test Loss: 0.5584, Test Acc: 70.69%\n",
            "Epoch 9303/10000, Train Loss: 0.6045, Train Acc: 65.03%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 9304/10000, Train Loss: 0.6282, Train Acc: 63.58%, Test Loss: 0.5594, Test Acc: 72.41%\n",
            "Epoch 9305/10000, Train Loss: 0.6024, Train Acc: 65.03%, Test Loss: 0.5649, Test Acc: 70.69%\n",
            "Epoch 9306/10000, Train Loss: 0.6179, Train Acc: 65.90%, Test Loss: 0.5712, Test Acc: 68.97%\n",
            "Epoch 9307/10000, Train Loss: 0.6016, Train Acc: 67.34%, Test Loss: 0.5684, Test Acc: 67.24%\n",
            "Epoch 9308/10000, Train Loss: 0.5963, Train Acc: 66.47%, Test Loss: 0.5804, Test Acc: 65.52%\n",
            "Epoch 9309/10000, Train Loss: 0.6143, Train Acc: 66.18%, Test Loss: 0.5795, Test Acc: 63.79%\n",
            "Epoch 9310/10000, Train Loss: 0.6246, Train Acc: 65.03%, Test Loss: 0.5590, Test Acc: 70.69%\n",
            "Epoch 9311/10000, Train Loss: 0.5948, Train Acc: 67.34%, Test Loss: 0.5592, Test Acc: 74.14%\n",
            "Epoch 9312/10000, Train Loss: 0.6234, Train Acc: 66.47%, Test Loss: 0.5587, Test Acc: 74.14%\n",
            "Epoch 9313/10000, Train Loss: 0.6213, Train Acc: 66.76%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 9314/10000, Train Loss: 0.6161, Train Acc: 63.01%, Test Loss: 0.5526, Test Acc: 74.14%\n",
            "Epoch 9315/10000, Train Loss: 0.5982, Train Acc: 66.76%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 9316/10000, Train Loss: 0.6148, Train Acc: 63.29%, Test Loss: 0.5546, Test Acc: 72.41%\n",
            "Epoch 9317/10000, Train Loss: 0.6251, Train Acc: 60.12%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 9318/10000, Train Loss: 0.6218, Train Acc: 61.27%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 9319/10000, Train Loss: 0.6083, Train Acc: 63.29%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 9320/10000, Train Loss: 0.5845, Train Acc: 67.63%, Test Loss: 0.5609, Test Acc: 70.69%\n",
            "Epoch 9321/10000, Train Loss: 0.6087, Train Acc: 63.87%, Test Loss: 0.5608, Test Acc: 72.41%\n",
            "Epoch 9322/10000, Train Loss: 0.6171, Train Acc: 65.61%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 9323/10000, Train Loss: 0.6199, Train Acc: 65.61%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 9324/10000, Train Loss: 0.5909, Train Acc: 67.05%, Test Loss: 0.5566, Test Acc: 72.41%\n",
            "Epoch 9325/10000, Train Loss: 0.6175, Train Acc: 66.18%, Test Loss: 0.5523, Test Acc: 72.41%\n",
            "Epoch 9326/10000, Train Loss: 0.6001, Train Acc: 62.72%, Test Loss: 0.5507, Test Acc: 72.41%\n",
            "Epoch 9327/10000, Train Loss: 0.6001, Train Acc: 65.90%, Test Loss: 0.5538, Test Acc: 75.86%\n",
            "Epoch 9328/10000, Train Loss: 0.5941, Train Acc: 65.90%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 9329/10000, Train Loss: 0.6216, Train Acc: 63.58%, Test Loss: 0.5492, Test Acc: 68.97%\n",
            "Epoch 9330/10000, Train Loss: 0.6040, Train Acc: 68.79%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 9331/10000, Train Loss: 0.6022, Train Acc: 67.63%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 9332/10000, Train Loss: 0.6150, Train Acc: 66.47%, Test Loss: 0.5516, Test Acc: 68.97%\n",
            "Epoch 9333/10000, Train Loss: 0.6246, Train Acc: 63.01%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9334/10000, Train Loss: 0.6171, Train Acc: 62.14%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9335/10000, Train Loss: 0.6317, Train Acc: 62.72%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 9336/10000, Train Loss: 0.6267, Train Acc: 63.58%, Test Loss: 0.5509, Test Acc: 70.69%\n",
            "Epoch 9337/10000, Train Loss: 0.6227, Train Acc: 63.58%, Test Loss: 0.5506, Test Acc: 70.69%\n",
            "Epoch 9338/10000, Train Loss: 0.6196, Train Acc: 62.43%, Test Loss: 0.5512, Test Acc: 72.41%\n",
            "Epoch 9339/10000, Train Loss: 0.6145, Train Acc: 64.16%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 9340/10000, Train Loss: 0.6014, Train Acc: 61.27%, Test Loss: 0.5494, Test Acc: 70.69%\n",
            "Epoch 9341/10000, Train Loss: 0.6185, Train Acc: 63.01%, Test Loss: 0.5497, Test Acc: 68.97%\n",
            "Epoch 9342/10000, Train Loss: 0.6331, Train Acc: 63.01%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 9343/10000, Train Loss: 0.6300, Train Acc: 64.16%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 9344/10000, Train Loss: 0.6256, Train Acc: 64.45%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9345/10000, Train Loss: 0.6111, Train Acc: 63.58%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 9346/10000, Train Loss: 0.6216, Train Acc: 63.01%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 9347/10000, Train Loss: 0.6202, Train Acc: 64.45%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 9348/10000, Train Loss: 0.6245, Train Acc: 65.03%, Test Loss: 0.5506, Test Acc: 72.41%\n",
            "Epoch 9349/10000, Train Loss: 0.5983, Train Acc: 67.63%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 9350/10000, Train Loss: 0.6084, Train Acc: 66.18%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 9351/10000, Train Loss: 0.6045, Train Acc: 64.74%, Test Loss: 0.5624, Test Acc: 70.69%\n",
            "Epoch 9352/10000, Train Loss: 0.6079, Train Acc: 66.47%, Test Loss: 0.5603, Test Acc: 72.41%\n",
            "Epoch 9353/10000, Train Loss: 0.6042, Train Acc: 63.29%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 9354/10000, Train Loss: 0.6179, Train Acc: 65.61%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 9355/10000, Train Loss: 0.6139, Train Acc: 62.43%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 9356/10000, Train Loss: 0.5946, Train Acc: 65.61%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 9357/10000, Train Loss: 0.6153, Train Acc: 61.85%, Test Loss: 0.5484, Test Acc: 72.41%\n",
            "Epoch 9358/10000, Train Loss: 0.6331, Train Acc: 63.01%, Test Loss: 0.5483, Test Acc: 68.97%\n",
            "Epoch 9359/10000, Train Loss: 0.6197, Train Acc: 60.40%, Test Loss: 0.5514, Test Acc: 70.69%\n",
            "Epoch 9360/10000, Train Loss: 0.6325, Train Acc: 63.87%, Test Loss: 0.5513, Test Acc: 74.14%\n",
            "Epoch 9361/10000, Train Loss: 0.6183, Train Acc: 66.47%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 9362/10000, Train Loss: 0.6109, Train Acc: 65.32%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 9363/10000, Train Loss: 0.6299, Train Acc: 64.74%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9364/10000, Train Loss: 0.6211, Train Acc: 63.87%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9365/10000, Train Loss: 0.6171, Train Acc: 63.58%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 9366/10000, Train Loss: 0.6179, Train Acc: 65.32%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 9367/10000, Train Loss: 0.6348, Train Acc: 65.61%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 9368/10000, Train Loss: 0.5913, Train Acc: 65.32%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 9369/10000, Train Loss: 0.6032, Train Acc: 65.61%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 9370/10000, Train Loss: 0.6111, Train Acc: 67.05%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 9371/10000, Train Loss: 0.6084, Train Acc: 63.58%, Test Loss: 0.5551, Test Acc: 75.86%\n",
            "Epoch 9372/10000, Train Loss: 0.6254, Train Acc: 62.14%, Test Loss: 0.5547, Test Acc: 75.86%\n",
            "Epoch 9373/10000, Train Loss: 0.5999, Train Acc: 67.63%, Test Loss: 0.5495, Test Acc: 74.14%\n",
            "Epoch 9374/10000, Train Loss: 0.6198, Train Acc: 66.76%, Test Loss: 0.5489, Test Acc: 70.69%\n",
            "Epoch 9375/10000, Train Loss: 0.6121, Train Acc: 67.05%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 9376/10000, Train Loss: 0.5837, Train Acc: 64.16%, Test Loss: 0.5568, Test Acc: 70.69%\n",
            "Epoch 9377/10000, Train Loss: 0.6315, Train Acc: 62.43%, Test Loss: 0.5632, Test Acc: 72.41%\n",
            "Epoch 9378/10000, Train Loss: 0.6339, Train Acc: 64.45%, Test Loss: 0.5738, Test Acc: 67.24%\n",
            "Epoch 9379/10000, Train Loss: 0.6028, Train Acc: 62.72%, Test Loss: 0.5692, Test Acc: 72.41%\n",
            "Epoch 9380/10000, Train Loss: 0.6173, Train Acc: 65.61%, Test Loss: 0.5645, Test Acc: 68.97%\n",
            "Epoch 9381/10000, Train Loss: 0.6228, Train Acc: 66.76%, Test Loss: 0.5611, Test Acc: 68.97%\n",
            "Epoch 9382/10000, Train Loss: 0.5992, Train Acc: 63.87%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 9383/10000, Train Loss: 0.6101, Train Acc: 64.74%, Test Loss: 0.5554, Test Acc: 72.41%\n",
            "Epoch 9384/10000, Train Loss: 0.6086, Train Acc: 66.47%, Test Loss: 0.5561, Test Acc: 70.69%\n",
            "Epoch 9385/10000, Train Loss: 0.6101, Train Acc: 63.58%, Test Loss: 0.5567, Test Acc: 74.14%\n",
            "Epoch 9386/10000, Train Loss: 0.5645, Train Acc: 65.61%, Test Loss: 0.5590, Test Acc: 72.41%\n",
            "Epoch 9387/10000, Train Loss: 0.6306, Train Acc: 61.85%, Test Loss: 0.5595, Test Acc: 74.14%\n",
            "Epoch 9388/10000, Train Loss: 0.6147, Train Acc: 66.18%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 9389/10000, Train Loss: 0.6379, Train Acc: 60.40%, Test Loss: 0.5468, Test Acc: 70.69%\n",
            "Epoch 9390/10000, Train Loss: 0.6364, Train Acc: 64.16%, Test Loss: 0.5492, Test Acc: 72.41%\n",
            "Epoch 9391/10000, Train Loss: 0.6038, Train Acc: 67.05%, Test Loss: 0.5562, Test Acc: 72.41%\n",
            "Epoch 9392/10000, Train Loss: 0.6011, Train Acc: 66.47%, Test Loss: 0.5547, Test Acc: 75.86%\n",
            "Epoch 9393/10000, Train Loss: 0.6211, Train Acc: 67.05%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 9394/10000, Train Loss: 0.6118, Train Acc: 65.90%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 9395/10000, Train Loss: 0.6128, Train Acc: 66.47%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 9396/10000, Train Loss: 0.6108, Train Acc: 65.90%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 9397/10000, Train Loss: 0.5880, Train Acc: 68.21%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 9398/10000, Train Loss: 0.6197, Train Acc: 63.01%, Test Loss: 0.5594, Test Acc: 72.41%\n",
            "Epoch 9399/10000, Train Loss: 0.6133, Train Acc: 64.16%, Test Loss: 0.5635, Test Acc: 70.69%\n",
            "Epoch 9400/10000, Train Loss: 0.5872, Train Acc: 66.47%, Test Loss: 0.5587, Test Acc: 70.69%\n",
            "Epoch 9401/10000, Train Loss: 0.6139, Train Acc: 64.74%, Test Loss: 0.5609, Test Acc: 68.97%\n",
            "Epoch 9402/10000, Train Loss: 0.6153, Train Acc: 65.32%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 9403/10000, Train Loss: 0.6094, Train Acc: 66.76%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 9404/10000, Train Loss: 0.6255, Train Acc: 62.72%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 9405/10000, Train Loss: 0.6103, Train Acc: 62.43%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 9406/10000, Train Loss: 0.6158, Train Acc: 65.90%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 9407/10000, Train Loss: 0.5952, Train Acc: 68.79%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 9408/10000, Train Loss: 0.6066, Train Acc: 63.01%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 9409/10000, Train Loss: 0.6042, Train Acc: 63.29%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 9410/10000, Train Loss: 0.6108, Train Acc: 64.16%, Test Loss: 0.5568, Test Acc: 75.86%\n",
            "Epoch 9411/10000, Train Loss: 0.6279, Train Acc: 64.74%, Test Loss: 0.5566, Test Acc: 74.14%\n",
            "Epoch 9412/10000, Train Loss: 0.6043, Train Acc: 68.21%, Test Loss: 0.5528, Test Acc: 75.86%\n",
            "Epoch 9413/10000, Train Loss: 0.6442, Train Acc: 65.90%, Test Loss: 0.5510, Test Acc: 70.69%\n",
            "Epoch 9414/10000, Train Loss: 0.6342, Train Acc: 64.45%, Test Loss: 0.5504, Test Acc: 68.97%\n",
            "Epoch 9415/10000, Train Loss: 0.6126, Train Acc: 62.72%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 9416/10000, Train Loss: 0.6231, Train Acc: 64.16%, Test Loss: 0.5518, Test Acc: 68.97%\n",
            "Epoch 9417/10000, Train Loss: 0.5996, Train Acc: 69.08%, Test Loss: 0.5503, Test Acc: 68.97%\n",
            "Epoch 9418/10000, Train Loss: 0.6087, Train Acc: 68.21%, Test Loss: 0.5485, Test Acc: 68.97%\n",
            "Epoch 9419/10000, Train Loss: 0.6062, Train Acc: 65.03%, Test Loss: 0.5495, Test Acc: 68.97%\n",
            "Epoch 9420/10000, Train Loss: 0.6199, Train Acc: 65.32%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 9421/10000, Train Loss: 0.6090, Train Acc: 65.03%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 9422/10000, Train Loss: 0.6212, Train Acc: 65.32%, Test Loss: 0.5481, Test Acc: 70.69%\n",
            "Epoch 9423/10000, Train Loss: 0.6035, Train Acc: 65.32%, Test Loss: 0.5465, Test Acc: 72.41%\n",
            "Epoch 9424/10000, Train Loss: 0.6194, Train Acc: 63.58%, Test Loss: 0.5483, Test Acc: 68.97%\n",
            "Epoch 9425/10000, Train Loss: 0.6078, Train Acc: 65.61%, Test Loss: 0.5501, Test Acc: 70.69%\n",
            "Epoch 9426/10000, Train Loss: 0.6175, Train Acc: 62.14%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 9427/10000, Train Loss: 0.5949, Train Acc: 65.90%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 9428/10000, Train Loss: 0.6342, Train Acc: 64.16%, Test Loss: 0.5599, Test Acc: 72.41%\n",
            "Epoch 9429/10000, Train Loss: 0.6073, Train Acc: 61.56%, Test Loss: 0.5570, Test Acc: 70.69%\n",
            "Epoch 9430/10000, Train Loss: 0.6073, Train Acc: 64.45%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 9431/10000, Train Loss: 0.6272, Train Acc: 61.85%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9432/10000, Train Loss: 0.6378, Train Acc: 65.90%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 9433/10000, Train Loss: 0.6262, Train Acc: 65.61%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 9434/10000, Train Loss: 0.6302, Train Acc: 66.76%, Test Loss: 0.5513, Test Acc: 72.41%\n",
            "Epoch 9435/10000, Train Loss: 0.6278, Train Acc: 65.03%, Test Loss: 0.5504, Test Acc: 70.69%\n",
            "Epoch 9436/10000, Train Loss: 0.5999, Train Acc: 63.01%, Test Loss: 0.5493, Test Acc: 70.69%\n",
            "Epoch 9437/10000, Train Loss: 0.6041, Train Acc: 62.72%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 9438/10000, Train Loss: 0.6123, Train Acc: 66.76%, Test Loss: 0.5512, Test Acc: 70.69%\n",
            "Epoch 9439/10000, Train Loss: 0.6059, Train Acc: 67.34%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 9440/10000, Train Loss: 0.5810, Train Acc: 66.76%, Test Loss: 0.5513, Test Acc: 70.69%\n",
            "Epoch 9441/10000, Train Loss: 0.6147, Train Acc: 65.32%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 9442/10000, Train Loss: 0.6126, Train Acc: 66.18%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 9443/10000, Train Loss: 0.5921, Train Acc: 65.61%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9444/10000, Train Loss: 0.6335, Train Acc: 64.16%, Test Loss: 0.5598, Test Acc: 72.41%\n",
            "Epoch 9445/10000, Train Loss: 0.6415, Train Acc: 63.29%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 9446/10000, Train Loss: 0.6366, Train Acc: 60.40%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 9447/10000, Train Loss: 0.6162, Train Acc: 63.29%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 9448/10000, Train Loss: 0.5924, Train Acc: 67.63%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 9449/10000, Train Loss: 0.5859, Train Acc: 65.32%, Test Loss: 0.5562, Test Acc: 68.97%\n",
            "Epoch 9450/10000, Train Loss: 0.5991, Train Acc: 69.65%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 9451/10000, Train Loss: 0.5936, Train Acc: 65.90%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 9452/10000, Train Loss: 0.5999, Train Acc: 67.63%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 9453/10000, Train Loss: 0.6110, Train Acc: 66.76%, Test Loss: 0.5565, Test Acc: 68.97%\n",
            "Epoch 9454/10000, Train Loss: 0.6173, Train Acc: 64.16%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 9455/10000, Train Loss: 0.5986, Train Acc: 67.92%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 9456/10000, Train Loss: 0.6103, Train Acc: 65.32%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 9457/10000, Train Loss: 0.6059, Train Acc: 67.34%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 9458/10000, Train Loss: 0.6058, Train Acc: 67.05%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 9459/10000, Train Loss: 0.6143, Train Acc: 64.74%, Test Loss: 0.5490, Test Acc: 72.41%\n",
            "Epoch 9460/10000, Train Loss: 0.6112, Train Acc: 66.47%, Test Loss: 0.5470, Test Acc: 70.69%\n",
            "Epoch 9461/10000, Train Loss: 0.6055, Train Acc: 66.47%, Test Loss: 0.5491, Test Acc: 70.69%\n",
            "Epoch 9462/10000, Train Loss: 0.6222, Train Acc: 63.29%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 9463/10000, Train Loss: 0.6397, Train Acc: 66.18%, Test Loss: 0.5511, Test Acc: 75.86%\n",
            "Epoch 9464/10000, Train Loss: 0.6063, Train Acc: 65.32%, Test Loss: 0.5481, Test Acc: 75.86%\n",
            "Epoch 9465/10000, Train Loss: 0.6209, Train Acc: 63.29%, Test Loss: 0.5453, Test Acc: 70.69%\n",
            "Epoch 9466/10000, Train Loss: 0.6141, Train Acc: 65.32%, Test Loss: 0.5476, Test Acc: 70.69%\n",
            "Epoch 9467/10000, Train Loss: 0.6356, Train Acc: 64.45%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 9468/10000, Train Loss: 0.6053, Train Acc: 63.29%, Test Loss: 0.5557, Test Acc: 70.69%\n",
            "Epoch 9469/10000, Train Loss: 0.6102, Train Acc: 65.61%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 9470/10000, Train Loss: 0.5957, Train Acc: 67.92%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 9471/10000, Train Loss: 0.6290, Train Acc: 64.16%, Test Loss: 0.5476, Test Acc: 70.69%\n",
            "Epoch 9472/10000, Train Loss: 0.6221, Train Acc: 61.85%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 9473/10000, Train Loss: 0.6150, Train Acc: 66.18%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 9474/10000, Train Loss: 0.6093, Train Acc: 64.74%, Test Loss: 0.5556, Test Acc: 70.69%\n",
            "Epoch 9475/10000, Train Loss: 0.6065, Train Acc: 61.27%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 9476/10000, Train Loss: 0.6349, Train Acc: 60.69%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 9477/10000, Train Loss: 0.6343, Train Acc: 63.01%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 9478/10000, Train Loss: 0.6251, Train Acc: 63.58%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 9479/10000, Train Loss: 0.6080, Train Acc: 67.05%, Test Loss: 0.5471, Test Acc: 72.41%\n",
            "Epoch 9480/10000, Train Loss: 0.6267, Train Acc: 64.16%, Test Loss: 0.5471, Test Acc: 70.69%\n",
            "Epoch 9481/10000, Train Loss: 0.6116, Train Acc: 64.45%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 9482/10000, Train Loss: 0.6292, Train Acc: 63.01%, Test Loss: 0.5595, Test Acc: 70.69%\n",
            "Epoch 9483/10000, Train Loss: 0.5955, Train Acc: 69.08%, Test Loss: 0.5665, Test Acc: 70.69%\n",
            "Epoch 9484/10000, Train Loss: 0.5914, Train Acc: 68.79%, Test Loss: 0.5589, Test Acc: 70.69%\n",
            "Epoch 9485/10000, Train Loss: 0.5937, Train Acc: 63.87%, Test Loss: 0.5606, Test Acc: 68.97%\n",
            "Epoch 9486/10000, Train Loss: 0.6099, Train Acc: 63.29%, Test Loss: 0.5602, Test Acc: 70.69%\n",
            "Epoch 9487/10000, Train Loss: 0.6202, Train Acc: 65.61%, Test Loss: 0.5602, Test Acc: 70.69%\n",
            "Epoch 9488/10000, Train Loss: 0.6215, Train Acc: 65.03%, Test Loss: 0.5528, Test Acc: 72.41%\n",
            "Epoch 9489/10000, Train Loss: 0.6102, Train Acc: 62.72%, Test Loss: 0.5499, Test Acc: 72.41%\n",
            "Epoch 9490/10000, Train Loss: 0.6001, Train Acc: 64.45%, Test Loss: 0.5529, Test Acc: 74.14%\n",
            "Epoch 9491/10000, Train Loss: 0.6125, Train Acc: 62.72%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 9492/10000, Train Loss: 0.6081, Train Acc: 63.29%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 9493/10000, Train Loss: 0.5786, Train Acc: 66.47%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 9494/10000, Train Loss: 0.6239, Train Acc: 67.63%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9495/10000, Train Loss: 0.6031, Train Acc: 68.79%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 9496/10000, Train Loss: 0.6146, Train Acc: 65.90%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 9497/10000, Train Loss: 0.6209, Train Acc: 60.98%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 9498/10000, Train Loss: 0.6018, Train Acc: 65.32%, Test Loss: 0.5554, Test Acc: 72.41%\n",
            "Epoch 9499/10000, Train Loss: 0.6150, Train Acc: 63.01%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 9500/10000, Train Loss: 0.6390, Train Acc: 63.87%, Test Loss: 0.5514, Test Acc: 72.41%\n",
            "Epoch 9501/10000, Train Loss: 0.5898, Train Acc: 67.05%, Test Loss: 0.5520, Test Acc: 70.69%\n",
            "Epoch 9502/10000, Train Loss: 0.6429, Train Acc: 62.14%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 9503/10000, Train Loss: 0.6083, Train Acc: 63.01%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 9504/10000, Train Loss: 0.6221, Train Acc: 65.90%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 9505/10000, Train Loss: 0.5938, Train Acc: 61.56%, Test Loss: 0.5494, Test Acc: 72.41%\n",
            "Epoch 9506/10000, Train Loss: 0.6054, Train Acc: 65.90%, Test Loss: 0.5471, Test Acc: 72.41%\n",
            "Epoch 9507/10000, Train Loss: 0.6264, Train Acc: 65.90%, Test Loss: 0.5493, Test Acc: 70.69%\n",
            "Epoch 9508/10000, Train Loss: 0.6223, Train Acc: 64.16%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 9509/10000, Train Loss: 0.6087, Train Acc: 66.18%, Test Loss: 0.5525, Test Acc: 68.97%\n",
            "Epoch 9510/10000, Train Loss: 0.6075, Train Acc: 65.03%, Test Loss: 0.5523, Test Acc: 70.69%\n",
            "Epoch 9511/10000, Train Loss: 0.6067, Train Acc: 67.63%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 9512/10000, Train Loss: 0.5960, Train Acc: 65.32%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9513/10000, Train Loss: 0.6240, Train Acc: 65.61%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 9514/10000, Train Loss: 0.6065, Train Acc: 67.05%, Test Loss: 0.5522, Test Acc: 70.69%\n",
            "Epoch 9515/10000, Train Loss: 0.6316, Train Acc: 65.61%, Test Loss: 0.5539, Test Acc: 72.41%\n",
            "Epoch 9516/10000, Train Loss: 0.6143, Train Acc: 60.40%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 9517/10000, Train Loss: 0.6104, Train Acc: 66.18%, Test Loss: 0.5509, Test Acc: 68.97%\n",
            "Epoch 9518/10000, Train Loss: 0.6176, Train Acc: 65.90%, Test Loss: 0.5521, Test Acc: 70.69%\n",
            "Epoch 9519/10000, Train Loss: 0.6161, Train Acc: 62.72%, Test Loss: 0.5506, Test Acc: 72.41%\n",
            "Epoch 9520/10000, Train Loss: 0.6050, Train Acc: 66.76%, Test Loss: 0.5508, Test Acc: 72.41%\n",
            "Epoch 9521/10000, Train Loss: 0.6319, Train Acc: 61.85%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 9522/10000, Train Loss: 0.6077, Train Acc: 64.45%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 9523/10000, Train Loss: 0.6182, Train Acc: 66.18%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 9524/10000, Train Loss: 0.6208, Train Acc: 64.45%, Test Loss: 0.5552, Test Acc: 70.69%\n",
            "Epoch 9525/10000, Train Loss: 0.6170, Train Acc: 63.29%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 9526/10000, Train Loss: 0.6108, Train Acc: 67.34%, Test Loss: 0.5505, Test Acc: 72.41%\n",
            "Epoch 9527/10000, Train Loss: 0.6138, Train Acc: 66.76%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 9528/10000, Train Loss: 0.6109, Train Acc: 62.72%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 9529/10000, Train Loss: 0.6290, Train Acc: 66.18%, Test Loss: 0.5498, Test Acc: 70.69%\n",
            "Epoch 9530/10000, Train Loss: 0.6193, Train Acc: 65.61%, Test Loss: 0.5489, Test Acc: 68.97%\n",
            "Epoch 9531/10000, Train Loss: 0.5952, Train Acc: 64.16%, Test Loss: 0.5509, Test Acc: 70.69%\n",
            "Epoch 9532/10000, Train Loss: 0.6012, Train Acc: 64.45%, Test Loss: 0.5535, Test Acc: 70.69%\n",
            "Epoch 9533/10000, Train Loss: 0.6260, Train Acc: 63.29%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9534/10000, Train Loss: 0.6239, Train Acc: 63.01%, Test Loss: 0.5567, Test Acc: 68.97%\n",
            "Epoch 9535/10000, Train Loss: 0.6152, Train Acc: 62.72%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 9536/10000, Train Loss: 0.6102, Train Acc: 65.90%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 9537/10000, Train Loss: 0.6156, Train Acc: 62.72%, Test Loss: 0.5512, Test Acc: 72.41%\n",
            "Epoch 9538/10000, Train Loss: 0.6036, Train Acc: 64.74%, Test Loss: 0.5535, Test Acc: 68.97%\n",
            "Epoch 9539/10000, Train Loss: 0.6234, Train Acc: 64.45%, Test Loss: 0.5548, Test Acc: 68.97%\n",
            "Epoch 9540/10000, Train Loss: 0.5926, Train Acc: 66.18%, Test Loss: 0.5531, Test Acc: 70.69%\n",
            "Epoch 9541/10000, Train Loss: 0.6028, Train Acc: 65.32%, Test Loss: 0.5509, Test Acc: 68.97%\n",
            "Epoch 9542/10000, Train Loss: 0.6289, Train Acc: 62.14%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 9543/10000, Train Loss: 0.5933, Train Acc: 66.18%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 9544/10000, Train Loss: 0.6120, Train Acc: 66.47%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 9545/10000, Train Loss: 0.6034, Train Acc: 67.34%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 9546/10000, Train Loss: 0.6074, Train Acc: 65.03%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 9547/10000, Train Loss: 0.6157, Train Acc: 62.72%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 9548/10000, Train Loss: 0.6009, Train Acc: 65.03%, Test Loss: 0.5527, Test Acc: 74.14%\n",
            "Epoch 9549/10000, Train Loss: 0.6280, Train Acc: 65.90%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 9550/10000, Train Loss: 0.6146, Train Acc: 63.87%, Test Loss: 0.5498, Test Acc: 72.41%\n",
            "Epoch 9551/10000, Train Loss: 0.6206, Train Acc: 62.72%, Test Loss: 0.5507, Test Acc: 68.97%\n",
            "Epoch 9552/10000, Train Loss: 0.6127, Train Acc: 66.18%, Test Loss: 0.5475, Test Acc: 72.41%\n",
            "Epoch 9553/10000, Train Loss: 0.6084, Train Acc: 69.08%, Test Loss: 0.5479, Test Acc: 70.69%\n",
            "Epoch 9554/10000, Train Loss: 0.6266, Train Acc: 60.12%, Test Loss: 0.5493, Test Acc: 68.97%\n",
            "Epoch 9555/10000, Train Loss: 0.6130, Train Acc: 63.87%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 9556/10000, Train Loss: 0.6210, Train Acc: 62.72%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 9557/10000, Train Loss: 0.6009, Train Acc: 65.32%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 9558/10000, Train Loss: 0.6169, Train Acc: 65.03%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 9559/10000, Train Loss: 0.6172, Train Acc: 63.01%, Test Loss: 0.5495, Test Acc: 72.41%\n",
            "Epoch 9560/10000, Train Loss: 0.6100, Train Acc: 65.03%, Test Loss: 0.5514, Test Acc: 72.41%\n",
            "Epoch 9561/10000, Train Loss: 0.6160, Train Acc: 65.61%, Test Loss: 0.5507, Test Acc: 72.41%\n",
            "Epoch 9562/10000, Train Loss: 0.6060, Train Acc: 67.05%, Test Loss: 0.5512, Test Acc: 68.97%\n",
            "Epoch 9563/10000, Train Loss: 0.5832, Train Acc: 67.92%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 9564/10000, Train Loss: 0.6113, Train Acc: 66.76%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 9565/10000, Train Loss: 0.5949, Train Acc: 67.05%, Test Loss: 0.5563, Test Acc: 70.69%\n",
            "Epoch 9566/10000, Train Loss: 0.6065, Train Acc: 65.61%, Test Loss: 0.5546, Test Acc: 70.69%\n",
            "Epoch 9567/10000, Train Loss: 0.6174, Train Acc: 64.45%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 9568/10000, Train Loss: 0.6350, Train Acc: 62.14%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9569/10000, Train Loss: 0.6025, Train Acc: 65.90%, Test Loss: 0.5518, Test Acc: 72.41%\n",
            "Epoch 9570/10000, Train Loss: 0.6125, Train Acc: 68.21%, Test Loss: 0.5558, Test Acc: 70.69%\n",
            "Epoch 9571/10000, Train Loss: 0.6147, Train Acc: 65.32%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 9572/10000, Train Loss: 0.6411, Train Acc: 62.14%, Test Loss: 0.5560, Test Acc: 70.69%\n",
            "Epoch 9573/10000, Train Loss: 0.5962, Train Acc: 65.03%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 9574/10000, Train Loss: 0.6048, Train Acc: 63.87%, Test Loss: 0.5579, Test Acc: 70.69%\n",
            "Epoch 9575/10000, Train Loss: 0.5984, Train Acc: 67.63%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 9576/10000, Train Loss: 0.6442, Train Acc: 65.90%, Test Loss: 0.5573, Test Acc: 70.69%\n",
            "Epoch 9577/10000, Train Loss: 0.5985, Train Acc: 66.47%, Test Loss: 0.5539, Test Acc: 74.14%\n",
            "Epoch 9578/10000, Train Loss: 0.6059, Train Acc: 67.05%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 9579/10000, Train Loss: 0.6075, Train Acc: 69.94%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 9580/10000, Train Loss: 0.5918, Train Acc: 64.74%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 9581/10000, Train Loss: 0.6132, Train Acc: 63.87%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 9582/10000, Train Loss: 0.6259, Train Acc: 66.18%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9583/10000, Train Loss: 0.6228, Train Acc: 64.16%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 9584/10000, Train Loss: 0.6063, Train Acc: 65.03%, Test Loss: 0.5550, Test Acc: 74.14%\n",
            "Epoch 9585/10000, Train Loss: 0.6065, Train Acc: 64.74%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 9586/10000, Train Loss: 0.6328, Train Acc: 65.32%, Test Loss: 0.5494, Test Acc: 72.41%\n",
            "Epoch 9587/10000, Train Loss: 0.6112, Train Acc: 66.18%, Test Loss: 0.5457, Test Acc: 72.41%\n",
            "Epoch 9588/10000, Train Loss: 0.5980, Train Acc: 60.69%, Test Loss: 0.5475, Test Acc: 72.41%\n",
            "Epoch 9589/10000, Train Loss: 0.5944, Train Acc: 69.94%, Test Loss: 0.5464, Test Acc: 72.41%\n",
            "Epoch 9590/10000, Train Loss: 0.6046, Train Acc: 66.18%, Test Loss: 0.5467, Test Acc: 68.97%\n",
            "Epoch 9591/10000, Train Loss: 0.5985, Train Acc: 65.90%, Test Loss: 0.5495, Test Acc: 68.97%\n",
            "Epoch 9592/10000, Train Loss: 0.5984, Train Acc: 64.74%, Test Loss: 0.5520, Test Acc: 70.69%\n",
            "Epoch 9593/10000, Train Loss: 0.6318, Train Acc: 62.72%, Test Loss: 0.5594, Test Acc: 72.41%\n",
            "Epoch 9594/10000, Train Loss: 0.6158, Train Acc: 61.56%, Test Loss: 0.5616, Test Acc: 70.69%\n",
            "Epoch 9595/10000, Train Loss: 0.6153, Train Acc: 62.43%, Test Loss: 0.5603, Test Acc: 70.69%\n",
            "Epoch 9596/10000, Train Loss: 0.6065, Train Acc: 64.16%, Test Loss: 0.5530, Test Acc: 70.69%\n",
            "Epoch 9597/10000, Train Loss: 0.6001, Train Acc: 65.03%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 9598/10000, Train Loss: 0.6393, Train Acc: 63.87%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 9599/10000, Train Loss: 0.6291, Train Acc: 64.45%, Test Loss: 0.5591, Test Acc: 68.97%\n",
            "Epoch 9600/10000, Train Loss: 0.6133, Train Acc: 67.63%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 9601/10000, Train Loss: 0.5906, Train Acc: 69.08%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 9602/10000, Train Loss: 0.6214, Train Acc: 63.58%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 9603/10000, Train Loss: 0.6249, Train Acc: 65.90%, Test Loss: 0.5508, Test Acc: 74.14%\n",
            "Epoch 9604/10000, Train Loss: 0.6302, Train Acc: 63.01%, Test Loss: 0.5517, Test Acc: 74.14%\n",
            "Epoch 9605/10000, Train Loss: 0.6255, Train Acc: 63.01%, Test Loss: 0.5519, Test Acc: 72.41%\n",
            "Epoch 9606/10000, Train Loss: 0.5952, Train Acc: 63.29%, Test Loss: 0.5534, Test Acc: 70.69%\n",
            "Epoch 9607/10000, Train Loss: 0.6029, Train Acc: 68.50%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 9608/10000, Train Loss: 0.6235, Train Acc: 65.03%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 9609/10000, Train Loss: 0.6088, Train Acc: 67.05%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 9610/10000, Train Loss: 0.6026, Train Acc: 67.63%, Test Loss: 0.5583, Test Acc: 70.69%\n",
            "Epoch 9611/10000, Train Loss: 0.6049, Train Acc: 65.32%, Test Loss: 0.5581, Test Acc: 68.97%\n",
            "Epoch 9612/10000, Train Loss: 0.6127, Train Acc: 65.90%, Test Loss: 0.5604, Test Acc: 68.97%\n",
            "Epoch 9613/10000, Train Loss: 0.5991, Train Acc: 67.34%, Test Loss: 0.5631, Test Acc: 70.69%\n",
            "Epoch 9614/10000, Train Loss: 0.6059, Train Acc: 65.03%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 9615/10000, Train Loss: 0.6216, Train Acc: 65.90%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 9616/10000, Train Loss: 0.6050, Train Acc: 64.45%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 9617/10000, Train Loss: 0.5918, Train Acc: 65.61%, Test Loss: 0.5582, Test Acc: 74.14%\n",
            "Epoch 9618/10000, Train Loss: 0.6196, Train Acc: 65.90%, Test Loss: 0.5568, Test Acc: 74.14%\n",
            "Epoch 9619/10000, Train Loss: 0.5982, Train Acc: 64.16%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 9620/10000, Train Loss: 0.6063, Train Acc: 65.61%, Test Loss: 0.5543, Test Acc: 74.14%\n",
            "Epoch 9621/10000, Train Loss: 0.5986, Train Acc: 67.34%, Test Loss: 0.5523, Test Acc: 72.41%\n",
            "Epoch 9622/10000, Train Loss: 0.5977, Train Acc: 66.47%, Test Loss: 0.5565, Test Acc: 70.69%\n",
            "Epoch 9623/10000, Train Loss: 0.6087, Train Acc: 64.45%, Test Loss: 0.5589, Test Acc: 72.41%\n",
            "Epoch 9624/10000, Train Loss: 0.5862, Train Acc: 66.47%, Test Loss: 0.5562, Test Acc: 74.14%\n",
            "Epoch 9625/10000, Train Loss: 0.5998, Train Acc: 66.18%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 9626/10000, Train Loss: 0.6118, Train Acc: 65.61%, Test Loss: 0.5593, Test Acc: 70.69%\n",
            "Epoch 9627/10000, Train Loss: 0.5901, Train Acc: 64.45%, Test Loss: 0.5594, Test Acc: 68.97%\n",
            "Epoch 9628/10000, Train Loss: 0.6152, Train Acc: 62.43%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 9629/10000, Train Loss: 0.6488, Train Acc: 60.40%, Test Loss: 0.5538, Test Acc: 70.69%\n",
            "Epoch 9630/10000, Train Loss: 0.6045, Train Acc: 66.76%, Test Loss: 0.5518, Test Acc: 75.86%\n",
            "Epoch 9631/10000, Train Loss: 0.6129, Train Acc: 63.29%, Test Loss: 0.5525, Test Acc: 75.86%\n",
            "Epoch 9632/10000, Train Loss: 0.6093, Train Acc: 65.90%, Test Loss: 0.5485, Test Acc: 75.86%\n",
            "Epoch 9633/10000, Train Loss: 0.6130, Train Acc: 67.05%, Test Loss: 0.5473, Test Acc: 75.86%\n",
            "Epoch 9634/10000, Train Loss: 0.6049, Train Acc: 67.05%, Test Loss: 0.5480, Test Acc: 72.41%\n",
            "Epoch 9635/10000, Train Loss: 0.6188, Train Acc: 63.58%, Test Loss: 0.5496, Test Acc: 72.41%\n",
            "Epoch 9636/10000, Train Loss: 0.6276, Train Acc: 63.01%, Test Loss: 0.5490, Test Acc: 70.69%\n",
            "Epoch 9637/10000, Train Loss: 0.5933, Train Acc: 64.45%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 9638/10000, Train Loss: 0.6108, Train Acc: 64.74%, Test Loss: 0.5515, Test Acc: 68.97%\n",
            "Epoch 9639/10000, Train Loss: 0.5991, Train Acc: 64.16%, Test Loss: 0.5536, Test Acc: 68.97%\n",
            "Epoch 9640/10000, Train Loss: 0.5977, Train Acc: 65.03%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 9641/10000, Train Loss: 0.6240, Train Acc: 64.45%, Test Loss: 0.5555, Test Acc: 70.69%\n",
            "Epoch 9642/10000, Train Loss: 0.5936, Train Acc: 67.05%, Test Loss: 0.5557, Test Acc: 68.97%\n",
            "Epoch 9643/10000, Train Loss: 0.5987, Train Acc: 65.61%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 9644/10000, Train Loss: 0.6104, Train Acc: 63.58%, Test Loss: 0.5516, Test Acc: 70.69%\n",
            "Epoch 9645/10000, Train Loss: 0.6354, Train Acc: 63.87%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 9646/10000, Train Loss: 0.6120, Train Acc: 60.69%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 9647/10000, Train Loss: 0.6416, Train Acc: 62.72%, Test Loss: 0.5485, Test Acc: 70.69%\n",
            "Epoch 9648/10000, Train Loss: 0.6183, Train Acc: 62.72%, Test Loss: 0.5500, Test Acc: 68.97%\n",
            "Epoch 9649/10000, Train Loss: 0.6203, Train Acc: 63.87%, Test Loss: 0.5543, Test Acc: 68.97%\n",
            "Epoch 9650/10000, Train Loss: 0.5923, Train Acc: 66.47%, Test Loss: 0.5542, Test Acc: 68.97%\n",
            "Epoch 9651/10000, Train Loss: 0.5831, Train Acc: 67.34%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 9652/10000, Train Loss: 0.6356, Train Acc: 64.45%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 9653/10000, Train Loss: 0.6065, Train Acc: 62.14%, Test Loss: 0.5520, Test Acc: 68.97%\n",
            "Epoch 9654/10000, Train Loss: 0.6216, Train Acc: 64.45%, Test Loss: 0.5541, Test Acc: 70.69%\n",
            "Epoch 9655/10000, Train Loss: 0.6171, Train Acc: 66.76%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9656/10000, Train Loss: 0.5997, Train Acc: 63.58%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 9657/10000, Train Loss: 0.6218, Train Acc: 67.63%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 9658/10000, Train Loss: 0.6065, Train Acc: 65.90%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 9659/10000, Train Loss: 0.5943, Train Acc: 65.90%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 9660/10000, Train Loss: 0.6291, Train Acc: 63.29%, Test Loss: 0.5534, Test Acc: 72.41%\n",
            "Epoch 9661/10000, Train Loss: 0.6141, Train Acc: 66.18%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 9662/10000, Train Loss: 0.6379, Train Acc: 65.03%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 9663/10000, Train Loss: 0.6070, Train Acc: 65.61%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 9664/10000, Train Loss: 0.6183, Train Acc: 64.16%, Test Loss: 0.5632, Test Acc: 70.69%\n",
            "Epoch 9665/10000, Train Loss: 0.6060, Train Acc: 66.47%, Test Loss: 0.5588, Test Acc: 68.97%\n",
            "Epoch 9666/10000, Train Loss: 0.6131, Train Acc: 67.05%, Test Loss: 0.5573, Test Acc: 72.41%\n",
            "Epoch 9667/10000, Train Loss: 0.5952, Train Acc: 65.90%, Test Loss: 0.5554, Test Acc: 72.41%\n",
            "Epoch 9668/10000, Train Loss: 0.6145, Train Acc: 65.03%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 9669/10000, Train Loss: 0.6138, Train Acc: 66.76%, Test Loss: 0.5567, Test Acc: 72.41%\n",
            "Epoch 9670/10000, Train Loss: 0.6032, Train Acc: 65.32%, Test Loss: 0.5552, Test Acc: 74.14%\n",
            "Epoch 9671/10000, Train Loss: 0.6225, Train Acc: 63.87%, Test Loss: 0.5546, Test Acc: 74.14%\n",
            "Epoch 9672/10000, Train Loss: 0.6089, Train Acc: 64.74%, Test Loss: 0.5550, Test Acc: 74.14%\n",
            "Epoch 9673/10000, Train Loss: 0.6113, Train Acc: 62.14%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 9674/10000, Train Loss: 0.5811, Train Acc: 64.16%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 9675/10000, Train Loss: 0.6147, Train Acc: 65.90%, Test Loss: 0.5524, Test Acc: 68.97%\n",
            "Epoch 9676/10000, Train Loss: 0.6540, Train Acc: 60.98%, Test Loss: 0.5576, Test Acc: 68.97%\n",
            "Epoch 9677/10000, Train Loss: 0.6223, Train Acc: 65.61%, Test Loss: 0.5587, Test Acc: 70.69%\n",
            "Epoch 9678/10000, Train Loss: 0.6110, Train Acc: 62.72%, Test Loss: 0.5609, Test Acc: 70.69%\n",
            "Epoch 9679/10000, Train Loss: 0.5889, Train Acc: 67.34%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 9680/10000, Train Loss: 0.6321, Train Acc: 67.92%, Test Loss: 0.5601, Test Acc: 68.97%\n",
            "Epoch 9681/10000, Train Loss: 0.6264, Train Acc: 64.74%, Test Loss: 0.5603, Test Acc: 68.97%\n",
            "Epoch 9682/10000, Train Loss: 0.6174, Train Acc: 64.16%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 9683/10000, Train Loss: 0.6070, Train Acc: 67.34%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 9684/10000, Train Loss: 0.6144, Train Acc: 62.14%, Test Loss: 0.5592, Test Acc: 74.14%\n",
            "Epoch 9685/10000, Train Loss: 0.6030, Train Acc: 64.74%, Test Loss: 0.5598, Test Acc: 72.41%\n",
            "Epoch 9686/10000, Train Loss: 0.5974, Train Acc: 67.63%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 9687/10000, Train Loss: 0.6176, Train Acc: 65.03%, Test Loss: 0.5528, Test Acc: 74.14%\n",
            "Epoch 9688/10000, Train Loss: 0.6202, Train Acc: 65.90%, Test Loss: 0.5510, Test Acc: 72.41%\n",
            "Epoch 9689/10000, Train Loss: 0.6141, Train Acc: 66.47%, Test Loss: 0.5498, Test Acc: 72.41%\n",
            "Epoch 9690/10000, Train Loss: 0.6315, Train Acc: 66.18%, Test Loss: 0.5525, Test Acc: 72.41%\n",
            "Epoch 9691/10000, Train Loss: 0.6124, Train Acc: 63.87%, Test Loss: 0.5500, Test Acc: 72.41%\n",
            "Epoch 9692/10000, Train Loss: 0.6169, Train Acc: 69.65%, Test Loss: 0.5485, Test Acc: 70.69%\n",
            "Epoch 9693/10000, Train Loss: 0.6091, Train Acc: 65.90%, Test Loss: 0.5511, Test Acc: 68.97%\n",
            "Epoch 9694/10000, Train Loss: 0.6156, Train Acc: 67.34%, Test Loss: 0.5575, Test Acc: 68.97%\n",
            "Epoch 9695/10000, Train Loss: 0.6260, Train Acc: 63.87%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 9696/10000, Train Loss: 0.6076, Train Acc: 65.32%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9697/10000, Train Loss: 0.6124, Train Acc: 64.16%, Test Loss: 0.5526, Test Acc: 68.97%\n",
            "Epoch 9698/10000, Train Loss: 0.5978, Train Acc: 65.03%, Test Loss: 0.5531, Test Acc: 68.97%\n",
            "Epoch 9699/10000, Train Loss: 0.6100, Train Acc: 63.87%, Test Loss: 0.5537, Test Acc: 70.69%\n",
            "Epoch 9700/10000, Train Loss: 0.6249, Train Acc: 63.87%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 9701/10000, Train Loss: 0.5884, Train Acc: 63.29%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 9702/10000, Train Loss: 0.6141, Train Acc: 63.01%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 9703/10000, Train Loss: 0.6024, Train Acc: 65.61%, Test Loss: 0.5532, Test Acc: 68.97%\n",
            "Epoch 9704/10000, Train Loss: 0.6102, Train Acc: 64.45%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 9705/10000, Train Loss: 0.5828, Train Acc: 67.34%, Test Loss: 0.5525, Test Acc: 70.69%\n",
            "Epoch 9706/10000, Train Loss: 0.5908, Train Acc: 65.90%, Test Loss: 0.5505, Test Acc: 68.97%\n",
            "Epoch 9707/10000, Train Loss: 0.6079, Train Acc: 62.72%, Test Loss: 0.5557, Test Acc: 74.14%\n",
            "Epoch 9708/10000, Train Loss: 0.6131, Train Acc: 67.34%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 9709/10000, Train Loss: 0.5980, Train Acc: 65.61%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 9710/10000, Train Loss: 0.6131, Train Acc: 66.76%, Test Loss: 0.5592, Test Acc: 68.97%\n",
            "Epoch 9711/10000, Train Loss: 0.6045, Train Acc: 67.92%, Test Loss: 0.5598, Test Acc: 70.69%\n",
            "Epoch 9712/10000, Train Loss: 0.5960, Train Acc: 67.92%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9713/10000, Train Loss: 0.6119, Train Acc: 62.43%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 9714/10000, Train Loss: 0.6287, Train Acc: 63.87%, Test Loss: 0.5528, Test Acc: 74.14%\n",
            "Epoch 9715/10000, Train Loss: 0.6095, Train Acc: 67.63%, Test Loss: 0.5538, Test Acc: 74.14%\n",
            "Epoch 9716/10000, Train Loss: 0.6257, Train Acc: 63.01%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 9717/10000, Train Loss: 0.6172, Train Acc: 60.40%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 9718/10000, Train Loss: 0.6273, Train Acc: 63.58%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 9719/10000, Train Loss: 0.5873, Train Acc: 70.23%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 9720/10000, Train Loss: 0.5938, Train Acc: 67.05%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 9721/10000, Train Loss: 0.5896, Train Acc: 66.47%, Test Loss: 0.5532, Test Acc: 75.86%\n",
            "Epoch 9722/10000, Train Loss: 0.6271, Train Acc: 63.29%, Test Loss: 0.5505, Test Acc: 72.41%\n",
            "Epoch 9723/10000, Train Loss: 0.6300, Train Acc: 60.12%, Test Loss: 0.5515, Test Acc: 75.86%\n",
            "Epoch 9724/10000, Train Loss: 0.6245, Train Acc: 64.16%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 9725/10000, Train Loss: 0.6109, Train Acc: 65.32%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9726/10000, Train Loss: 0.6088, Train Acc: 65.61%, Test Loss: 0.5578, Test Acc: 68.97%\n",
            "Epoch 9727/10000, Train Loss: 0.6079, Train Acc: 67.05%, Test Loss: 0.5586, Test Acc: 68.97%\n",
            "Epoch 9728/10000, Train Loss: 0.6142, Train Acc: 67.05%, Test Loss: 0.5560, Test Acc: 70.69%\n",
            "Epoch 9729/10000, Train Loss: 0.5997, Train Acc: 66.47%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 9730/10000, Train Loss: 0.6340, Train Acc: 62.72%, Test Loss: 0.5557, Test Acc: 70.69%\n",
            "Epoch 9731/10000, Train Loss: 0.6189, Train Acc: 66.18%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 9732/10000, Train Loss: 0.6368, Train Acc: 62.14%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 9733/10000, Train Loss: 0.6066, Train Acc: 64.16%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 9734/10000, Train Loss: 0.6243, Train Acc: 65.32%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 9735/10000, Train Loss: 0.6288, Train Acc: 65.03%, Test Loss: 0.5594, Test Acc: 70.69%\n",
            "Epoch 9736/10000, Train Loss: 0.6456, Train Acc: 63.87%, Test Loss: 0.5565, Test Acc: 72.41%\n",
            "Epoch 9737/10000, Train Loss: 0.5872, Train Acc: 69.36%, Test Loss: 0.5539, Test Acc: 70.69%\n",
            "Epoch 9738/10000, Train Loss: 0.6189, Train Acc: 64.45%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 9739/10000, Train Loss: 0.6151, Train Acc: 65.03%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 9740/10000, Train Loss: 0.6274, Train Acc: 63.87%, Test Loss: 0.5552, Test Acc: 72.41%\n",
            "Epoch 9741/10000, Train Loss: 0.6242, Train Acc: 66.76%, Test Loss: 0.5577, Test Acc: 72.41%\n",
            "Epoch 9742/10000, Train Loss: 0.6324, Train Acc: 62.14%, Test Loss: 0.5565, Test Acc: 72.41%\n",
            "Epoch 9743/10000, Train Loss: 0.6111, Train Acc: 63.87%, Test Loss: 0.5525, Test Acc: 72.41%\n",
            "Epoch 9744/10000, Train Loss: 0.6069, Train Acc: 64.45%, Test Loss: 0.5509, Test Acc: 72.41%\n",
            "Epoch 9745/10000, Train Loss: 0.6243, Train Acc: 64.45%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 9746/10000, Train Loss: 0.6000, Train Acc: 65.03%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 9747/10000, Train Loss: 0.6225, Train Acc: 63.87%, Test Loss: 0.5513, Test Acc: 68.97%\n",
            "Epoch 9748/10000, Train Loss: 0.6205, Train Acc: 65.90%, Test Loss: 0.5510, Test Acc: 68.97%\n",
            "Epoch 9749/10000, Train Loss: 0.6164, Train Acc: 65.32%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 9750/10000, Train Loss: 0.6095, Train Acc: 64.74%, Test Loss: 0.5517, Test Acc: 68.97%\n",
            "Epoch 9751/10000, Train Loss: 0.6339, Train Acc: 63.29%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 9752/10000, Train Loss: 0.6182, Train Acc: 65.32%, Test Loss: 0.5632, Test Acc: 72.41%\n",
            "Epoch 9753/10000, Train Loss: 0.6058, Train Acc: 67.63%, Test Loss: 0.5651, Test Acc: 72.41%\n",
            "Epoch 9754/10000, Train Loss: 0.6239, Train Acc: 63.01%, Test Loss: 0.5625, Test Acc: 70.69%\n",
            "Epoch 9755/10000, Train Loss: 0.6163, Train Acc: 66.18%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 9756/10000, Train Loss: 0.6141, Train Acc: 66.76%, Test Loss: 0.5553, Test Acc: 70.69%\n",
            "Epoch 9757/10000, Train Loss: 0.6117, Train Acc: 63.01%, Test Loss: 0.5514, Test Acc: 75.86%\n",
            "Epoch 9758/10000, Train Loss: 0.6166, Train Acc: 64.45%, Test Loss: 0.5516, Test Acc: 72.41%\n",
            "Epoch 9759/10000, Train Loss: 0.6267, Train Acc: 65.32%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 9760/10000, Train Loss: 0.6335, Train Acc: 64.74%, Test Loss: 0.5617, Test Acc: 68.97%\n",
            "Epoch 9761/10000, Train Loss: 0.6076, Train Acc: 66.18%, Test Loss: 0.5587, Test Acc: 68.97%\n",
            "Epoch 9762/10000, Train Loss: 0.6212, Train Acc: 66.76%, Test Loss: 0.5541, Test Acc: 72.41%\n",
            "Epoch 9763/10000, Train Loss: 0.6142, Train Acc: 63.87%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 9764/10000, Train Loss: 0.5956, Train Acc: 67.92%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 9765/10000, Train Loss: 0.6088, Train Acc: 64.16%, Test Loss: 0.5559, Test Acc: 70.69%\n",
            "Epoch 9766/10000, Train Loss: 0.6184, Train Acc: 67.63%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 9767/10000, Train Loss: 0.6168, Train Acc: 65.61%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9768/10000, Train Loss: 0.5887, Train Acc: 65.90%, Test Loss: 0.5581, Test Acc: 70.69%\n",
            "Epoch 9769/10000, Train Loss: 0.6255, Train Acc: 66.47%, Test Loss: 0.5614, Test Acc: 70.69%\n",
            "Epoch 9770/10000, Train Loss: 0.6204, Train Acc: 63.58%, Test Loss: 0.5588, Test Acc: 70.69%\n",
            "Epoch 9771/10000, Train Loss: 0.6139, Train Acc: 66.76%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 9772/10000, Train Loss: 0.6162, Train Acc: 66.18%, Test Loss: 0.5530, Test Acc: 74.14%\n",
            "Epoch 9773/10000, Train Loss: 0.6229, Train Acc: 64.45%, Test Loss: 0.5520, Test Acc: 74.14%\n",
            "Epoch 9774/10000, Train Loss: 0.6064, Train Acc: 64.74%, Test Loss: 0.5547, Test Acc: 74.14%\n",
            "Epoch 9775/10000, Train Loss: 0.6113, Train Acc: 64.16%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 9776/10000, Train Loss: 0.6252, Train Acc: 63.87%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 9777/10000, Train Loss: 0.5927, Train Acc: 67.05%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9778/10000, Train Loss: 0.6212, Train Acc: 61.85%, Test Loss: 0.5561, Test Acc: 68.97%\n",
            "Epoch 9779/10000, Train Loss: 0.6065, Train Acc: 66.18%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 9780/10000, Train Loss: 0.5892, Train Acc: 66.76%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 9781/10000, Train Loss: 0.6178, Train Acc: 66.76%, Test Loss: 0.5563, Test Acc: 68.97%\n",
            "Epoch 9782/10000, Train Loss: 0.5762, Train Acc: 70.23%, Test Loss: 0.5605, Test Acc: 68.97%\n",
            "Epoch 9783/10000, Train Loss: 0.6128, Train Acc: 65.32%, Test Loss: 0.5595, Test Acc: 72.41%\n",
            "Epoch 9784/10000, Train Loss: 0.6165, Train Acc: 62.72%, Test Loss: 0.5582, Test Acc: 74.14%\n",
            "Epoch 9785/10000, Train Loss: 0.6056, Train Acc: 64.74%, Test Loss: 0.5552, Test Acc: 74.14%\n",
            "Epoch 9786/10000, Train Loss: 0.6130, Train Acc: 64.74%, Test Loss: 0.5559, Test Acc: 74.14%\n",
            "Epoch 9787/10000, Train Loss: 0.6224, Train Acc: 64.45%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 9788/10000, Train Loss: 0.6111, Train Acc: 64.74%, Test Loss: 0.5529, Test Acc: 68.97%\n",
            "Epoch 9789/10000, Train Loss: 0.6159, Train Acc: 66.47%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 9790/10000, Train Loss: 0.6133, Train Acc: 64.74%, Test Loss: 0.5546, Test Acc: 68.97%\n",
            "Epoch 9791/10000, Train Loss: 0.6354, Train Acc: 64.45%, Test Loss: 0.5589, Test Acc: 72.41%\n",
            "Epoch 9792/10000, Train Loss: 0.6131, Train Acc: 65.32%, Test Loss: 0.5596, Test Acc: 74.14%\n",
            "Epoch 9793/10000, Train Loss: 0.6095, Train Acc: 65.03%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 9794/10000, Train Loss: 0.6065, Train Acc: 67.05%, Test Loss: 0.5527, Test Acc: 74.14%\n",
            "Epoch 9795/10000, Train Loss: 0.6125, Train Acc: 64.16%, Test Loss: 0.5533, Test Acc: 70.69%\n",
            "Epoch 9796/10000, Train Loss: 0.6090, Train Acc: 63.01%, Test Loss: 0.5536, Test Acc: 72.41%\n",
            "Epoch 9797/10000, Train Loss: 0.5861, Train Acc: 63.87%, Test Loss: 0.5549, Test Acc: 70.69%\n",
            "Epoch 9798/10000, Train Loss: 0.6192, Train Acc: 65.03%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 9799/10000, Train Loss: 0.6156, Train Acc: 64.16%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 9800/10000, Train Loss: 0.6075, Train Acc: 66.47%, Test Loss: 0.5569, Test Acc: 70.69%\n",
            "Epoch 9801/10000, Train Loss: 0.6208, Train Acc: 65.03%, Test Loss: 0.5590, Test Acc: 70.69%\n",
            "Epoch 9802/10000, Train Loss: 0.6032, Train Acc: 66.47%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9803/10000, Train Loss: 0.5953, Train Acc: 63.29%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 9804/10000, Train Loss: 0.6101, Train Acc: 66.76%, Test Loss: 0.5640, Test Acc: 68.97%\n",
            "Epoch 9805/10000, Train Loss: 0.6127, Train Acc: 66.76%, Test Loss: 0.5671, Test Acc: 68.97%\n",
            "Epoch 9806/10000, Train Loss: 0.5922, Train Acc: 65.90%, Test Loss: 0.5666, Test Acc: 70.69%\n",
            "Epoch 9807/10000, Train Loss: 0.5926, Train Acc: 65.03%, Test Loss: 0.5636, Test Acc: 68.97%\n",
            "Epoch 9808/10000, Train Loss: 0.6184, Train Acc: 69.08%, Test Loss: 0.5664, Test Acc: 70.69%\n",
            "Epoch 9809/10000, Train Loss: 0.6080, Train Acc: 67.63%, Test Loss: 0.5614, Test Acc: 70.69%\n",
            "Epoch 9810/10000, Train Loss: 0.6044, Train Acc: 62.43%, Test Loss: 0.5613, Test Acc: 68.97%\n",
            "Epoch 9811/10000, Train Loss: 0.5993, Train Acc: 63.29%, Test Loss: 0.5613, Test Acc: 68.97%\n",
            "Epoch 9812/10000, Train Loss: 0.6017, Train Acc: 65.03%, Test Loss: 0.5600, Test Acc: 72.41%\n",
            "Epoch 9813/10000, Train Loss: 0.5773, Train Acc: 70.23%, Test Loss: 0.5593, Test Acc: 72.41%\n",
            "Epoch 9814/10000, Train Loss: 0.6277, Train Acc: 63.01%, Test Loss: 0.5577, Test Acc: 74.14%\n",
            "Epoch 9815/10000, Train Loss: 0.6156, Train Acc: 65.90%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 9816/10000, Train Loss: 0.6305, Train Acc: 64.74%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 9817/10000, Train Loss: 0.6043, Train Acc: 67.34%, Test Loss: 0.5537, Test Acc: 72.41%\n",
            "Epoch 9818/10000, Train Loss: 0.6157, Train Acc: 66.18%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 9819/10000, Train Loss: 0.6190, Train Acc: 64.45%, Test Loss: 0.5553, Test Acc: 72.41%\n",
            "Epoch 9820/10000, Train Loss: 0.6053, Train Acc: 61.27%, Test Loss: 0.5525, Test Acc: 74.14%\n",
            "Epoch 9821/10000, Train Loss: 0.6097, Train Acc: 65.61%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 9822/10000, Train Loss: 0.6124, Train Acc: 62.43%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 9823/10000, Train Loss: 0.6085, Train Acc: 63.58%, Test Loss: 0.5545, Test Acc: 70.69%\n",
            "Epoch 9824/10000, Train Loss: 0.6328, Train Acc: 63.58%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 9825/10000, Train Loss: 0.6239, Train Acc: 64.16%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 9826/10000, Train Loss: 0.6143, Train Acc: 65.61%, Test Loss: 0.5585, Test Acc: 68.97%\n",
            "Epoch 9827/10000, Train Loss: 0.5816, Train Acc: 67.34%, Test Loss: 0.5570, Test Acc: 68.97%\n",
            "Epoch 9828/10000, Train Loss: 0.6040, Train Acc: 62.14%, Test Loss: 0.5551, Test Acc: 72.41%\n",
            "Epoch 9829/10000, Train Loss: 0.6342, Train Acc: 61.27%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 9830/10000, Train Loss: 0.6187, Train Acc: 64.16%, Test Loss: 0.5550, Test Acc: 72.41%\n",
            "Epoch 9831/10000, Train Loss: 0.6226, Train Acc: 64.16%, Test Loss: 0.5519, Test Acc: 68.97%\n",
            "Epoch 9832/10000, Train Loss: 0.6143, Train Acc: 65.90%, Test Loss: 0.5514, Test Acc: 70.69%\n",
            "Epoch 9833/10000, Train Loss: 0.6078, Train Acc: 65.03%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 9834/10000, Train Loss: 0.6239, Train Acc: 66.47%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 9835/10000, Train Loss: 0.5944, Train Acc: 64.74%, Test Loss: 0.5566, Test Acc: 68.97%\n",
            "Epoch 9836/10000, Train Loss: 0.6323, Train Acc: 65.61%, Test Loss: 0.5579, Test Acc: 68.97%\n",
            "Epoch 9837/10000, Train Loss: 0.5961, Train Acc: 63.58%, Test Loss: 0.5577, Test Acc: 68.97%\n",
            "Epoch 9838/10000, Train Loss: 0.6256, Train Acc: 63.87%, Test Loss: 0.5558, Test Acc: 68.97%\n",
            "Epoch 9839/10000, Train Loss: 0.6198, Train Acc: 65.03%, Test Loss: 0.5563, Test Acc: 72.41%\n",
            "Epoch 9840/10000, Train Loss: 0.6082, Train Acc: 63.58%, Test Loss: 0.5574, Test Acc: 72.41%\n",
            "Epoch 9841/10000, Train Loss: 0.6281, Train Acc: 62.14%, Test Loss: 0.5591, Test Acc: 72.41%\n",
            "Epoch 9842/10000, Train Loss: 0.5888, Train Acc: 65.61%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 9843/10000, Train Loss: 0.6366, Train Acc: 60.69%, Test Loss: 0.5573, Test Acc: 68.97%\n",
            "Epoch 9844/10000, Train Loss: 0.6168, Train Acc: 62.43%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 9845/10000, Train Loss: 0.5836, Train Acc: 66.76%, Test Loss: 0.5612, Test Acc: 68.97%\n",
            "Epoch 9846/10000, Train Loss: 0.6179, Train Acc: 64.74%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 9847/10000, Train Loss: 0.5947, Train Acc: 65.61%, Test Loss: 0.5634, Test Acc: 68.97%\n",
            "Epoch 9848/10000, Train Loss: 0.6188, Train Acc: 63.01%, Test Loss: 0.5624, Test Acc: 70.69%\n",
            "Epoch 9849/10000, Train Loss: 0.6044, Train Acc: 67.92%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 9850/10000, Train Loss: 0.6277, Train Acc: 62.43%, Test Loss: 0.5551, Test Acc: 74.14%\n",
            "Epoch 9851/10000, Train Loss: 0.5912, Train Acc: 71.68%, Test Loss: 0.5555, Test Acc: 74.14%\n",
            "Epoch 9852/10000, Train Loss: 0.6008, Train Acc: 65.03%, Test Loss: 0.5579, Test Acc: 72.41%\n",
            "Epoch 9853/10000, Train Loss: 0.6298, Train Acc: 63.01%, Test Loss: 0.5619, Test Acc: 74.14%\n",
            "Epoch 9854/10000, Train Loss: 0.6106, Train Acc: 67.63%, Test Loss: 0.5544, Test Acc: 75.86%\n",
            "Epoch 9855/10000, Train Loss: 0.5960, Train Acc: 67.34%, Test Loss: 0.5517, Test Acc: 72.41%\n",
            "Epoch 9856/10000, Train Loss: 0.5989, Train Acc: 65.32%, Test Loss: 0.5503, Test Acc: 70.69%\n",
            "Epoch 9857/10000, Train Loss: 0.6363, Train Acc: 65.61%, Test Loss: 0.5501, Test Acc: 68.97%\n",
            "Epoch 9858/10000, Train Loss: 0.6233, Train Acc: 67.92%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 9859/10000, Train Loss: 0.6097, Train Acc: 65.03%, Test Loss: 0.5653, Test Acc: 68.97%\n",
            "Epoch 9860/10000, Train Loss: 0.6445, Train Acc: 64.16%, Test Loss: 0.5675, Test Acc: 70.69%\n",
            "Epoch 9861/10000, Train Loss: 0.6433, Train Acc: 66.18%, Test Loss: 0.5617, Test Acc: 68.97%\n",
            "Epoch 9862/10000, Train Loss: 0.6053, Train Acc: 63.01%, Test Loss: 0.5596, Test Acc: 70.69%\n",
            "Epoch 9863/10000, Train Loss: 0.6104, Train Acc: 67.63%, Test Loss: 0.5611, Test Acc: 70.69%\n",
            "Epoch 9864/10000, Train Loss: 0.6015, Train Acc: 66.18%, Test Loss: 0.5602, Test Acc: 68.97%\n",
            "Epoch 9865/10000, Train Loss: 0.5925, Train Acc: 65.61%, Test Loss: 0.5576, Test Acc: 72.41%\n",
            "Epoch 9866/10000, Train Loss: 0.5988, Train Acc: 65.61%, Test Loss: 0.5548, Test Acc: 74.14%\n",
            "Epoch 9867/10000, Train Loss: 0.6176, Train Acc: 63.29%, Test Loss: 0.5549, Test Acc: 74.14%\n",
            "Epoch 9868/10000, Train Loss: 0.6004, Train Acc: 68.21%, Test Loss: 0.5557, Test Acc: 72.41%\n",
            "Epoch 9869/10000, Train Loss: 0.6294, Train Acc: 64.45%, Test Loss: 0.5545, Test Acc: 72.41%\n",
            "Epoch 9870/10000, Train Loss: 0.5921, Train Acc: 67.63%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 9871/10000, Train Loss: 0.5947, Train Acc: 63.87%, Test Loss: 0.5526, Test Acc: 74.14%\n",
            "Epoch 9872/10000, Train Loss: 0.5968, Train Acc: 67.05%, Test Loss: 0.5496, Test Acc: 72.41%\n",
            "Epoch 9873/10000, Train Loss: 0.6433, Train Acc: 65.32%, Test Loss: 0.5498, Test Acc: 70.69%\n",
            "Epoch 9874/10000, Train Loss: 0.6247, Train Acc: 64.45%, Test Loss: 0.5518, Test Acc: 70.69%\n",
            "Epoch 9875/10000, Train Loss: 0.6246, Train Acc: 65.90%, Test Loss: 0.5514, Test Acc: 68.97%\n",
            "Epoch 9876/10000, Train Loss: 0.5926, Train Acc: 67.34%, Test Loss: 0.5552, Test Acc: 70.69%\n",
            "Epoch 9877/10000, Train Loss: 0.6010, Train Acc: 67.92%, Test Loss: 0.5570, Test Acc: 70.69%\n",
            "Epoch 9878/10000, Train Loss: 0.6074, Train Acc: 67.92%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 9879/10000, Train Loss: 0.6044, Train Acc: 65.90%, Test Loss: 0.5554, Test Acc: 68.97%\n",
            "Epoch 9880/10000, Train Loss: 0.6117, Train Acc: 61.85%, Test Loss: 0.5536, Test Acc: 70.69%\n",
            "Epoch 9881/10000, Train Loss: 0.6309, Train Acc: 63.01%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 9882/10000, Train Loss: 0.6169, Train Acc: 64.16%, Test Loss: 0.5538, Test Acc: 72.41%\n",
            "Epoch 9883/10000, Train Loss: 0.6312, Train Acc: 63.01%, Test Loss: 0.5522, Test Acc: 72.41%\n",
            "Epoch 9884/10000, Train Loss: 0.6100, Train Acc: 64.74%, Test Loss: 0.5493, Test Acc: 68.97%\n",
            "Epoch 9885/10000, Train Loss: 0.6107, Train Acc: 65.90%, Test Loss: 0.5544, Test Acc: 70.69%\n",
            "Epoch 9886/10000, Train Loss: 0.6300, Train Acc: 60.69%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 9887/10000, Train Loss: 0.6197, Train Acc: 63.87%, Test Loss: 0.5621, Test Acc: 70.69%\n",
            "Epoch 9888/10000, Train Loss: 0.6316, Train Acc: 60.69%, Test Loss: 0.5609, Test Acc: 70.69%\n",
            "Epoch 9889/10000, Train Loss: 0.5952, Train Acc: 69.08%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 9890/10000, Train Loss: 0.6356, Train Acc: 63.29%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 9891/10000, Train Loss: 0.6116, Train Acc: 64.16%, Test Loss: 0.5581, Test Acc: 72.41%\n",
            "Epoch 9892/10000, Train Loss: 0.6343, Train Acc: 62.43%, Test Loss: 0.5571, Test Acc: 72.41%\n",
            "Epoch 9893/10000, Train Loss: 0.6020, Train Acc: 65.90%, Test Loss: 0.5535, Test Acc: 74.14%\n",
            "Epoch 9894/10000, Train Loss: 0.6290, Train Acc: 65.32%, Test Loss: 0.5530, Test Acc: 72.41%\n",
            "Epoch 9895/10000, Train Loss: 0.6174, Train Acc: 66.47%, Test Loss: 0.5576, Test Acc: 70.69%\n",
            "Epoch 9896/10000, Train Loss: 0.6158, Train Acc: 64.74%, Test Loss: 0.5547, Test Acc: 72.41%\n",
            "Epoch 9897/10000, Train Loss: 0.6049, Train Acc: 65.32%, Test Loss: 0.5561, Test Acc: 72.41%\n",
            "Epoch 9898/10000, Train Loss: 0.6143, Train Acc: 64.74%, Test Loss: 0.5498, Test Acc: 72.41%\n",
            "Epoch 9899/10000, Train Loss: 0.6165, Train Acc: 66.18%, Test Loss: 0.5485, Test Acc: 72.41%\n",
            "Epoch 9900/10000, Train Loss: 0.6222, Train Acc: 63.58%, Test Loss: 0.5528, Test Acc: 68.97%\n",
            "Epoch 9901/10000, Train Loss: 0.6046, Train Acc: 64.45%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 9902/10000, Train Loss: 0.6231, Train Acc: 63.58%, Test Loss: 0.5541, Test Acc: 68.97%\n",
            "Epoch 9903/10000, Train Loss: 0.6092, Train Acc: 65.32%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9904/10000, Train Loss: 0.5986, Train Acc: 64.16%, Test Loss: 0.5544, Test Acc: 68.97%\n",
            "Epoch 9905/10000, Train Loss: 0.6077, Train Acc: 67.92%, Test Loss: 0.5522, Test Acc: 68.97%\n",
            "Epoch 9906/10000, Train Loss: 0.6405, Train Acc: 63.29%, Test Loss: 0.5530, Test Acc: 68.97%\n",
            "Epoch 9907/10000, Train Loss: 0.6451, Train Acc: 62.14%, Test Loss: 0.5536, Test Acc: 70.69%\n",
            "Epoch 9908/10000, Train Loss: 0.6028, Train Acc: 64.16%, Test Loss: 0.5588, Test Acc: 70.69%\n",
            "Epoch 9909/10000, Train Loss: 0.6063, Train Acc: 66.18%, Test Loss: 0.5590, Test Acc: 70.69%\n",
            "Epoch 9910/10000, Train Loss: 0.6231, Train Acc: 62.72%, Test Loss: 0.5563, Test Acc: 70.69%\n",
            "Epoch 9911/10000, Train Loss: 0.6321, Train Acc: 64.16%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 9912/10000, Train Loss: 0.5966, Train Acc: 66.47%, Test Loss: 0.5569, Test Acc: 68.97%\n",
            "Epoch 9913/10000, Train Loss: 0.6104, Train Acc: 63.29%, Test Loss: 0.5586, Test Acc: 68.97%\n",
            "Epoch 9914/10000, Train Loss: 0.6002, Train Acc: 66.47%, Test Loss: 0.5582, Test Acc: 68.97%\n",
            "Epoch 9915/10000, Train Loss: 0.6321, Train Acc: 65.32%, Test Loss: 0.5559, Test Acc: 72.41%\n",
            "Epoch 9916/10000, Train Loss: 0.5991, Train Acc: 62.43%, Test Loss: 0.5572, Test Acc: 74.14%\n",
            "Epoch 9917/10000, Train Loss: 0.6029, Train Acc: 67.92%, Test Loss: 0.5560, Test Acc: 72.41%\n",
            "Epoch 9918/10000, Train Loss: 0.5913, Train Acc: 68.50%, Test Loss: 0.5532, Test Acc: 72.41%\n",
            "Epoch 9919/10000, Train Loss: 0.5928, Train Acc: 65.32%, Test Loss: 0.5547, Test Acc: 68.97%\n",
            "Epoch 9920/10000, Train Loss: 0.6104, Train Acc: 66.76%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 9921/10000, Train Loss: 0.5812, Train Acc: 66.18%, Test Loss: 0.5611, Test Acc: 70.69%\n",
            "Epoch 9922/10000, Train Loss: 0.5855, Train Acc: 63.01%, Test Loss: 0.5656, Test Acc: 68.97%\n",
            "Epoch 9923/10000, Train Loss: 0.6008, Train Acc: 63.01%, Test Loss: 0.5698, Test Acc: 70.69%\n",
            "Epoch 9924/10000, Train Loss: 0.6150, Train Acc: 69.08%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 9925/10000, Train Loss: 0.6039, Train Acc: 65.61%, Test Loss: 0.5510, Test Acc: 74.14%\n",
            "Epoch 9926/10000, Train Loss: 0.6344, Train Acc: 62.72%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 9927/10000, Train Loss: 0.6508, Train Acc: 62.43%, Test Loss: 0.5533, Test Acc: 72.41%\n",
            "Epoch 9928/10000, Train Loss: 0.6022, Train Acc: 65.32%, Test Loss: 0.5510, Test Acc: 72.41%\n",
            "Epoch 9929/10000, Train Loss: 0.6061, Train Acc: 65.61%, Test Loss: 0.5543, Test Acc: 70.69%\n",
            "Epoch 9930/10000, Train Loss: 0.6244, Train Acc: 65.90%, Test Loss: 0.5586, Test Acc: 70.69%\n",
            "Epoch 9931/10000, Train Loss: 0.6327, Train Acc: 63.87%, Test Loss: 0.5628, Test Acc: 70.69%\n",
            "Epoch 9932/10000, Train Loss: 0.6032, Train Acc: 64.16%, Test Loss: 0.5595, Test Acc: 68.97%\n",
            "Epoch 9933/10000, Train Loss: 0.6284, Train Acc: 63.87%, Test Loss: 0.5549, Test Acc: 72.41%\n",
            "Epoch 9934/10000, Train Loss: 0.6072, Train Acc: 65.90%, Test Loss: 0.5548, Test Acc: 72.41%\n",
            "Epoch 9935/10000, Train Loss: 0.6117, Train Acc: 68.21%, Test Loss: 0.5543, Test Acc: 72.41%\n",
            "Epoch 9936/10000, Train Loss: 0.6108, Train Acc: 63.29%, Test Loss: 0.5595, Test Acc: 70.69%\n",
            "Epoch 9937/10000, Train Loss: 0.6044, Train Acc: 64.16%, Test Loss: 0.5583, Test Acc: 70.69%\n",
            "Epoch 9938/10000, Train Loss: 0.5936, Train Acc: 64.74%, Test Loss: 0.5553, Test Acc: 68.97%\n",
            "Epoch 9939/10000, Train Loss: 0.6063, Train Acc: 67.05%, Test Loss: 0.5575, Test Acc: 70.69%\n",
            "Epoch 9940/10000, Train Loss: 0.6275, Train Acc: 62.72%, Test Loss: 0.5617, Test Acc: 68.97%\n",
            "Epoch 9941/10000, Train Loss: 0.6430, Train Acc: 65.32%, Test Loss: 0.5634, Test Acc: 70.69%\n",
            "Epoch 9942/10000, Train Loss: 0.6188, Train Acc: 64.45%, Test Loss: 0.5620, Test Acc: 68.97%\n",
            "Epoch 9943/10000, Train Loss: 0.5974, Train Acc: 68.79%, Test Loss: 0.5611, Test Acc: 70.69%\n",
            "Epoch 9944/10000, Train Loss: 0.6227, Train Acc: 69.08%, Test Loss: 0.5596, Test Acc: 68.97%\n",
            "Epoch 9945/10000, Train Loss: 0.6011, Train Acc: 65.90%, Test Loss: 0.5555, Test Acc: 72.41%\n",
            "Epoch 9946/10000, Train Loss: 0.6112, Train Acc: 67.63%, Test Loss: 0.5580, Test Acc: 74.14%\n",
            "Epoch 9947/10000, Train Loss: 0.6319, Train Acc: 61.56%, Test Loss: 0.5581, Test Acc: 70.69%\n",
            "Epoch 9948/10000, Train Loss: 0.6245, Train Acc: 67.05%, Test Loss: 0.5560, Test Acc: 70.69%\n",
            "Epoch 9949/10000, Train Loss: 0.6096, Train Acc: 67.34%, Test Loss: 0.5545, Test Acc: 74.14%\n",
            "Epoch 9950/10000, Train Loss: 0.6033, Train Acc: 62.72%, Test Loss: 0.5540, Test Acc: 72.41%\n",
            "Epoch 9951/10000, Train Loss: 0.6216, Train Acc: 63.01%, Test Loss: 0.5526, Test Acc: 72.41%\n",
            "Epoch 9952/10000, Train Loss: 0.6057, Train Acc: 67.92%, Test Loss: 0.5532, Test Acc: 75.86%\n",
            "Epoch 9953/10000, Train Loss: 0.6001, Train Acc: 67.05%, Test Loss: 0.5542, Test Acc: 72.41%\n",
            "Epoch 9954/10000, Train Loss: 0.6087, Train Acc: 65.03%, Test Loss: 0.5552, Test Acc: 68.97%\n",
            "Epoch 9955/10000, Train Loss: 0.6081, Train Acc: 64.74%, Test Loss: 0.5539, Test Acc: 68.97%\n",
            "Epoch 9956/10000, Train Loss: 0.6284, Train Acc: 62.43%, Test Loss: 0.5527, Test Acc: 68.97%\n",
            "Epoch 9957/10000, Train Loss: 0.6239, Train Acc: 62.14%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 9958/10000, Train Loss: 0.6138, Train Acc: 65.32%, Test Loss: 0.5574, Test Acc: 68.97%\n",
            "Epoch 9959/10000, Train Loss: 0.6159, Train Acc: 65.61%, Test Loss: 0.5572, Test Acc: 68.97%\n",
            "Epoch 9960/10000, Train Loss: 0.6252, Train Acc: 67.05%, Test Loss: 0.5556, Test Acc: 68.97%\n",
            "Epoch 9961/10000, Train Loss: 0.6215, Train Acc: 65.32%, Test Loss: 0.5559, Test Acc: 68.97%\n",
            "Epoch 9962/10000, Train Loss: 0.6159, Train Acc: 65.61%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 9963/10000, Train Loss: 0.6448, Train Acc: 64.74%, Test Loss: 0.5583, Test Acc: 68.97%\n",
            "Epoch 9964/10000, Train Loss: 0.6227, Train Acc: 63.58%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 9965/10000, Train Loss: 0.5959, Train Acc: 66.47%, Test Loss: 0.5572, Test Acc: 70.69%\n",
            "Epoch 9966/10000, Train Loss: 0.6247, Train Acc: 66.47%, Test Loss: 0.5527, Test Acc: 72.41%\n",
            "Epoch 9967/10000, Train Loss: 0.5896, Train Acc: 67.63%, Test Loss: 0.5564, Test Acc: 72.41%\n",
            "Epoch 9968/10000, Train Loss: 0.5981, Train Acc: 65.03%, Test Loss: 0.5599, Test Acc: 70.69%\n",
            "Epoch 9969/10000, Train Loss: 0.5961, Train Acc: 65.03%, Test Loss: 0.5602, Test Acc: 70.69%\n",
            "Epoch 9970/10000, Train Loss: 0.6125, Train Acc: 64.16%, Test Loss: 0.5587, Test Acc: 70.69%\n",
            "Epoch 9971/10000, Train Loss: 0.6186, Train Acc: 65.90%, Test Loss: 0.5540, Test Acc: 74.14%\n",
            "Epoch 9972/10000, Train Loss: 0.6239, Train Acc: 64.16%, Test Loss: 0.5531, Test Acc: 72.41%\n",
            "Epoch 9973/10000, Train Loss: 0.6003, Train Acc: 65.90%, Test Loss: 0.5554, Test Acc: 75.86%\n",
            "Epoch 9974/10000, Train Loss: 0.6181, Train Acc: 64.16%, Test Loss: 0.5530, Test Acc: 75.86%\n",
            "Epoch 9975/10000, Train Loss: 0.5917, Train Acc: 67.92%, Test Loss: 0.5520, Test Acc: 72.41%\n",
            "Epoch 9976/10000, Train Loss: 0.6126, Train Acc: 61.56%, Test Loss: 0.5540, Test Acc: 68.97%\n",
            "Epoch 9977/10000, Train Loss: 0.6427, Train Acc: 62.43%, Test Loss: 0.5549, Test Acc: 68.97%\n",
            "Epoch 9978/10000, Train Loss: 0.6042, Train Acc: 67.63%, Test Loss: 0.5537, Test Acc: 68.97%\n",
            "Epoch 9979/10000, Train Loss: 0.6388, Train Acc: 60.69%, Test Loss: 0.5529, Test Acc: 70.69%\n",
            "Epoch 9980/10000, Train Loss: 0.5939, Train Acc: 69.65%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9981/10000, Train Loss: 0.6151, Train Acc: 67.05%, Test Loss: 0.5562, Test Acc: 70.69%\n",
            "Epoch 9982/10000, Train Loss: 0.6446, Train Acc: 62.14%, Test Loss: 0.5550, Test Acc: 68.97%\n",
            "Epoch 9983/10000, Train Loss: 0.6598, Train Acc: 61.85%, Test Loss: 0.5545, Test Acc: 68.97%\n",
            "Epoch 9984/10000, Train Loss: 0.5935, Train Acc: 67.92%, Test Loss: 0.5538, Test Acc: 68.97%\n",
            "Epoch 9985/10000, Train Loss: 0.6133, Train Acc: 66.18%, Test Loss: 0.5534, Test Acc: 68.97%\n",
            "Epoch 9986/10000, Train Loss: 0.6141, Train Acc: 68.21%, Test Loss: 0.5555, Test Acc: 68.97%\n",
            "Epoch 9987/10000, Train Loss: 0.6122, Train Acc: 62.43%, Test Loss: 0.5564, Test Acc: 68.97%\n",
            "Epoch 9988/10000, Train Loss: 0.5976, Train Acc: 63.01%, Test Loss: 0.5551, Test Acc: 68.97%\n",
            "Epoch 9989/10000, Train Loss: 0.6134, Train Acc: 65.61%, Test Loss: 0.5568, Test Acc: 68.97%\n",
            "Epoch 9990/10000, Train Loss: 0.6429, Train Acc: 64.74%, Test Loss: 0.5560, Test Acc: 68.97%\n",
            "Epoch 9991/10000, Train Loss: 0.6371, Train Acc: 62.14%, Test Loss: 0.5571, Test Acc: 68.97%\n",
            "Epoch 9992/10000, Train Loss: 0.5905, Train Acc: 67.92%, Test Loss: 0.5580, Test Acc: 68.97%\n",
            "Epoch 9993/10000, Train Loss: 0.6097, Train Acc: 67.05%, Test Loss: 0.5597, Test Acc: 68.97%\n",
            "Epoch 9994/10000, Train Loss: 0.6142, Train Acc: 65.61%, Test Loss: 0.5567, Test Acc: 70.69%\n",
            "Epoch 9995/10000, Train Loss: 0.6285, Train Acc: 60.69%, Test Loss: 0.5559, Test Acc: 74.14%\n",
            "Epoch 9996/10000, Train Loss: 0.5980, Train Acc: 67.92%, Test Loss: 0.5529, Test Acc: 72.41%\n",
            "Epoch 9997/10000, Train Loss: 0.6143, Train Acc: 62.14%, Test Loss: 0.5524, Test Acc: 72.41%\n",
            "Epoch 9998/10000, Train Loss: 0.6039, Train Acc: 65.03%, Test Loss: 0.5564, Test Acc: 70.69%\n",
            "Epoch 9999/10000, Train Loss: 0.6218, Train Acc: 65.03%, Test Loss: 0.5589, Test Acc: 68.97%\n",
            "Epoch 10000/10000, Train Loss: 0.6210, Train Acc: 65.61%, Test Loss: 0.5623, Test Acc: 70.69%\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists for tracking metrics\n",
        "num_epochs = 10000\n",
        "train_losses, test_losses = [], []\n",
        "train_accuracies, test_accuracies = [], []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    correct_train, total_train = 0, 0\n",
        "    train_loss = 0.0\n",
        "    for features, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "    train_accuracies.append(100 * correct_train / total_train)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct_test, total_test = 0, 0\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_loader:\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "    test_losses.append(test_loss / len(test_loader))\n",
        "    test_accuracies.append(100 * correct_test / total_test)\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.2f}%, \"\n",
        "          f\"Test Loss: {test_losses[-1]:.4f}, Test Acc: {test_accuracies[-1]:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "M_IVWsLajnqA",
        "outputId": "dcefa123-8fe6-4cce-8f5b-c169a71a94ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot loss over epochs\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(test_losses, label=\"Testing Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss over Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot accuracy over epochs\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
        "plt.plot(test_accuracies, label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy over Epochs\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdDrjy2PjseQ",
        "outputId": "b21b171e-70b7-4e55-bae6-0caa3d792e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing configuration: Learning Rate=0.001, Batch Size=16, Hidden Sizes=(10,)\n",
            "Testing accuracy: 60.34%\n",
            "\n",
            "Testing configuration: Learning Rate=0.001, Batch Size=16, Hidden Sizes=(20,)\n",
            "Testing accuracy: 53.45%\n",
            "\n",
            "Testing configuration: Learning Rate=0.001, Batch Size=16, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 55.17%\n",
            "\n",
            "Testing configuration: Learning Rate=0.001, Batch Size=32, Hidden Sizes=(10,)\n",
            "Testing accuracy: 58.62%\n",
            "\n",
            "Testing configuration: Learning Rate=0.001, Batch Size=32, Hidden Sizes=(20,)\n",
            "Testing accuracy: 63.79%\n",
            "\n",
            "Testing configuration: Learning Rate=0.001, Batch Size=32, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 51.72%\n",
            "\n",
            "Testing configuration: Learning Rate=0.001, Batch Size=64, Hidden Sizes=(10,)\n",
            "Testing accuracy: 37.93%\n",
            "\n",
            "Testing configuration: Learning Rate=0.001, Batch Size=64, Hidden Sizes=(20,)\n",
            "Testing accuracy: 65.52%\n",
            "\n",
            "Testing configuration: Learning Rate=0.001, Batch Size=64, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 50.00%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=16, Hidden Sizes=(10,)\n",
            "Testing accuracy: 50.00%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=16, Hidden Sizes=(20,)\n",
            "Testing accuracy: 50.00%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=16, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 63.79%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=32, Hidden Sizes=(10,)\n",
            "Testing accuracy: 50.00%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=32, Hidden Sizes=(20,)\n",
            "Testing accuracy: 77.59%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=32, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 67.24%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=64, Hidden Sizes=(10,)\n",
            "Testing accuracy: 58.62%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=64, Hidden Sizes=(20,)\n",
            "Testing accuracy: 60.34%\n",
            "\n",
            "Testing configuration: Learning Rate=0.005, Batch Size=64, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 62.07%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=16, Hidden Sizes=(10,)\n",
            "Testing accuracy: 62.07%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=16, Hidden Sizes=(20,)\n",
            "Testing accuracy: 55.17%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=16, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 50.00%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=32, Hidden Sizes=(10,)\n",
            "Testing accuracy: 50.00%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=32, Hidden Sizes=(20,)\n",
            "Testing accuracy: 58.62%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=32, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 65.52%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=64, Hidden Sizes=(10,)\n",
            "Testing accuracy: 51.72%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=64, Hidden Sizes=(20,)\n",
            "Testing accuracy: 50.00%\n",
            "\n",
            "Testing configuration: Learning Rate=0.01, Batch Size=64, Hidden Sizes=(10, 5)\n",
            "Testing accuracy: 50.00%\n",
            "\n",
            "Best Testing Accuracy: 77.59% with parameters {'learning_rate': 0.005, 'batch_size': 32, 'hidden_sizes': (20,)}\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "# Define ranges for hyperparameters\n",
        "learning_rates = [0.001, 0.005, 0.01]\n",
        "batch_sizes = [16, 32, 64]\n",
        "hidden_layer_sizes = [(10,), (20,), (10, 5)]  # List of tuples representing each layer's units\n",
        "num_epochs = 50  # Set a standard number of epochs for each run\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "for lr, batch_size, hidden_sizes in itertools.product(learning_rates, batch_sizes, hidden_layer_sizes):\n",
        "    print(f\"Testing configuration: Learning Rate={lr}, Batch Size={batch_size}, Hidden Sizes={hidden_sizes}\")\n",
        "\n",
        "    # Define a new model class each time to avoid reusing the same weights\n",
        "    class MLPModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(MLPModel, self).__init__()\n",
        "            layers = [nn.Linear(16, hidden_sizes[0]), nn.ReLU()]\n",
        "            if len(hidden_sizes) > 1:\n",
        "                layers.extend([nn.Linear(hidden_sizes[0], hidden_sizes[1]), nn.ReLU()])\n",
        "            layers.append(nn.Linear(hidden_sizes[-1], 5))  # Output layer\n",
        "            self.network = nn.Sequential(*layers)\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.network(x)\n",
        "\n",
        "    model = MLPModel()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Create new DataLoader instances for the current batch size\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for features, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_loader:\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Testing accuracy: {accuracy:.2f}%\\n\")\n",
        "\n",
        "    # Check if this configuration is the best so far\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_params = {'learning_rate': lr, 'batch_size': batch_size, 'hidden_sizes': hidden_sizes}\n",
        "\n",
        "print(f\"Best Testing Accuracy: {best_accuracy:.2f}% with parameters {best_params}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}